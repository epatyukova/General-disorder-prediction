{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865fd6bd-ed8c-427a-ab7d-9d3d1349a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import pytorch_lightning as L\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "# from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from torchmetrics.functional import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from pymatgen.core.composition import Composition\n",
    "from crabnet.kingcrab import CrabNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR, StepLR\n",
    "\n",
    "from crabnet.utils.utils import (Lamb, Lookahead, RobustL1, BCEWithLogitsLoss,\n",
    "                         EDMDataset, get_edm, Scaler, DummyScaler, count_parameters)\n",
    "from crabnet.utils.get_compute_device import get_compute_device\n",
    "# from crabnet.utils.composition import _element_composition, get_sym_dict, parse_formula, CompositionError\n",
    "#from utils.optim import SWA\n",
    "\n",
    "data_type_np = np.float32\n",
    "data_type_torch = torch.float32\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CrabNetDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_file: str , \n",
    "                 val_file: str, \n",
    "                 test_file: str,\n",
    "                 n_elements ='infer', \n",
    "                 classification = False,\n",
    "                 elem_prop='mat2vec',\n",
    "                 batch_size = 2**10,\n",
    "                 scale = True,\n",
    "                 pin_memory = True):\n",
    "        super().__init__()\n",
    "        self.train_path = train_file\n",
    "        self.val_path = val_file\n",
    "        self.test_path = test_file\n",
    "        self.batch_size = batch_size\n",
    "        self.n_elements=n_elements\n",
    "        self.pin_memory = pin_memory\n",
    "        self.scale = scale\n",
    "        self.classification = classification\n",
    "        self.elem_prop=elem_prop\n",
    "\n",
    "    def prepare_data(self):\n",
    "        ### loading and encoding trianing data\n",
    "        if(re.search('.json', self.train_path )):\n",
    "            self.data_train=pd.read_json(self.train_path)\n",
    "        elif(re.search('.csv', self.train_path)):\n",
    "            self.data_train=pd.read_csv(self.train_path)\n",
    "\n",
    "        self.train_main_data = list(get_edm(self.data_train, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=False,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.train_len_data = len(self.train_main_data[0])\n",
    "        self.train_n_elements = self.train_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.train_n_elements:0.0f} '\n",
    "              f'elements in the formula for training')\n",
    "        \n",
    "        ### loading and encoding validation data\n",
    "        if(re.search('.json', self.val_path )):\n",
    "            self.data_val=pd.read_json(self.val_path)\n",
    "        elif(re.search('.csv', self.val_path)):\n",
    "            self.data_val=pd.read_csv(self.val_path)\n",
    "        \n",
    "        self.val_main_data = list(get_edm(self.data_val, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.val_len_data = len(self.val_main_data[0])\n",
    "        self.val_n_elements = self.val_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.val_n_elements:0.0f} '\n",
    "              f'elements in the formula for validation')\n",
    "        \n",
    "        ### loading and encoding testing data\n",
    "        if(re.search('.json', self.test_path )):\n",
    "            self.data_test=pd.read_json(self.test_path)\n",
    "        elif(re.search('.csv', self.test_path)):\n",
    "            self.data_test=pd.read_csv(self.test_path)\n",
    "        \n",
    "        self.test_main_data = list(get_edm(self.data_test, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.test_len_data = len(self.test_main_data[0])\n",
    "        self.test_n_elements = self.test_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.test_n_elements:0.0f} '\n",
    "              f'elements in the formula for testing')\n",
    "\n",
    "        self.train_dataset = EDMDataset(self.train_main_data, self.train_n_elements)\n",
    "        self.val_dataset = EDMDataset(self.val_main_data, self.val_n_elements)\n",
    "        self.test_dataset = EDMDataset(self.test_main_data, self.test_n_elements)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory, shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "\n",
    "\n",
    "class CrabNetLightning(L.LightningModule):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = CrabNet(out_dims=config['out_dims'],\n",
    "                             d_model=config['d_model'],\n",
    "                             N=config['N'],\n",
    "                             heads=config['heads'])\n",
    "        print('\\nModel architecture: out_dims, d_model, N, heads')\n",
    "        print(f'{self.model.out_dims}, {self.model.d_model}, '\n",
    "                  f'{self.model.N}, {self.model.heads}')\n",
    "        print(f'Model size: {count_parameters(self.model)} parameters\\n')\n",
    "\n",
    "        ### here we define some important parameters\n",
    "        self.fudge=config['fudge']\n",
    "        self.batch_size=config['batch_size']\n",
    "        self.classification = config['classification']\n",
    "        self.base_lr=config['base_lr']\n",
    "        self.max_lr=config['max_lr']\n",
    "        ### here we also need to initialise scaler based on training data\n",
    "        if(re.search('.json', config['train_path'] )):\n",
    "            train_data=pd.read_json(config['train_path'])\n",
    "        elif(re.search('.csv', config['train_path'])):\n",
    "            train_data=pd.read_csv(config['train_path'])\n",
    "        \n",
    "        y=train_data['target'].values\n",
    "        self.step_size = len(y)\n",
    "        if self.classification:\n",
    "            self.scaler = DummyScaler(y)\n",
    "        else:\n",
    "            self.scaler = Scaler(y)\n",
    "        ### we also define loss function based on task\n",
    "        if self.classification:\n",
    "            if(np.sum(y)>0):\n",
    "                self.weight=torch.tensor(((len(y)-np.sum(y))/np.sum(y))).cuda()\n",
    "            print(\"Using BCE loss for classification task\")\n",
    "            self.criterion = BCEWithLogitsLoss\n",
    "        else:\n",
    "            print(\"Using RobustL1 loss for regression task\")\n",
    "            self.criterion = RobustL1\n",
    "\n",
    "    def forward(self, src, frac):\n",
    "        out=self.model(src, frac)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        base_optim = Lamb(params=self.model.parameters(),lr=0.001)\n",
    "        optimizer = Lookahead(base_optimizer=base_optim)\n",
    "        lr_scheduler = CyclicLR(optimizer,\n",
    "                                base_lr=self.base_lr,\n",
    "                                max_lr=self.max_lr,\n",
    "                                cycle_momentum=False,\n",
    "                                step_size_up=self.step_size)\n",
    "        # lr_scheduler=StepLR(optimizer,\n",
    "        #                     step_size=3,\n",
    "        #                     gamma=0.5)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"train_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        val_loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"val_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return val_loss\n",
    "     \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"test_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "\n",
    "        y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "        acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "        f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "        mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "        self.log(\"predict_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"predict_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"predict_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return formula, y_pred, prediction, uncertainty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960839e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('crabnet/crabnet_config.json','r') as f:\n",
    "        config=json.load(f)\n",
    "\n",
    "L.seed_everything(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba25ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 207925.06formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 208416.34formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 210505.90formulae/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory crabnet_models/crabnet_trained_models/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | CrabNet | 12.0 M\n",
      "----------------------------------\n",
      "12.0 M    Trainable params\n",
      "23.8 K    Non-trainable params\n",
      "12.0 M    Total params\n",
      "48.044    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a0051cde1b42b29384003f05eab260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21e01c31c784e2a8e33bbfe0e52205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Swapping scheduler `CyclicLR` for `SWALR`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74530ba4aba04043ac61a7be1cbc93cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff22d714fd60416d81ddeffc11f041f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d1f957ac2841aab63a9c260e22507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb0e9f78cd14296be10c517f926cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8f2ab97fb54e60ac4692a6d1a7d399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e117a3997ff44190b1032f0640bed83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ce536abc324c31a7e6c629fc97a4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0552984cc42b4f6e8e83575e0607536c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5968febe9e0046e1b798bcd21d5b6d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24f159775bc4721aee74167a2f1fef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 212528.78formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 205074.96formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 202331.59formulae/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca916f8dea704f3ab49158b8c53bfbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8879008745264143\n",
      "         test_f1            0.8783106564072712\n",
      "         test_mc            0.7603236724744891\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8879008745264143,\n",
       "  'test_f1': 0.8783106564072712,\n",
       "  'test_mc': 0.7603236724744891}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CrabNetLightning(**config)\n",
    "# wandb_logger = WandbLogger(project=\"Crabnet-global-disorder-new\", config=config, log_model=\"all\")\n",
    "trainer = Trainer(max_epochs=10,accelerator='gpu', devices=1, \n",
    "                      callbacks=[StochasticWeightAveraging(swa_epoch_start=config['swa_epoch_start'],swa_lrs=config['swa_lrs']),\n",
    "                                EarlyStopping(monitor='val_loss', patience=config['patience']), ModelCheckpoint(monitor='val_acc', mode=\"max\", \n",
    "                                dirpath='crabnet_models/crabnet_trained_models/', filename='disorder-{epoch:02d}-{val_acc:.2f}')])\n",
    "disorder_data = CrabNetDataModule(config['train_path'],\n",
    "                                   config['val_path'],\n",
    "                                   config['test_path'],\n",
    "                                   classification = config['classification'])\n",
    "trainer.fit(model, datamodule=disorder_data)\n",
    "trainer.test(ckpt_path='best',datamodule=disorder_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08e8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in disorder_data.predict_dataloader():\n",
    "    X, y_true, formula = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009ecb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 204244.68formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 198486.13formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 208400.89formulae/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from checkpoint at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5561b5f65ca04f218dfad511fa061098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8879008745264143\n",
      "         test_f1            0.8783106564072712\n",
      "         test_mc            0.7603236724744891\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8879008745264143,\n",
       "  'test_f1': 0.8783106564072712,\n",
       "  'test_mc': 0.7603236724744891}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(ckpt_path='best', datamodule=disorder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d63e676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 211632.95formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 198487.25formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 206336.60formulae/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from checkpoint at crabnet_models/crabnet_trained_models/disorder-epoch=08-val_acc=0.89.ckpt\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02c3c7d30874800b6c406c3f7b8ad31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 74it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formula, prediction, uncertainty=trainer.predict(ckpt_path='best', datamodule=disorder_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3368e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.9639],\n",
       "        [0.0169],\n",
       "        ...,\n",
       "        [0.9998],\n",
       "        [0.9998],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19cbdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d37da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False, ...,  True,  True,  True]),\n",
       " tensor([1., 1., 0.,  ..., 1., 1., 1.]),\n",
       " tensor([[1.0000],\n",
       "         [0.9639],\n",
       "         [0.0169],\n",
       "         ...,\n",
       "         [0.9998],\n",
       "         [0.9998],\n",
       "         [1.0000]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred,y_true,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db711242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879008745264143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "413b7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783106564072712"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59d74a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7603236724744891"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c388f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507252526634921"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(**config):\n",
    "    model = CrabNetLightning(**config)\n",
    "    wandb_logger = WandbLogger(project=\"Crabnet-global-disorder-new\", config=config, log_model=\"all\")\n",
    "    trainer = Trainer(max_epochs=100,accelerator='gpu', devices=1, logger=wandb_logger,\n",
    "                      callbacks=[StochasticWeightAveraging(swa_epoch_start=config['swa_epoch_start'],swa_lrs=config['swa_lrs']),\n",
    "                                EarlyStopping(monitor='val_loss', patience=config['patience']), ModelCheckpoint(monitor='val_acc', mode=\"max\", \n",
    "                                dirpath='crabnet_models/crabnet_trained_models/', filename='disorder-{epoch:02d}-{val_acc:.2f}')])\n",
    "    disorder_data = CrabNetDataModule(config['train_path'],\n",
    "                                   config['val_path'],\n",
    "                                   config['test_path'],\n",
    "                                   classification = config['classification'])\n",
    "    trainer.fit(model, datamodule=disorder_data)\n",
    "    trainer.test(ckpt_path='best',datamodule=disorder_data)\n",
    "\n",
    "    formula, prediction, uncertainty=trainer.predict(ckpt_path='best', datamodule=disorder_data)\n",
    "    metrics={}\n",
    "    metrics['acc']=balanced_accuracy_score(y_true,y_pred)\n",
    "    metrics['f1']=f1_score(y_true,y_pred,average='weighted')\n",
    "    metrics['precision']=precision_score(y_true,y_pred)\n",
    "    metrics['recall']=recall_score(y_true,y_pred)\n",
    "    metrics['mc']=matthews_corrcoef(y_true,y_pred)\n",
    "    metrics['roc_auc']=roc_auc_score(y_true,prediction)\n",
    "    metrics['conf_matrix']=confusion_matrix(y_true,y_pred)\n",
    "    pred_matrix={}\n",
    "    pred_matrix['y_true']=y_true\n",
    "    pred_matrix['y_score']=prediction.detach().numpy()\n",
    "    pred_matrix['y_true']=y_pred\n",
    "   \n",
    "    wandb.log(metrics)\n",
    "    wandb.log(pred_matrix)\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207459ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    wandb.init(project=\"Crabnet-global-disorder-ne\")\n",
    "    wandb.login(key='b11d318e434d456c201ef1d3c86a3c1ce31b98d7')\n",
    "\n",
    "    with open('crabnet/crabnet_config.json','r') as f:\n",
    "        config=json.load(f)\n",
    "\n",
    "    L.seed_everything(config['random_seed'])\n",
    "    main(**config)\n",
    "\n",
    "    wandb.finish()\n",
    "    # print('Start sweeping with different parameters for RF...')\n",
    "\n",
    "    # wandb.login(key='b11d318e434d456c201ef1d3c86a3c1ce31b98d7')\n",
    "\n",
    "    # sweep_config = {\n",
    "    # 'method': 'random',\n",
    "    # 'parameters': {'n_estimators': {'values': [50, 100, 150, 200]},\n",
    "    #                'class_weight': {'values':['balanced', 'balanced_subsample']},\n",
    "    #                'criterion': {'values': ['gini', 'entropy', 'log_loss']}\n",
    "    # }\n",
    "    # }\n",
    "\n",
    "    # sweep_id = wandb.sweep(sweep=sweep_config, project=\"RF-disorder-prediction-global-disorder\")\n",
    "\n",
    "    # wandb.agent(sweep_id, function=main, count=10)\n",
    "\n",
    "    # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e8196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54b9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26095c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "969b3391-b032-4e0c-bcd8-572003b50d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrabNetDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_file: str , \n",
    "                 val_file: str, \n",
    "                 test_file: str,\n",
    "                 n_elements ='infer', \n",
    "                 classification = False,\n",
    "                 batch_size = 2**10,\n",
    "                 scale = True,\n",
    "                 pin_memory = True,\n",
    "                 num_workers = 1):\n",
    "        super().__init__()\n",
    "        self.train_path = train_file\n",
    "        self.val_path = val_file\n",
    "        self.test_path = test_file\n",
    "        self.batch_size = batch_size\n",
    "        self.n_elements=n_elements\n",
    "        self.pin_memory = pin_memory\n",
    "        self.scale = scale\n",
    "        self.classification = classification\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        ### loading and encoding trianing data\n",
    "        if(re.search('.json', self.train_path )):\n",
    "            self.data_train=pd.read_json(self.train_path)\n",
    "        elif(re.search('.csv', self.train_path)):\n",
    "            self.data_train=pd.read_csv(self.train_path)\n",
    "\n",
    "        self.train_main_data = list(get_edm(self.data_train, elem_prop='mat2vec',\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=False,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.train_len_data = len(self.train_main_data[0])\n",
    "        self.train_n_elements = self.train_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.train_n_elements:0.0f} '\n",
    "              f'elements in the formula for training')\n",
    "        \n",
    "        ### loading and encoding validation data\n",
    "        if(re.search('.json', self.val_path )):\n",
    "            self.data_val=pd.read_json(self.val_path)\n",
    "        elif(re.search('.csv', self.val_path)):\n",
    "            self.data_val=pd.read_csv(self.val_path)\n",
    "        \n",
    "        self.val_main_data = list(get_edm(self.data_val, elem_prop='mat2vec',\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.val_len_data = len(self.val_main_data[0])\n",
    "        self.val_n_elements = self.val_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.val_n_elements:0.0f} '\n",
    "              f'elements in the formula for validation')\n",
    "        \n",
    "        ### loading and encoding testing data\n",
    "        if(re.search('.json', self.test_path )):\n",
    "            self.data_test=pd.read_json(self.test_path)\n",
    "        elif(re.search('.csv', self.test_path)):\n",
    "            self.data_test=pd.read_csv(self.test_path)\n",
    "        \n",
    "        self.test_main_data = list(get_edm(self.data_test, elem_prop='mat2vec',\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.test_len_data = len(self.test_main_data[0])\n",
    "        self.test_n_elements = self.test_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.test_n_elements:0.0f} '\n",
    "              f'elements in the formula for testing')\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        ### creating dataloaders for training\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = EDMDataset(self.train_main_data, self.train_n_elements)\n",
    "            self.val_dataset = EDMDataset(self.val_main_data, self.val_n_elements)\n",
    "            \n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage == \"predict\":\n",
    "            self.test_dataset = EDMDataset(self.test_main_data, self.test_n_elements)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                        pin_memory=self.pin_memory, shuffle=False,num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n",
    "                        pin_memory=self.pin_memory, shuffle=False,num_workers=self.num_workers)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False,num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "class CrabNetLightning(L.LightningModule):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = CrabNet(out_dims=config['out_dims'],\n",
    "                             d_model=config['d_model'],\n",
    "                             N=config['N'],\n",
    "                             heads=config['heads'])\n",
    "        print('\\n Model architecture: out_dims, d_model, N, heads')\n",
    "        print(f'{self.model.out_dims}, {self.model.d_model}, '\n",
    "                  f'{self.model.N}, {self.model.heads}')\n",
    "        print(f'Model size: {count_parameters(self.model)} parameters\\n')\n",
    "\n",
    "        ### here we define some important parameters\n",
    "        self.fudge=config['fudge']\n",
    "        self.batch_size=config['batch_size']\n",
    "        self.classification = config['classification']\n",
    "        self.base_lr=config['base_lr']\n",
    "        self.max_lr=config['max_lr']\n",
    "        ### here we also need to initialise scaler based on training data\n",
    "        if(re.search('.json', config['train_path'] )):\n",
    "            train_data=pd.read_json(config['train_path'])\n",
    "        elif(re.search('.csv', config['train_path'])):\n",
    "            train_data=pd.read_csv(config['train_path'])\n",
    "        \n",
    "        y=train_data['target'].values\n",
    "        self.step_size = len(y)\n",
    "        if self.classification:\n",
    "            self.scaler = DummyScaler(y)\n",
    "        else:\n",
    "            self.scaler = Scaler(y)\n",
    "        ### we also define loss function based on task\n",
    "        if self.classification:\n",
    "            if(np.sum(y)>0):\n",
    "                self.weight=torch.tensor(((len(y)-np.sum(y))/np.sum(y)),dtype=data_type_torch).to(device)\n",
    "            print(\"Using BCE loss for classification task\")\n",
    "            self.criterion = BCEWithLogitsLoss\n",
    "        else:\n",
    "            print(\"Using RobustL1 loss for regression task\")\n",
    "            self.criterion = RobustL1\n",
    "\n",
    "\n",
    "    def forward(self, src, frac):\n",
    "        out=self.model(src, frac)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        base_optim = Lamb(params=self.model.parameters(),lr=0.001)\n",
    "        optimizer = Lookahead(base_optimizer=base_optim)\n",
    "        lr_scheduler = CyclicLR(optimizer,\n",
    "                                base_lr=self.base_lr,\n",
    "                                max_lr=self.max_lr,\n",
    "                                cycle_momentum=False,\n",
    "                                step_size_up=self.step_size)\n",
    "        # lr_scheduler=StepLR(optimizer,\n",
    "        #                     step_size=3,\n",
    "        #                     gamma=0.5)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=accuracy_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            f1=f1_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            # auc=roc_auc_score(prediction.view(-1).detach().cpu().numpy(),y.view(-1).detach().cpu().numpy())\n",
    "            self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_f1\", f1, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            # self.log(\"train_auc\", auc, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"train_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        val_loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "        if self.classification:\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=accuracy_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            f1=f1_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            # auc=roc_auc_score(prediction.view(-1).detach().cpu().numpy(),y.view(-1).detach().cpu().numpy())\n",
    "            self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_f1\", f1, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            # self.log(\"val_auc\", auc, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"val_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return val_loss\n",
    "     \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "        if self.classification:\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=accuracy_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            f1=f1_score(y_pred,y.view(-1).detach().cpu().numpy())\n",
    "            # auc=roc_auc_score(prediction.view(-1).detach().cpu().numpy(),y.view(-1).detach().cpu().numpy())\n",
    "            self.log(\"test_acc\", acc, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_f1\", f1, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            # self.log(\"test_auc\", auc, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"test_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "        return formula, prediction, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d04ae9e-517a-4926-a0e4-406f81c9ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading the data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a3e8f-eed8-47d6-a871-5031d22b99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_data = CrabNetDataModule(config['train_path'],\n",
    "                                   config['val_path'],\n",
    "                                   config['test_path'],\n",
    "                                   classification = config['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167bc4b2-8312-4630-991c-e1c02cb50377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 230354.83formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 231825.29formulae/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 230580.65formulae/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "disorder_data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb120a89-f33c-4e02-9256-1cf32cba6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_data.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b91a72-85fa-4ce4-b4f6-859fffc18f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=disorder_data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804ef160-0cf2-4ae6-a19e-358f37f3f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[17.],\n",
      "         [11.],\n",
      "         [47.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [ 1.],\n",
      "         [16.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]],\n",
      "\n",
      "        [[34.],\n",
      "         [49.],\n",
      "         [48.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[52.],\n",
      "         [64.],\n",
      "         [55.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [22.],\n",
      "         [20.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [26.],\n",
      "         [15.],\n",
      "         ...,\n",
      "         [ 0.],\n",
      "         [ 0.],\n",
      "         [ 0.]]]), tensor([1., 0., 1.,  ..., 0., 1., 1.]), ('Ag0.201 Cl1 Na0.799', 'H2 Gd1 K1 O9 S2', 'Cd0.95 Cu0.05 In2 Se4', 'Gd5 Ge10 Ir4', 'Nd2 Ni17', 'Cr4 Nb1 Zr1', 'Ba2 Ga1 Li1 S4', 'C1.5 Fe14.6 Ga2.4 Sm2', 'Cu5 O4 Rb3', 'Gd1 Si1 Ti1', 'Fe7 Sm1', 'Co2.73 Cu0.27 O4', 'Cu0.96 Eu1 Sn1.04', 'Ga0.15 La1 Mn0.85 O3', 'Ce1 Mo6 Se8', 'Ce0.2 Nd2 O7 Zr1.8', 'Mo0.836 Rh1.164', 'Ba8 S17 Sb6', 'Gd1 N1', 'Hf1.8 O7 Ti0.2 Y2', 'K1.7 Na0.3 O15 Si6 Zr1', 'K1 Mo2 O8 Sm1', 'Cl10 N2 Si4', 'In1 O4 Pr1 Sr1', 'C1 Cd0.1 Mg0.9 O3', 'Ca1 Hf4 O9', 'Ho2 O5 Ti1', 'H2 Cs3 O1 S4 Sb1', 'Mo3 Os0.5 Ru0.5', 'Al1 Rb1 Sb4', 'C2 H4.7 Ca1 O6.35', 'Cl4 Se1', 'As0.833 Pd0.67 Tl0.167', 'C1 Sn1 Yb3', 'Cs0.74 K1.26 Mo2 O11 P2', 'In0.289 Li1 O6 Sc0.71 Si2', 'Mn1 O3 Tl1', 'Ga1 Na3 Se4 Zn1', 'H3 Eu1 Li1', 'Br2 Hg2 O6', 'Cs7.45 Ga7.11 Si38.9', 'H8 Na2 O12 S2 Zn1', 'Sm1 Sn3', 'Dy5 Pb3', 'Fe1.5 Nd0.5 O3', 'C0.61 Na4 O7.39 S1.39', 'Al0.75 Mn1 Si1.25', 'In0.5 Li0.5 Mo3 Se3', 'Mg0.62 Ni1.38 O4 Si1', 'Ba0.7 Eu0.02 La0.1 Na0.15 O3 Ti1', 'Fe1.591 Li0.646 Mn0.684 O4', 'Mn0.397 Re0.603', 'Mn0.811 Re0.189', 'H15 Cl2 Co1 N6 O2', 'Ag1 Cl6 Cs2 In0.909 Tb0.091', 'Al2 Si2 Sm1', 'Eu0.63 Ge6 K1 La8.37 O26', 'H1.25 Al0.25 Ti0.75', 'C2 H8 Cu1 Na1 O8 P1 S1', 'Co1 Sb0.84 Se1.16', 'Li4 O8 P2 Zn1', 'Ba1 Ce1 F5', 'H12 Co1 O14 Se2 Tl2', 'Fe0.3 La0.7 Mn0.7 O3 Pb0.3', 'C1 Pu0.83 Ta0.17', 'F7 K1 Pd1 Zr1', 'Ba1 Er2 O10 Si3', 'Mn0.95 P1 V0.05', 'In1 Lu2 Ni2', 'Ba3 Ge1 I2', 'Fe1 Ge0.11 Mn1 P0.63 Si0.26', 'Cu2.8 Te2', 'Co0.924 Mg0.744 Mn1.008 O4', 'Br2 O3 Te1 Zn2', 'H0.92 Fe0.91 Mg7.63 O18 Si4 Ti0.454', 'Ce1 N2 O1 Ta1', 'Br6 Gd4 Si1', 'Fe2.6 In0.9 O6 Sn0.5', 'C12 Fe2 O12 Os1', 'Cd3 O15 P4 Pb2', 'H6 Cl3 N3 O1 Ru1', 'Fe1 K1 S0.22 Se1.78', 'Bi1 Cu2.7 Fe1.05 Mn3.25 O12', 'Al43 Dy6 W4', 'F6 Li2 Pd1', 'Ta0.9 Te2 Zr0.1', 'H6 B1 Li1 Mn1 O11 P2', 'Al1.7 Fe0.3 Mg1 O4', 'Ba8 Cu5 Ge28.7 Si12.3', 'Cs2 F6 K1 Mo1', 'O7 Pr4 Se3 Si2', 'Sm1 Sn1 Zn1', 'Ce1 Cu3.85 Mn1.15', 'Ba8.028 Dy1.04 Fe4.264 O24 U2.668', 'Ba1 Ca0.125 Mg1 O8 Si2 Sr1.875', 'La3 Mo14 O30', 'Br3 Cs1 Eu1', 'Bi3 Cu1 Zr5', 'As12 Pr1 Ru4', 'Fe2 K9 S7', 'Ba0.5 La0.5 Mn1 O2.5', 'Ag0.79 S2 V1', 'C16 H54 Mo12 N4 O42 Si1', 'Ca1 O1', 'Ho5 In3', 'Cr0.23 Mn0.08 Ni0.69', 'Cr1 Fe1 O7 Ti2', 'Li1 Mn0.5 Ni0.5 O2', 'B4 Nb1.6 Zr2.4', 'H7.65 Fe2.58 K0.87 O14.13 S2', 'Cs4 O20 Sb4 Si4', 'Li2 Mn0.9 O4 P0.2 Si0.8', 'Ca1.9 Eu0.019 F1 Na1.08 O4 Si1', 'Ag9 Al12 Cs2.9 O48 Si12', 'I2 In1 N1 O9', 'H2 Al3.48 Ca1 Fe0.11 Mg2.21 O12 Si1.2', 'Ir1 O5.87 Sr2 Zn1', 'C8 H14 Fe1 Mn1 N1 O12', 'K1 N1 O3', 'Ca0.5 Cr0.5 La0.5 O3 Ti0.5', 'Al7 Cl0.93 O16 Sr6', 'Br1 La3 S8 Si2', 'Al9 Co3 Nd2', 'C4 H11 Al4 N1 O17 P4', 'In5 Ir1 Pr1', 'Al2 Au2 U1', 'B2 Co3 Zr1', 'C4 H20 Cd2 N8 O8 S4 Se2', 'Bi2 Ga1.6 In4.4 S12', 'S1.52 Sb2 Se1.48', 'Mn6 Sc0.35 Sn6 Yb0.65', 'Cu5 U1', 'C2 Fe14 Ga3 Sm2', 'H48 Ca3 O52 V10', 'Er2 Ni2 Sn1', 'C1 Dy2 Fe15 N1 Si2', 'Ce3 Pd1 Si3', 'Ag4 Ho3 Sn4', 'Eu0.74 K0.42 O6.32 Sb2', 'C16 H57.6 N4 O31.8 V10', 'Ba2 Cu1.086 O6.29 Tl1.914', 'Ce1 Cu9 Sn4', 'Al1.97 Fe0.23 Mg0.7 O4', 'La16 Pb2.24 Rh8.76', 'Al1 K0.22 Na0.78 O8 Si3', 'Ag0.5 Cr1 Cu0.5 S2', 'Fe0.183 Li0.91 Mn0.8 O4 P1', 'Cl8 Pd8 S8', 'K2 S3 Ti1', 'Cl9 Cs3 Y2', 'Cr0.5 La1 Ni4.5', 'Li11.58377 P2.77264 S1.23969', 'Bi2 O5 V1', 'Al0.5 Co1 Fe1.5 O4', 'Na8 O26 S6 V2', 'Al1 Cs1 Mo2 O8', 'O6.963 Ti1.928 Yb2.074', 'Gd5 Ge1.99 Si2.02', 'O10 P2 Pb1 V2', 'Al1 Ce1 O4 Sr1', 'Pd1 Pr1 Zn1', 'Ag1 Pd1', 'Al1.998 Mg0.355 O4 Zn0.647', 'Li0.25 Mg0.25 O3 Sm0.75 Ti0.75', 'Er1 Se2', 'Cu1 Er2 K1 Se4', 'Ba2 Ca1.35 Cu0.65 F14 Fe2', 'C1 Mo0.85 Nb0.15', 'Eu0.01 Ge4 O12 Y1.99 Zn1', 'H3 F11 O1 Sb2', 'Cu0.6 Fe2 O4 Zn0.4', 'Ga1 Ir1 Y1', 'Hf5 Sn3', 'Ce1 F4', 'Cd0.65 Pd2 Yb1.35', 'B12 Lu1', 'Al1 La2 Ni1.24 Ru0.76', 'As1 Cu1 Hf1 Si1', 'Cu1 Se8 Sm5', 'Al5 Gd1 Mn2 Zn15', 'Se2 Y1 Yb0.5', 'Sb2 Si1 V4', 'N12 Rb2 Zn1', 'Bi2 Se2 Te1', 'Ge0.24 Ta1.04 V1.72', 'La1 Ni0.9 O3 Ti0.1', 'Bi0.73 Fe0.73 O3 Pb0.27 Ti0.27', 'Al0.24 Ni1.76 U1', 'F6 Pb1 Zr1', 'Ca1 Ce0.036 F3.82 S2 Y1.964', 'Na2 P2 Si1', 'Er1 Mn2 Si2', 'Er11 Sn10', 'Ce1 Ge1 Pt1', 'Ce2.55 Eu1.044 O12 Sr4.406 Zn1.001', 'Al0.2 Bi0.9 Fe0.9 O3', 'Ho1 Li1 O8 W2', 'Ba1 Co1 Ir1 La1 O6', 'Fe1 O12 P3 Sr1 Ti1', 'O8 Sc1 Te2 V1', 'Ni2 Tb0.95', 'Ba0.54 Bi1 K0.46 O3', 'Al0.75 Cr2 Zn0.25', 'Pb0.84 S1.86 Se0.14 Sn1.16', 'S2 Se1 Sn2', 'Co0.93 Mg1.08 Sm3.92', 'Co0.06 Li0.9 Ni0.938 O2', 'Ga3.3 Pr6 Se14', 'Fe1 O2 Rb1', 'La2 Ni3', 'H5 N5 Na2 O12 Ru1', 'Fe0.5 Mo3 N1 Rh1.5', 'La0.941 Mo6 Se8', 'Al1 Ho3 Ni8', 'Ba3 Fe1 O9 Ta1 Ti1', 'H7 O7 P2 Pr1', 'Al0.11 I0.89 La0.65', 'H0.66 Al0.33 La3 Li6.53 O12 Zr2', 'Fe3 O1 Ti3', 'Ag4 Er3 Ga7', 'C2 Cs1 Gd1 O6', 'Ca1 N2 O2 Si2', 'Fe0.172 Mg1.828 O4 Si1', 'Al1.95 Au5.05 Sr1', 'Cm1 Cu3 O8 Pb2 Sr2', 'Cl2 Hg3 S2', 'O12 Sm2 W3', 'H20 B5 Cl1 Cs2 Li1 Y1', 'Ba2 Cu2 Eu2 O11 Ti2', 'Ce0.875 O4 Sr0.125 V1', 'Er2 S4 Sr1', 'Ba1 O6 Ru1 Sr1 Y1', 'Bi16 Cl22 Pd1', 'Ca0.1 Co4 Sb12', 'As3 Cu1 O1 Sm2', 'Ag1 Ga0.665 In0.335 Se2', 'H2 Mg1 Mo1 O5', 'Pb0.758 S1', 'Ca1.01 O4 Pr2.99 Sb1', 'H3 Co2 Fe15 Nd2', 'Rh3 Sm1', 'H9 Al10.51 Ca19 Cu1 Mn1.49 O78 Si17.91', 'La0.86 Mn1 Na0.108 O3.09', 'Cl6 Cs2 Er1 Na1', 'C6 H16 Cl1 Co1 Cr1 K1 N5 O12.5', 'Se2 W1 Zn0.5', 'Fe1 O6 Pb2 Sb1', 'Bi0.4 O3 Yb1.6', 'Co1.56 Cr0.44 Nb1', 'As2 Fe2 O6 Sc2 Sr4', 'Co2.5 Fe2.2 Ga7.3 Pr1', 'C2 H4.42 Ca1 O6.21', 'H24 Ca3 O22 S3', 'Ag1 In3 K2 Se6', 'C16 F3 O15 P1 Ru5', 'Fe23 Ho5 Y1', 'F6 Na1 Rh1 Tl2', 'Ga0.9 Ge1.35 Zr0.75', 'F6 Gd2 Nd2 O3', 'Ag0.25 Pd0.5 S0.25', 'H5 Mo5 O23 Rb3 Se2', 'Ba1 Fe2 Nd1 O5', 'Al0.93 B4 Fe0.07 Yb1', 'Fe0.18 Mn0.82 S1', 'H1 Li1 O3 P1 Tl1', 'Al0.85 Cu0.1 Fe1.9 Si0.15 V1', 'Nb2 Pd0.743 Se5', 'H1 Al2.61 Ca1.97 Fe0.36 O13 Si3 Ti0.03', 'Lu1 O7 P2 Rb1', 'Ga1 Y1', 'Nb2.11 O14 Sb3.89 Ti1', 'Ba2 Cu3.904 Fe0.052 O7.895 Pr0.19 Y0.79', 'Cd2 Cu1 Er1', 'C0.8 Ba2 Cu1.2 O4.82', 'As1 Fe0.278 O1 Pr1 Ru0.722', 'H6 B1 Mg1 O8 P1', 'Bi1 O2 Pr2', 'Ba4 Na1 O12 Ru3', 'Bi1 Li3 O4', 'C18 Ho10 Mn13', 'B1 Ta1 W1', 'Fe0.33 Mn0.67 Pd3', 'Co12 Mn5 Y2', 'As2 Fe2 Na0.4 Sr0.6', 'C5 Fe2 U3', 'K0.9 Li1 Na0.1 O4 S1', 'Ca1 Nd4 O17 Ti5', 'Na1.85 Nd0.05 O4 S1', 'As3 Yb4.7', 'Al1.68 Cl2 Ga4.32 Na8 O24 Si6', 'C3 Al3 U1', 'Ba1 Ca7 F3 Na5 O24 P6', 'Pr3 Se7 Si1.25', 'La1.16 Se7.16 V3.46', 'Ga3 Ti5', 'C12 H36 Cl2 N6 O6 Ru2 S6', 'C4.8 B4 Nd5', 'H2 Al3.96 B2 Ca4 Fe1.92 Mg0.12 O32 Si8', 'Al1 Cl4 N5 S5', 'H18 Cr1 F6 Mn1 N6', 'Bi0.5 Pd3 Tl0.5', 'Bi0.8 Ca0.2 Fe0.93 Nb0.07 O3', 'Cu0.134 Pd0.866', 'Li1.93 Mo3 O12 Zn2.03', ' Al0.383 Ca0.944 Cr0.01 Fe0.394 Mg0.479 Mn0.004 O6 Si1.742 Ti0.044', 'O1.306 Ta1', 'Bi2.04 Co0.07 O9 Sr0.89 Ta2', 'Co1 S17 U8', 'Tb1 Te3', 'Co1 La1.25 O4 Sr0.75', 'In20 Ni11 Tb4', 'Ca1 F6 Pt1', 'Mn1 Na2 O7 P2', 'Al1.35 B52.5 Cu1.17', 'Cd1 O21 P6 Ta2', 'Nb1 Ni3', 'B2 Hf2.83 Ru5.17', 'Ba2 Ca1.19 F14 Mn0.81 V2', 'Ce3 Mn0.5 Se7 Si1', 'C0.46 Ta1', 'F1 O12 P3 Pb5', 'Ca1 S4 Tm2', 'Ag1 K1 Se1', 'Nb0.52 O3 Pb1 Sc0.48', 'Cu0.24 Li0.76 Nb1 O3', 'H32 Al8 B2 Cl4 O29', 'F6 Ni1 Rh1', 'Eu0.358 Na0.642 O4 W1', 'Dy0.5 Ho0.5 Mn2', 'Al4 Ar0.72 Fe0.09 Mg1.91 Na0.05 O18 Si5', 'Ca13.07 Ce0.93 Mn1 Sb11', 'Fe2.42 La0.08 Li0.5 O4', 'Co0.28 Gd1 Sn1.78', 'Cu3 La0.67 O12 Ti4', 'B8 K3 Na1 O14', 'Pr0.5 Se1 Yb0.5', 'Hg1 N3 O6 Rb1', 'Fe1 O4 U1', 'Ga3.18 In0.82 O12 Sn2.7 Ti0.3', 'Cr1 Fe1 Ti0.2 Zr0.8', 'H10 Nd1 O14 P3', 'Ca1 Co0.3 O7 Si2 Sr1 Zn0.7', 'As1.4 Se0.6 U1', 'Al0.1 Fe1 Rh0.9', 'Co4 Na10 O9', 'Br6.05 I1.95 P19.1 Sn24', 'Cl1 I1 Pb1', 'I6 Tl1 Yb1', 'Ag0.75 Cu3 Y1.25', 'Ag0.86 Bi8.49 Cu0.38 Pb6.63 S20 Sb0.89', 'H2 F1 K1 Li1 O4 P1', 'Ag0.6 Li2 Tl1.4', 'Co3.378 Fe0.405 La0.15 Sb12', 'B1 V1', 'Er2 Ge1 Rh3', 'H4 F4 Ga1 N1', 'Ba2 Cu1.1 O6.044 Tl1.9', 'Co2 Si1 Ti1', 'Ba1 Dy0.5 O3 Sb0.5', 'Se1 Ti1', 'Gd3 Li3 O12 Te2', 'Sb0.1 Te0.9 Tm1', 'Al1 Cs0.814 O12 Si5', 'Au10 Gd5.61 Mg1.39', 'C8 H10 K4 O21 Zr1', 'Li0.95 Mn2.05 O4', 'Ca0.3 Cu1 O1.75 Sr0.7', 'Fe2.57 Mn0.43 O4', 'Mo0.09 Re0.91', 'C1 Mn1 O3', 'B2 Ni2 Tb1', 'Cl8 Co1 Li6', 'Eu0.025 O4 Ta1 Tb0.025 Y0.95', 'Co0.07 Ga0.023 Li0.983 Ni0.93 O2', 'Al0.4 Ba1 Fe11.6 O19', 'B2 Fe1', 'Cs5 Na6 P5 S20 U1', 'Cu2.7 Mo0.3 O7.47 Pr1 Sr2', 'H2 Pr1', 'As1 Co0.85 Fe0.15 Nd1 O1', 'Al6 Cu6 Yb1', 'Br4 Cs2 I2 Sn1', 'C1 Dy2 Fe2 Si2', 'Al3 Cl12 Ho1', 'La4 O9 Sr3', 'Ba1.6 N6 Si2 Sr3.4', 'N0.87 Sc1', 'O14 Ru3 Sn15', 'Co6 Ge6 Mg1', 'Au14.2 Ce3 Sn2.7', 'Pb1.006 S1', 'Fe0.94 Nb1.94 O8 Th0.58 Y0.42', 'Cu2 Rb1 Ta1 Te4', 'Lu2 Ni12 P7', 'Np1 Sb2', 'H2 Er1 K3 O10 Si3', 'In3 Yb8', 'H12 Li3 O10 V1', 'C2.008 Co6 Mo6', 'La6 Pd13 Zn4', 'Mo2 O11 Ta2', 'Au5 Cs1 Ga9', 'Ga1.2 La1 Ni3.8', 'K0.667 Li0.333 O8 P1 Ta2', 'Ce1 Pd1 Zn1', 'Fe1 Mo1 O6 Pb2', 'H6 B1 Ca0.42 Co1 K0.17 O11 P2', 'Cl6 Cs2 Na1 Sm1', 'Ga1 Ni1 Sc1', 'B6 O0.787', 'Ni1 O3 Y1', 'Mg1 Pu2', 'N1 Ta0.25 V0.75', 'B2 Co3 Lu1', 'Cl6 K2 Re1', 'Al2.4 Mg0.39 O4', 'H26 N6 O19 P6', 'F1.56 O1.56 Pb0.24 Ta1', 'As1 P1 Ru1', 'Fe7 Mn5 Y1', 'B1 Bi1 Pb1 S4', 'B5 Br1 Eu2 O9', 'Cl2 Sm1', 'Co0.3 Fe0.7 La0.4 O3 Sr0.6', 'S2 Sc1.37', 'C2 H4 Mn1 O6', 'Bi18.793 Ca4.207 O42 V4', 'Fe3 Gd2 Si5', 'Nb3 Sn1', 'Er2 O7 Ru2', 'Ce1 Co4 Pu1', 'As1 Mn1', 'Cu2 Mg1 S4 Si1', 'Ba1 Fe0.9 O2.6 Y0.1', 'Cu2 S4 Si0.79 Sn0.21 Zn1', 'Cr1.8 Si1 V1.2', 'C3 K4 O11 U1', 'Al2 Lu1', 'Mn3 O14 Sb3 Tm2', 'Ca2 Fe9 O13', 'Au1 Tb2', 'Mn1 O3 Pr0.525 Sr0.475', 'H1 Al3 Ca1.68 O13 Si3 Sr0.32', ' H2 Al0.13 Ca0.13 Fe1.31 K0.17 Li0.13 Mg3.37 Mn0.06 Na2.2 O24 Si8', 'Ba5.93 O80 Ti40', 'As3 Co2 Na1 O10', 'Pd3 Sb0.5 Tl0.5', 'Al0.9 Ba1 Fe11.1 O19', 'Pd3 Tm1', 'H18 Cl4 O25 Th1', 'F24 Fe3 Pb8', 'Sr3 Tl5', 'Bi2 Nb2 O9 Pb0.49 Sr0.5', 'C4 H16 Br0.51 I0.48 K1 N8 S4', 'Au1 Ba2 Pt1', 'B4 Fe1 Sc1', 'La3 O7 Os1', 'Ca5 Pt2', 'H6 Ag1 Cr2 In3 O14', 'Mg343.08 Pt48.72', ' C0.905 Al5.472 Ca3.53 Cl0.073 K0.14 Na0.33 O26.775 S0.015 Si6.528', 'Ba1 Co4 O7.2 Yb1', 'Co0.7 Ga1 Mn0.3', 'In2 Ni9 Pr1', 'Cd0.15 Pb0.85 S1', 'Ce0.2 O4 Pr0.8 Sr2', 'Ba2 Sn1 Te5', 'Mo2.4 O16 V3.6', 'Ni5 Yb1', 'Ni4 O12 P3 Tl1', 'Eu1 Ga1.6 Mg0.4', 'Ca3 Cr2 O12 Si1.89 Ti1.11', 'C3 Co1 Fe16 Sm2', 'S1.53 Sb2 Se1.47', 'B0.15 Ca1.85 Na0.15 O4 Si0.85', 'Ga0.3 V1.8 Zr0.9', 'Cl2 O6 Sr3 Te2', 'Ni1 O2 Sr1', 'Cu5 K3 O4', 'Ge1 Os1 Zr1', 'Mo2.904 Nd5 O15.25 V0.096', 'Cu2 Se4 Si1 Zn1', 'Cu1 Na2 O8 S2', 'As2 Ga1 Li1 O7', ' C0.21 H9.848 Al0.117 Cl0.33 Cr0.372 Fe0.261 Mg2.25 O8.554', 'Ba0.2 Bi1.956 Mn4 O10', 'In2 Pt1 Yb0.95', 'N0.76 V1', 'Al6 Ca5 O14', 'In0.5 Ni1 Sb0.5 Zr1', 'F6 Ti1 Zr1', 'Cu2 Ni1 Sn1', 'Cr1 K3 O8', 'As0.67 Cr1 Sb0.33', 'Mg0.2 Mn0.8 Na0.7 O2', 'B8 Nb7 Rh6', 'Cu1 Hf1 Sn1', 'Fe0.25 Se2 Ti1', 'Nb18 O69 W8', 'H4 Ag1 N1 S4 W1', 'As4 Ba4 Ge1', 'Eu4 Mg1 N5 Ta1', 'Ni1 O4.22 Pr2', 'As2 Eu1 Si1', 'Ni1.338 O12 Sb2.662 Sr4', 'Ba0.2 Ni1 O4 Pr1.8', 'Ca1.16 Ge1 Mg0.83 O4', 'As0.85 Cu1.07 P1.15 Sm1', 'Sb1 Sn1 Ti1', 'Bi0.98 Cu1 O1 Pb0.02 Te1', 'S1 Ti0.685', 'As3 In2 Na3 O12', 'Eu1 Mo5 O8', 'C6 Fe1 K1.903 Mn1 N6', 'Br4 Hg3 Te1', 'S6 Si2 Tl4', 'H4 Ga1 N1 O8 P2 Zn1', 'Mg0.264 Nb0.636 O3 Pb1 Sc0.1', 'P1 S4 Y1', 'Ca1 Co2 Ge2', 'Cu3 Se2 Ta1 Te2', 'C0.953 B0.016', 'Bi1.2 Eu0.26 Li0.4 Mg0.5 Nb1.5 O6.7', 'Nb1 O3 Th0.25', 'Ca1 Co1 O4.17 Pr1', 'Ca1 Ga0.54 In0.46', 'C1 Nd1 Rh3', 'Ba1.8 Bi0.3 Co0.82 O6 Ru1.07', 'Fe2 Hf0.81 Sn0.19', 'Pt2 Si2 Sr1', 'Co1.6 Fe0.8 O4 Sn0.6', 'Ca0.75 O3 Sr0.25 Ti1', 'In4 Rh2 Sc5', 'Dy0.015 O3 Sr0.985 Zr1', 'Br1 In1 O3 Te1', 'Hg3 Pb16 S46 Sb18', 'Br6 Rb2 W1', 'H2 Ca2 Cr1 I2 O11', 'Na1 O4 Ti1 Y1', 'Lu1 Si2', 'Er5 Si4', 'Li0.96 Zn3.04', 'Ga1 Ni1 Yb1', 'Pd1 S6 Ta2', 'Al5.5 Ca7.902 Na1.73 O18 Si0.5', 'Al0.2 La0.6 Li0.4 O3 Ti0.8', 'In0.0216 Mg0.9784', 'As2 Mo0.4', 'Li1.067 Ni0.4 O2 Ti0.533', 'Ba4 Ge2 Sb2 Te10', 'Ge3 O12 Sr3 Y2', 'In1 Rh1 Sm1', 'K1 Mn1 P1', 'Ge1 Lu1 Na1 O4', 'B13.06 Se0.94', 'Na2.63 O12 P3 Sc2', 'Gd4 In1 Rh1', 'C2 H11.256 Al0.916 Fe0.084 K0.686 N1.314 Na1 O14 P2', 'La0.55 Li0.35 O3 Ti1', 'Al2 Tb1', 'Co2.853 Fe0.147 In2 S2', 'Na3 P1 S1 Se3', 'C1 Co2 Mo4', 'Ca1.88 Li2 Mg2 N6 Si2 Sr0.12', 'Cu0.5 La2 Li0.5 O4', 'Al1.756 Fe0.062 Mn0.182 O5 Si1', 'Co0.888 Fe0.112 La1 O3', 'Bi2.23 La0.3 Se8 Sn0.77 Sr2.71', 'Fe1 Ir1 O6 Sr2', 'Dy3 Fe1 Ga1 S7', 'Al10.88 K1.44 O17.23', 'Al1.1 Re0.9', 'Ba2 Cu2.02 Nb0.97 O8 Pr0.99', 'Al1.846 Pt0.154 Zr1', 'Ce1 Hg2', 'C16 H48 I3 Lu1 O8 S8', 'Al2 Ca1 Si2', 'Al1.02 Fe0.98 Mn1.335 Na1.479 O12 P3', 'F2 Li1 O2 Ta1', 'Ge1 Na1 O5 Sb1', 'La2 Mo1.7 O9 S0.3', 'Cu2 Li3 O4', 'Li1.13 Mn2 O4', 'H14 Co0.65 Cu0.35 O11 S1', 'Mn27.772 Ti9.228', 'Fe0.226 Mg1.774 O4 Si1', 'Al12 Eu3 Rh4', 'Bi1 Mn1 O2.81', 'Cs1 I3 Mn1', 'Cs2 Mo5 Na8 O44 U8', 'Al0.75 Co0.5 Cr0.2 Ni3.55 Y1', 'As3 Mo3 Rb2', 'Ag0.7 Cd0.1 Zn0.2', 'C9 O9 Os3 S2', 'Al1 Dy1 Pd1', 'Nb14 O39 Rb5 V1', 'O12 P4 Rb1 Tb1', 'P8 Th3 U3', 'B2 Nb2.49 Ni0.51 Ru5', 'Al3 Tm1', 'Ba1 Co1 Na2 O8 V2', 'Co1.75 La2 O6 Ti0.25', 'H5 B7 O14 Rb2', 'F3 La2 Li1 O8 S2', 'La0.65 Mn0.95 O3 Pb0.35 Ti0.05', 'Li0.69 Ni1.01 O2', 'Co1 U1', 'Al2 La0.5 U0.5', 'Mo0.04 O5 V1.96', 'Al1.338 Ca3 Fe0.662 O12 Si3', 'H3 O3 Tb1', 'B4 Pu1', 'Ta0.045 Ti0.955', 'C1 B2 Lu1 Ni2', 'C4 H10 Mg1 N4 O6', 'C25 H36 Bi2 Cl1 Fe4 N3 O13', 'Al1 Mn1 S7 Y3', 'Fe1 Na3 O3', 'La1 Mn0.9 O3 Sc0.1', 'Cr0.1112 Li1 Mn1.8888 O4', 'Nb0.74 O6 Sb1.26 Ti1', 'Ce2 Fe16.09 Ga0.91', 'B1 Ce1 Rh3', 'O7 Rb2 Se2', 'H2 Cu1 O5 S1', 'Cu2 In2 O5', 'C22 H34 N2 Si2', 'Bi1 Na1 Zn0.94', 'Ba1 Mn2 O3', 'Mg3 O8 V2', 'Ge2 Lu2 O7', 'Ge1.01 In0.99 Rb0.99 Se4', 'C0.25 Cr6 P2.75', 'Cr1 Pt3', 'O4 Rb2 W1', 'C8 H26 Cl3 N1 O3 Ru1 S3', 'Fe1 Sb2 Se4', 'Mg0.05 O1 Zn0.95', 'Cu3 Eu1 Pd2', 'B2 Dy2 O24 S6', 'Ir1 Lu1 Si1', 'Ni1 Si1 W1', 'Co0.3 Fe0.7', 'La1 Sb1 Sc1', 'Eu1 La2 S4', 'K1 O8 W2 Y1', 'H6 Mn3 O12 S2', 'Fe1 Sb1.8 Te0.2', 'B1 Bi0.09 La2.91 O9 W1', 'Cu2 Fe0.6 Mn0.4 S4 Sn1', 'Dy1 O4 P1', '  Al0.28 Ca2.912 Ce0.003 Fe1.336 Mg0.146 Mn0.019 Na0.025 Nd0.003 O12 Si2.337 Sr0.001 Ti0.889 Y0.01 Zr0.039', 'Gd1 Ge1 Mn0.1 Ti0.9', 'Ga0.37 Ge5.63 Mn6 Sc1', 'H6 O10 Rb2 S1 Te1', 'Ba6 Cu11.76 Fe13.24 S27', 'Ge1 Nd1 Ti1', 'Ca0.9 Co1 Nd1.1 O4', 'Co0.02 Cr0.98 Cu1 O2', 'Li9.688 Nb4.242 O30 Ti7.07', 'Al4 Cu0.3 Mg1.7 O18 Si5', 'Cl2 I1 K1', 'Cr1.9 Fe1 Ga0.1 S4', 'O17 P6 Sr2', 'Co1 F4 Li1', 'Cr2 Fe10 Tm1', 'C6 H17 Co2 N11 O1', 'As1 Cr1.6 Mo0.4', ' Fe1.05 Mn1.88 Na0.18 O38 Pb0.61 Sr0.39 Ti7.03 V7.78 Zn0.26', 'Al8 Au3.96 Si1.04 Sm1', 'Cl6 In0.6 Li2.6 Zr0.4', 'Bi0.1 Ca0.3 Cu2 Nd1.7 O6 Sr0.9', 'Ag2 Nd1 Si2', 'H5 Ca2 Fe1 Mn1 O15 Si4', 'Co0.1545 Fe0.1545 Li0.97 Ni0.721 O2', 'Al0.4 Fe1.6 Ni0.7 O4 Zn0.3', 'C1 Ti3 Tl1', 'Ba2 Cu0.5 In1.5 O4.56', 'Ba3 Cl2 O5 W1', 'Ge1 In2 Na2 Se6', 'Ge1 Mo2.25 W0.75', 'Er1 Rb1 S2', 'Cu1 Ga0.2 In0.8 Tb1', 'C1 Co1 Fe12 Nd2 V1', 'Eu1 Gd1 O7 Ti2', 'As2 Ni4 Tb1', 'H14 Cu4 Mn1 O18 S2', 'Cu0.2 Ho1 In1 Ni0.8', 'Cr1 Ge2 Zr1', 'Al11 Na11 O48 S16 Si13', 'Al0.7 As4 Ca0.1 Cu5.1 Fe0.2 K2 Na0.9 O18', 'Al2 Nd0.4 Pr0.6', 'Ge3 La4 S4.248 Se7.752', 'C11 Co2 O11 Ru1', 'Al2 Cd1 Te4', 'Li1 O5.5 Sr2 W1', 'Ag1 Ga1 Ge1 Se4', 'Cu5 O30 Ta11', 'Al25.62 Au7.37 Sr3 Ti1', 'H8 Co0.14 Mg0.29 Mn0.44 Na2 Ni0.06 O12 S2', 'O6 Rb1 Sb1 W1', 'Co6.5 Mo3.9 Ta2.6', 'Co0.4 Dy1 Ge2', 'B12.774 Li1', 'B6 Co21 Ti2', 'Fe2.93 O4', 'As3 Cu3 Sm2', 'H2.2 I1 K0.45 N0.55', 'Cl6 Na1 Pr2', 'Ge0.74 O2 V0.21', 'K2 Nd1 O15 P5', 'Co12 Mn5 Nd2', 'B1 I3', 'K2 Te2', 'F2 La6 O24 Si6 Sr4', 'Ce0.2 Mn1 O3 Pr0.15 Sr0.65', 'C14 H34 Eu1 N6 O9 Pt1.5 S4', 'Cr1 K1 O7 P2', 'Ba3 Ho4 O9', 'Cu3 Mo1.94 O9 S0.06', 'Ca0.9 Mn7 O12 Sr0.1', 'Mo1 S0.25 Se1.75', 'C4 H24 Br6 Cd1 N12', 'Ag0.7 Ce2 Ga9.1', 'Bi17 O36 Yb7', 'K1 O3 Ta1', 'Na4 Ni3 O15 P4', 'Gd0.2 La0.8 Mn1 O3', 'Cu1 Sb0.115 Sn0.835', 'Ba4 Co1 O27 Ti11', 'Ba0.4 Ca1 O6 Sr1.6 W1', 'As3 Ga1 Si1 Sr1', 'Cl24 Hg23 P12 Zn6', 'Bi4 Cl2 S5', 'H18 Cr1 F6 Fe1 N6', 'Eu1 Ni2 Sb2', 'Hf1 Si1', 'Cr1.8 Mn1.2 O4', 'B7 Cl1 Li4 O12', 'Au1 In0.5 Zr0.5', 'Hf1.5 Mn1.5', 'Cu2.8 O7.316 Re0.2 Sr2 Y1', 'As1 V3', 'Cr0.333 In1 O3.333 Ti0.667', 'Ca1 I2 O6', 'Gd5 Ge4', 'Eu5 O7 S6 V3', 'C2 H8 Br2 Co1 N4 S2', 'Al19.5 Fe5.604 Pd0.396', 'Fe0.3 Ga0.7 Ni3', 'Bi0.49 Na0.51 O3 Ti1', 'B10 Ni19 Tb3', 'Gd2 Mo3 O12', 'Ca0.098 Eu0.902 Ga4', 'Ba0.7 Fe1 La1.3 Mn1 O6', 'C2 H2 Na1 O6 P1 Zn1', 'Ca10 Cl0.24 F1.9 O24 P6', 'Bi2 O6 Te1', 'Al0.726 Ca1 Mg0.656 O6 Si1.368 Ti0.262', 'Br7 In4', 'In1 O12 Rb3 S3', 'Mg15 Nd1 Ni1', 'C1 Nb2 P1', 'Ga1 Lu1 Pt1', 'Ni2 Y0.96', 'Fe2 Li1 N3 Sr2', 'In1.1 Ni0.88 Tm1', 'O14 P4 Sr1 V2', 'Co1 Nd0.3 O2.58 Sr0.7', 'Ce0.04 Co1 Dy0.04 Fe1.92 O4', 'Dy1 Ga2 Ni1', 'S5 Th2', 'Fe0.246 Mg1.754 O4 Si1', 'La1 Ni0.53 O3 V0.47', 'Ga0.7 Mn0.3 Ni3', 'Al2 Sb6 Sr0.85 Yb4.15', 'Cs10 S14 Tc6', 'Ba3 Ca1 Nb2 O9', 'Al2.86 Ca1.64 F2 Mg3.38 Mn1.22 Na0.87 O22 Si6', 'B1 Ba1 Na1 O3', 'H3 B1 In1 Na1 O10 P2', 'H10 Co1 O15 S2 U1', 'Co1 Sb2.847 Te0.068', 'B2.54 Si0.962', 'C36 H108 As4 Si16 Sn4', 'C1 Gd7 Si4', 'O2 Th0.19 U0.81', 'B1 Cr1 O4 Pb1', 'Ba8 Ga6 Si40', 'K1 O3', 'Cr1 Ni1 Ta1', 'Au4.93 Eu1 In1.07', 'Eu1 Ge1 Pd2', 'H4 Co1 N2 O4 S1', 'Pt11 Si5 Sm8', 'Cr0.75 Ru0.25', 'P0.41 S0.59 U1', 'B2 Ho1 Ir3', 'C1 Mo1.4 Nb0.6', 'H8 B1 Na1 O6', 'Al1 Ca0.08 F5 Sr0.92', 'B1 Co0.24 Fe0.86 Mn0.9', 'C9 H2 O9 Os3 S1', 'Pr1 Te6 U1', 'Ce4 Fe1 S7', 'Ce1 Mn8 Ni4', 'F1 Na1 Nb1 O6 Pr1 Ti1', 'Fe1 K1 S1.04 Se0.96', 'B2 Mo2 Ni1', 'Ca1.17 Co0.83 Ge1 O4', 'Al2 Co0.1 Mg0.9 O4', 'Er1 Ga0.4 Mn1.6', 'Bi0.006 Cd0.996 Cl3 Cs0.996', 'Ga0.75 Nb0.25 Ni3', 'C1 Al4 N3 O1', 'Cu0.644 In5 Na0.356 S8', 'Ba1 Ca1.14 Cu2.68 La0.86 O6.52 Zn0.1', 'B2 Er1 Fe2', 'Ca1 O3 Te1', 'Al0.19 Ca0.88 K0.12 Mg0.83 O6 Si1.98', 'Ba8 Cl1 Co2 Mn6 O22', 'C1 Ho1 Ru2 Si1', 'Ba4 Cu6.72 Nd2 O15.08', 'Al1 Co1 Mn2', 'La2 O6 Pt1 Zn1', 'P1.02 Pd4.5', 'Cu1.8 Mn5.2 O12 Pr1', 'Er3 Ga2 Ni6', 'Ba2 Cu3 O6.03 Y1', 'Mo0.15 N1.79 O1.21 Sr1 W0.85', 'Er6 I10 Ni1', 'Fe1.95 Ti0.05', 'Ba1.3 Cu3 La1.7 O7.3', 'Ba0.8 In1 La1.2 Mn1 O6', 'C2 H6 Er1 N1 O9 S1', 'Ca18 K3 O56 P14 Sc0.4 Sm0.6', '  H1.51 Al0.1 Ca0.06 F0.47 Fe2.63 K0.07 Li1.66 Mg1.35 Mn0.13 Na1.08 O23.51 Si8 Ti0.06 Zn0.31', 'Ba2 Ca3.4 Cu4 O11.96 Tl1.482', 'Cd1.2 Mn0.8 Se1.6 Te0.4', 'Eu1 Te1', 'Al1 K0.8 Na0.2 O8 Si3', 'B1 Co1.76 V0.24', 'C1 B15.5 N1 Sc0.93', 'B1 Cu1.5 Fe12.5 Nd2', 'O2 Ti0.928', 'B2 Ir5 Mg2 P0.72', 'Cs2 Mo3 O16 U2', 'B4 Ba2 Cd1 O12 Y2', 'Ca0.36 Fe0.68 Mg0.32 Na0.64 O6 Si2', 'C4 H20 Mg1 N8 O14 Re2', 'Mn3 Si3 V2', 'F1.22 Ga1 Mn1 O4.78 Sr2', 'Cu1 Ni2 Ti1', 'Dy4 Sb3', 'Bi0.35 Nb0.025 O3 Pb0.65 Sc0.35 Ti0.6 Yb0.025', 'Ni4 Sn1 Zr1', 'C30 Co8 O24', 'Ag0.02 Cd0.99 O1', 'C1 B4 F6 O1', 'Hf1.6 O7 Ti0.4 Y2', 'Nd1.6 Ni1 O4 Sr0.4', 'Ge3 Na4 O12 Zr2', 'O9 P2 U2', 'P4 Ru1 Si4', 'Ge6 Tm5 Zn3.88', 'H12 Al1 Na1 O14 S2', 'H1 N1 S9', 'Fe0.05 Mn0.95 P1', 'H2 Al3.48 Ca1 Fe0.16 Mg2.17 O12 Si1.19', 'Ca10 F2 O24 P3.6 V2.4', 'Cs3 Mg2 N1 O17 P6', 'Al1 Li3 O5 Si1', 'Ce10 Cl4 Ga5', 'Al1 F2 Mg3.16 Na3 O22 Sc1.84 Si7', 'Dy1 Po1', 'Co0.2 Li1 Mn0.4 Ni0.4 O4 P1', 'Bi2 Fe2 O9.52 Sr2.63', 'Cs0.1 Ni1 O2', 'Ag1 Al0.036 Dy0.964', 'Cu0.59 Pd0.72 Sn1', 'Ce5 Ni1 Pb3', 'H2 I2 Na1 O9 V1', 'H2 B5 Li2 Na1 O10', 'B2 Ba1 Ce0.02 Na1 O6 Y1', 'Te6 Zr5', 'Cr0.3 La2 Mo1.7 O8.9', 'Fe17 Gd2 N2', 'Au3 Pr3 Sb4', 'Fe1 Ni7 Si3', 'O17 P2 Rb3 V1.63 W2.37', 'Fe1 Mo1 O6 Sr1.9 Tb0.1', 'Al0.15 La0.57 Mn0.85 Nd0.1 O3 Sr0.33', 'H6 Fe9.24 Mg2.76 O30 P6', 'Li1.14 O4 Ti1.8', 'C4 H16 Al1 Li1 N4', 'Ga1 Nb6 Pt1', 'Ce1 Te3', 'C5 H27 Bi2 Cl11 N12', 'Cd1 Na2 O2', 'H2.73 B1 Fe12.93 Nd2 Si1.07', 'H2 Fe3 O10 P2', 'Ga2 O16 P5 Rb1', 'C10 H20 Co1 N6 O6 Pr1 S2', 'Cu3 In4 N5 Sr8', 'Bi0.9 Fe1 La0.1 O3', 'O6.96 Ru2 Tl2', 'Ba2 Cu1.1 O5.996 Tl1.9', 'Al2 Gd0.8 Zr0.2', 'Bi0.65 Fe1 La0.1 O2.875 Pb0.25', 'C2 Co3 O10 Se2', 'Cu3 P1 S2 Se2', 'C2 Cr3', 'Cs1 Fe2 O16 P5', 'H30.72 Al16 K0.46 Na15.62 O95.36 Si24', 'N1 Na5 O4 W1', 'Cu2.772 O7.36 Re0.136 Sr2 Y1', 'B1 Cl11.47 I1.53 Zr6', 'Ge1 Mn1 Tb1', 'Ag1 Li1', 'Br4 Po1', 'Ca1 O4 Se1', 'B1 Nd3 O9 W1', 'Ce1 Ni4.95 Sn1.05', 'Cu0.94 La1.61 O4 Sr0.39 Ti0.06', 'Mn1 O2 Rb0.27', 'Ba1.3 Ce1 Cu3 Eu1 O9 Pb1 Sr0.7', 'Al3 B4 Er0.12 O12 Y0.88', 'H36 N4 Na2 O38 V10', 'Ce0.666 Mo0.999 O3.996', 'Gd1 Ge2 Ru2', 'La1 Ni9 Y2', 'B8 Ru18.95 Ti10.05', 'Ge1 Mn2 Si1 Y1', 'In2 Ni9 Y1', 'H10 Na2 O12 P2 Zn1', 'Pr6 Sb14.7 Zn1.22', 'B1 Fe14 Th2', 'Cl1 Mo1 Nd1 O4', 'Au1 Cs1.83 O1 Rb1.17', 'Mn0.5 Sn0.5 Te1', ' Ag0.004 Bi0.004 Ca0.03 K0.456 Na0.492 Nb0.896 O3 Sb0.064 Zr0.038', 'Nb1.8 Si1 V1.2', 'H10 Ag2 B10', 'Fe1 Gd0.333 O2.96 Sr0.667', 'Eu1 Se2 Sm1', 'B0.75 Ru3 U1', 'O7 Ru2 Sm2', 'Co0.5 Ge1 La3 S7', 'Al0.33 Cs1 O6 W1.67', 'Cs7.71 Ga7.02 Si38.98', 'Co2 K2 O9 Se3', 'Ga1 La1 Pt1', 'Al0.1 La1 Ni0.9 O3.042', 'Al2 Ba7 O19 Sc6', 'La0.5 Mg0.25 O3 Sr0.5 Ti0.75', 'Sr1 Zn11', 'Fe1.55 Mn1.06 Na1.49 O12 P3 Zn0.38', 'Al5.3 Ce1 Mn2 Zn14.7', 'Ge6 Na1 Nd9 O26', 'Co0.143 O3 Rh0.857', 'Ag2 As1 Cs1 S3', 'O7.75 W0.75 Yb2 Zr1.25', 'Cu2.143 Li0.06 Mg0.797 O3', 'Ag0.91 Pt0.09', 'Fe1 O3 S1', 'O13 P2 Pb8', 'Al0.75 Fe0.25 Na1 O2', 'B1.5 Ir1', 'H8 O10 Sr1 V2', 'Ba1 Cr8 Ni2 O15', 'Be15 Cu8 Hf6', 'Ba2 Fe1 Mo0.8 Nb0.2 O6', 'Cu1 Eu1 Si3', 'Al2 Ca0.4 Yb0.6', 'B3 Co7 Gd2', 'K2 Mo2 O11 P2', 'B2 Ta0.5 Zr0.5', 'Dy4 Ga12 Ni1', 'B2 Cd1 O5 Sr1', 'C14 H34 N6 O9 Pd1.5 S4 Tb1', 'Nb1 Nd2 O7 Sc1', 'Fe4 Rb8 S10', 'Ag1 Mo3 O14 P2', 'Ce4 Mg1.027 Os0.973', 'Mn0.5 Nb0.5 O2.875 Sr1', 'Ba0.9 K0.1 S2.888 V1', 'Cd1 Nd1 O7 Sb1 Ti1', 'B1 Pd2', 'Mo1 S1.5 Te0.5', 'Ba1 Pr2 Se4', 'B2 Ni13 Sm3', 'C4 H24 I10 N6 Pb3', 'H4 Br6 Cu2 O4 Pb4', 'H3 O5 P1 Zn1', 'C8 H24 Cu2 N20', 'Nd1 Se1.9', 'Co0.1 Cr2 Cu0.9 Se4', 'Cu2 S3.2 Se0.8 Sn1 Zn1', 'Mo0.4 O3 V1.6', 'Al1.97 Fe0.03 Mn3 O12 Si2.61', 'Cs1 O12 Te2 V3', 'Cs2 Hg1 Se8 Sn3', 'Ca1 Ge1 O5 Ti0.114 Zr0.885', 'Bi1 Pd1 Te1', 'Eu0.02 F3 K1 Mg0.98', 'S7 Ti5.5', 'Be3 Cu1', 'Al1.6 Ga0.4 La1 Pd2', 'Cr1 Cu2 O8 Sr2 Y1', 'H8 Co3 F4 N2 O12 P4', 'Ba2 Ce2 O13 Si4', 'As3 W2', 'Mg0.96 Pb0.04', 'H8 B12 F12 K1 Li1 O4', 'Ga2 Se2 Te1', 'Co1.26 Mn0.74 Zr1', 'N2 Nd1 Th1', 'Cr0.8 K2 Mo1.2 O8 Pb1', 'Mn1 O3 Sm0.75 Sr0.25', 'H8 Ba2 O8 Pt1', 'Er3 Ga2 Ge1 Mn3', 'Cs1 Cu1 Gd2 Te4', 'Ca0.6 O3 Sm0.26 Ti1', 'Fe1.02 Li0.95 O4 P1')]\n"
     ]
    }
   ],
   "source": [
    "for batch in trainloader:\n",
    "    print(batch)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3fb4bb-9f09-4542-b4e0-77c76f6c673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'train_path': 'data/crabnet_data/train.csv',\n",
    "            'val_path': 'data/crabnet_data/val.csv',\n",
    "            'test_path':'data/crabnet_data/test.csv',\n",
    "            'out_dims': 3,\n",
    "            'd_model': 512,\n",
    "            'N': 3,\n",
    "            'heads': 4,\n",
    "            'classification': True,\n",
    "            'batch_size': 2**12,\n",
    "            'fudge': 0,\n",
    "            'random_seed': 42,\n",
    "            'swa_epoch_start' : 0.05,\n",
    "            'swa_lrs': 1e-2,\n",
    "            'base_lr': 1e-4,\n",
    "            'max_lr': 6e-3,\n",
    "            'schedule': 'CyclicLR',\n",
    "            'patience': 10,\n",
    "            'num_workers' : 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a48e1a5-145f-4484-9366-aa706f56f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('crabnet/crabnet_config.json','w') as f:\n",
    "    json.dump(config,f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c77df7-dcaf-470c-93cc-23a8060a85e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15299087-ee3c-42d7-9591-32fd3e14f6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b47ce2-dc55-40c5-a70b-196c119cd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='data/general_disorder.csv'\n",
    "df=pd.read_csv('data/general_disorder.csv',usecols=['formula', 'disorder'])\n",
    "df=df.rename(columns={'disorder':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5024a330-eaec-4679-8816-f0137771c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.linspace(0,len(df)-1,len(df),dtype=int)\n",
    "train_idx,test_idx= train_test_split(index, test_size=0.2, random_state=42)\n",
    "train_idx,val_idx= train_test_split(train_idx, test_size=0.1, random_state=42)\n",
    "val_set = df.iloc[val_idx]\n",
    "val_set.to_csv('data/crabnet_data/val.csv',index=False)\n",
    "test_set = df.iloc[test_idx]\n",
    "test_set.to_csv('data/crabnet_data/test.csv',index=False)\n",
    "train_set = df.iloc[train_idx]\n",
    "train_set.to_csv('data/crabnet_data/train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9be35ec-5c91-45ad-afd4-68d4445bac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=''\n",
    "config={'train_path': path+'data/crabnet_data/train.csv',\n",
    "            'val_path': path+'data/crabnet_data/val.csv',\n",
    "            'test_path': path+'data/crabnet_data/test.csv',\n",
    "            'out_dims': 3,\n",
    "            'd_model': 512,\n",
    "            'N': 3,\n",
    "            'heads': 4,\n",
    "            'classification': True,\n",
    "            'batch_size': 2**12,\n",
    "            'fudge': 0,\n",
    "            'random_seed': 42,\n",
    "            'swa_epoch_start' : 0.05,\n",
    "            'swa_lrs': 1e-2,\n",
    "            'base_lr': 1e-4,\n",
    "            'max_lr': 6e-3,\n",
    "            'schedule': 'CyclicLR',\n",
    "            'patience': 10,\n",
    "            'num_workers' : 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d960351-c043-41ad-a072-a265f12265f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1e03a0-ac38-467e-bb1b-d53fea9860fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = CrabNetLightning(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c196248f-1d74-4ef9-a184-433d0b4f00f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1,accelerator='gpu', devices=1,\n",
    "                      callbacks=[StochasticWeightAveraging(swa_epoch_start=config['swa_epoch_start'],swa_lrs=config['swa_lrs']),\n",
    "                                EarlyStopping(monitor='val_loss', patience=config['patience']), ModelCheckpoint(monitor='val_acc', mode=\"max\", \n",
    "                                dirpath=path+'crabnet_models/trained_models/', filename='disorder-{epoch:02d}-{val_acc:.2f}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1503c1fc-bbba-4f4a-a49d-ab23430df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_data = CrabNetDataModule(config['train_path'],\n",
    "                                   config['val_path'],\n",
    "                                   config['test_path'],\n",
    "                                   classification = config['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764bcf6b-1fe2-4b08-92a9-0337a6675742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 235357.34formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 230421.06formulae/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 230603.14formulae/s]\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | CrabNet | 12.0 M | train\n",
      "------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "23.8 K    Non-trainable params\n",
      "12.0 M    Total params\n",
      "48.044    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ef6444f34e44a3b0e6099a8591e8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Swapping scheduler `CyclicLR` for `SWALR`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=disorder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45acb356-cc37-472c-b7af-86ea8b33fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 232381.28formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 247921.00formulae/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 246702.89formulae/s]\n",
      "Restoring states from the checkpoint path at /Users/elenapatyukova/Documents/GitHub/Disorder-prediction-new/crabnet_models/trained_models/disorder-epoch=00-val_acc=0.61.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/elenapatyukova/Documents/GitHub/Disorder-prediction-new/crabnet_models/trained_models/disorder-epoch=00-val_acc=0.61.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dd988c25a04f6d8b804bb037530dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.6029446721076965\n",
      "      test_f1_epoch         0.7522377967834473\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc_epoch': 0.6029446721076965, 'test_f1_epoch': 0.7522377967834473}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(ckpt_path='best',datamodule=disorder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ce733a-08cc-4835-8592-890b7802ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 235414.16formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 239556.39formulae/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 242176.67formulae/s]\n",
      "Restoring states from the checkpoint path at /Users/elenapatyukova/Documents/GitHub/Disorder-prediction-new/crabnet_models/trained_models/disorder-epoch=00-val_acc=0.61.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/elenapatyukova/Documents/GitHub/Disorder-prediction-new/crabnet_models/trained_models/disorder-epoch=00-val_acc=0.61.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenapatyukova/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ab9bfda7d2405fb86bb50b19db96a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(ckpt_path='best',datamodule=disorder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6ad6d-e9d3-4348-9047-23f5fd9fcb7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/pyplot.py:3236\u001b[0m, in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mhist)\n\u001b[1;32m   3212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhist\u001b[39m(\n\u001b[1;32m   3213\u001b[0m     x: ArrayLike \u001b[38;5;241m|\u001b[39m Sequence[ArrayLike],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3234\u001b[0m     BarContainer \u001b[38;5;241m|\u001b[39m Polygon \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[BarContainer \u001b[38;5;241m|\u001b[39m Polygon],\n\u001b[1;32m   3235\u001b[0m ]:\n\u001b[0;32m-> 3236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3239\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdensity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcumulative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcumulative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhisttype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhisttype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3246\u001b[0m \u001b[43m        \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/axes/_axes.py:6922\u001b[0m, in \u001b[0;36mAxes.hist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6921\u001b[0m     height \u001b[38;5;241m=\u001b[39m top\n\u001b[0;32m-> 6922\u001b[0m bars \u001b[38;5;241m=\u001b[39m \u001b[43m_barfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mboffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6923\u001b[0m \u001b[43m                \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcenter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6924\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mbottom_kwarg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6925\u001b[0m patches\u001b[38;5;241m.\u001b[39mappend(bars)\n\u001b[1;32m   6926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stacked:\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/axes/_axes.py:2524\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(left, bottom, width, height, color, edgecolor, linewidth,\n\u001b[1;32m   2522\u001b[0m            hatch, patch_labels)\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[0;32m-> 2524\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRectangle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlbl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2532\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[1;32m   2533\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/patches.py:718\u001b[0m, in \u001b[0;36mRectangle.__init__\u001b[0;34m(self, xy, width, height, angle, rotation_point, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, width, height, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    696\u001b[0m              angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, rotation_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m        %(Patch:kwdoc)s\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/patches.py:95\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_hatch(hatch)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_capstyle(capstyle)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_joinstyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoinstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/patches.py:485\u001b[0m, in \u001b[0;36mPatch.set_joinstyle\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39minterpd\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_joinstyle\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m    475\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    Set the `.JoinStyle`.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    s : `.JoinStyle` or %(JoinStyle)s\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m     js \u001b[38;5;241m=\u001b[39m \u001b[43mJoinStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joinstyle \u001b[38;5;241m=\u001b[39m js\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/enum.py:714\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start, boundary)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[1;32m    717\u001b[0m         value,\n\u001b[1;32m    718\u001b[0m         names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m         boundary\u001b[38;5;241m=\u001b[39mboundary,\n\u001b[1;32m    724\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/enum.py:1095\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEnum\u001b[39;00m(metaclass\u001b[38;5;241m=\u001b[39mEnumType):\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    Create a collection of name/value pairs.\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    attributes -- see the documentation for details.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;66;03m# all enum instances are actually created during class construction\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;66;03m# without calling this method; this method is called by the metaclass'\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;66;03m# __call__ (i.e. Color(3) ), and by pickle\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(value) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[1;32m   1100\u001b[0m             \u001b[38;5;66;03m# For lookups like Color(Color.RED)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x15d89e3e0> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/pyplot.py:197\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[0;32m--> 197\u001b[0m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/backend_bases.py:1893\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1893\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3154\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/axes/_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3070\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/patches.py:585\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    584\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path()\n\u001b[0;32m--> 585\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    587\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/patches.py:261\u001b[0m, in \u001b[0;36mPatch.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the `~.transforms.Transform` applied to the `Patch`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_patch_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43martist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/transforms.py:1347\u001b[0m, in \u001b[0;36mTransform.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03m    Compose two transforms together so that *self* is followed by *other*.\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    ``A + B`` returns a transform ``C`` so that\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;124;03m    ``C.transform(x) == B.transform(A.transform(x))``.\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mcomposite_transform_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Transform) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m             \u001b[38;5;28mNotImplemented\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/transforms.py:2522\u001b[0m, in \u001b[0;36mcomposite_transform_factory\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Affine2D) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Affine2D):\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CompositeAffine2D(a, b)\n\u001b[0;32m-> 2522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCompositeGenericTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/transforms.py:2366\u001b[0m, in \u001b[0;36mCompositeGenericTransform.__init__\u001b[0;34m(self, a, b, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b \u001b[38;5;241m=\u001b[39m b\n\u001b[0;32m-> 2366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/disorder_pred/lib/python3.11/site-packages/matplotlib/transforms.py:199\u001b[0m, in \u001b[0;36mTransformNode.set_children\u001b[0;34m(self, *children)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Use weak references so this dictionary won't keep obsolete nodes\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# alive; the callback deletes the dictionary entry. This is a\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# performance improvement over using WeakValueDictionary.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m _, pop\u001b[38;5;241m=\u001b[39mchild\u001b[38;5;241m.\u001b[39m_parents\u001b[38;5;241m.\u001b[39mpop, k\u001b[38;5;241m=\u001b[39mid_self: pop(k))\n\u001b[0;32m--> 199\u001b[0m     child\u001b[38;5;241m.\u001b[39m_parents[id_self] \u001b[38;5;241m=\u001b[39m ref\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(pred[0][2],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e6198-91f5-49e7-8170-66deef3f8ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0099245-3aac-4a32-80c5-b5d79633f02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ec9d8-7adb-46f0-9e87-0492286b0ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f1a17-4e0a-4e31-abd2-a89458114105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1101584-0e56-4fa6-9cbc-0b74b9342f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[0.1,0.2,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0986cf9-aa8c-4b19-a8a4-d6afe24d4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crabnet.utils.utils import (Lamb, Lookahead, RobustL1, BCEWithLogitsLoss,\n",
    "                         EDMDataset, get_edm, Scaler, DummyScaler, count_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0f5e40-9cf2-4b98-a6bb-daab6c372cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=Scaler(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47bbc5f8-fee1-4757-bd65-d1b2bce3cc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8006, -0.3203,  1.1209])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c11c2-cb06-40e8-aba2-871884d01788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
