{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatgen.core.composition import Composition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytorch_lightning as L\n",
    "import wandb\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as Dataloader_PIG\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR, StepLR\n",
    "from torch.nn import CrossEntropyLoss, L1Loss, MSELoss, ReLU, NLLLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "from roost.Data import data_from_composition_general\n",
    "from roost.Model import Roost\n",
    "from roost.utils import count_parameters, Scaler, DummyScaler, BCEWithLogitsLoss, Lamb, Lookahead, get_compute_device\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_type_np = np.float32\n",
    "data_type_torch = torch.float32\n",
    "device=get_compute_device()\n",
    "\n",
    "\n",
    "class RoostDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_file: str , \n",
    "                 val_file: str, \n",
    "                 test_file: str, \n",
    "                 batch_size = 256,\n",
    "                 features='onehot',\n",
    "                 predictset='test'):\n",
    "        super().__init__()\n",
    "        self.train_path = train_file\n",
    "        self.val_path = val_file\n",
    "        self.test_path = test_file\n",
    "        self.batch_size = batch_size\n",
    "        self.features=features\n",
    "        self.predictset=predictset\n",
    "\n",
    "    def prepare_data(self):\n",
    "        path='data/el-embeddings/'\n",
    "        if(self.features == 'onehot'):\n",
    "            with open(path+'onehot-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'matscholar'):\n",
    "            with open(path+'matscholar-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'mat2vec'):\n",
    "            with open(path+'mat2vec.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'cgcnn'):\n",
    "            with open(path+'cgcnn-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        \n",
    "        ### loading and encoding trianing data\n",
    "        if(re.search('.json', self.train_path )):\n",
    "            self.data_train=pd.read_json(self.train_path)\n",
    "        elif(re.search('.csv', self.train_path)):\n",
    "            self.data_train=pd.read_csv(self.train_path)\n",
    "\n",
    "        self.train_dataset = data_from_composition_general(self.data_train,elem_features)\n",
    "        self.train_len = len(self.train_dataset)\n",
    "        \n",
    "        ### loading and encoding validation data\n",
    "        if(re.search('.json', self.val_path )):\n",
    "            self.data_val=pd.read_json(self.val_path)\n",
    "        elif(re.search('.csv', self.val_path)):\n",
    "            self.data_val=pd.read_csv(self.val_path)\n",
    "        \n",
    "        self.val_dataset = data_from_composition_general(self.data_val,elem_features)\n",
    "        self.val_len = len(self.val_dataset)\n",
    "\n",
    "        ### loading and encoding testing data\n",
    "        if(re.search('.json', self.test_path )):\n",
    "            self.data_test=pd.read_json(self.test_path)\n",
    "        elif(re.search('.csv', self.test_path)):\n",
    "            self.data_test=pd.read_csv(self.test_path)\n",
    "        \n",
    "        self.test_dataset = data_from_composition_general(self.data_test,elem_features)\n",
    "        self.test_len = len(self.test_dataset)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return Dataloader_PIG(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return Dataloader_PIG(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return Dataloader_PIG(self.test_dataset, batch_size=self.test_len, shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        if(self.predictset=='test'):\n",
    "            return Dataloader_PIG(self.test_dataset, batch_size=self.test_len, shuffle=False)\n",
    "        elif(self.predictset=='val'):\n",
    "            return Dataloader_PIG(self.val_dataset, batch_size=self.val_len, shuffle=False)\n",
    "    \n",
    "\n",
    "class RoostLightningClass(L.LightningModule):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size=config['data_params']['batch_size']\n",
    "        self.out_dims=config['model_params']['output_dim']\n",
    "        self.n_graphs=config['model_params']['n_graphs']\n",
    "        self.comp_heads=config['model_params']['comp_heads']\n",
    "        self.internal_elem_dim=config['model_params']['internal_elem_dim']\n",
    "        self.setup=config['setup_params']\n",
    "        self.model = Roost(**config['model_params'])\n",
    "        self.classification = config['classification']\n",
    "        self.loss_name = config['setup_params']['loss']\n",
    "        # maybe need to do it, to unify Roost and CrabNet\n",
    "        print('\\n Model architecture: out_dims, n_graphs, heads, internal_elem_dim')\n",
    "        print(f'{self.out_dims}, {self.n_graphs}, '\n",
    "                  f'{self.comp_heads}, {self.internal_elem_dim}')\n",
    "        print(f'Model size: {count_parameters(self.model)} parameters\\n')\n",
    "        if(config['classification']==True):\n",
    "            if(config['setup_params']['loss'] == 'BCEWithLogitsLoss'):\n",
    "                self.criterion = BCEWithLogitsLoss\n",
    "            if(config['setup_params']['loss'] == 'CrossEntropyLoss'):\n",
    "                self.criterion = nn.functional.cross_entropy\n",
    "            if(re.search('.json', config['data_params']['train_path'])):\n",
    "                train_data = pd.read_json(config['data_params']['train_path'])\n",
    "            elif(re.search('.csv', config['data_params']['train_path'])):\n",
    "                train_data = pd.read_csv(config['data_params']['train_path'])\n",
    "            y = train_data['disorder'].values\n",
    "            self.step_size = len(y)\n",
    "            if(config['model_params']['output_dim']>1):\n",
    "                classes = np.linspace(0,config['model_params']['output_dim']-1,config['model_params']['output_dim'],dtype=int)\n",
    "            else:\n",
    "                classes=np.array([0,1],dtype=int)\n",
    "            set_classes=set(classes)\n",
    "            y_classes = set(np.unique(y))\n",
    "            if(set_classes.issubset(y_classes)):\n",
    "                self.weight = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=classes, y=y), dtype=data_type_torch).to(device)\n",
    "            else:\n",
    "                self.weight = torch.ones(len(classes), dtype=data_type_torch).to(device)\n",
    "            if(self.loss_name == 'BCEWithLogitsLoss'):\n",
    "                self.weight=self.weight[1]\n",
    "    \n",
    "        elif(config['classification']==False):\n",
    "            self.criterion = L1Loss()\n",
    "            if(re.search('.json', config['data_params']['train_path'] )):\n",
    "                train_data=pd.read_json(config['data_params']['train_path'])\n",
    "            elif(re.search('.csv', config['data_params']['train_path'])):\n",
    "                train_data=pd.read_csv(config['data_params']['train_path'])\n",
    "            y=train_data['disorder'].values\n",
    "            self.step_size = len(y)\n",
    "            self.scaler=Scaler(y)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        out = self.model(batch.x, batch.edge_index, batch.pos, batch.batch)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if(self.setup['optim'] == 'AdamW'):\n",
    "        # We use AdamW optimizer with MultistepLR scheduler as in the original Roost model\n",
    "            optimizer = torch.optim.AdamW(self.parameters(),lr=self.setup['learning_rate'], \n",
    "                                        weight_decay=self.setup['weight_decay']) \n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=self.setup['gamma'])\n",
    "\n",
    "        elif(self.setup['optim'] == 'Lamb'):\n",
    "            base_optim = Lamb(params=self.model.parameters(),lr=0.001)\n",
    "            optimizer = Lookahead(base_optimizer=base_optim)\n",
    "            scheduler = CyclicLR(optimizer,\n",
    "                                base_lr=self.setup['base_lr'],\n",
    "                                max_lr=self.setup['max_lr'],\n",
    "                                cycle_momentum=False,\n",
    "                                step_size_up=self.step_size)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        if(self.classification == True):\n",
    "            if(self.loss_name == 'BCEWithLogitsLoss'):\n",
    "                loss=self.criterion(logits, batch.y,self.weight)\n",
    "                prediction = torch.sigmoid(logits)\n",
    "                y_pred = prediction.detach().cpu().numpy() > 0.5\n",
    "            elif(self.loss_name == 'CrossEntropyLoss'):\n",
    "                loss=self.criterion(logits, batch.y.long(),self.weight)\n",
    "                prediction = torch.nn.functional.softmax(logits,dim=1)\n",
    "                y_pred = torch.argmax(prediction,dim=1).detach().cpu().numpy()\n",
    "            acc=balanced_accuracy_score(batch.y.detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(batch.y.detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(batch.y.detach().cpu().numpy(),y_pred)\n",
    "\n",
    "            self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        elif(self.classification == False):\n",
    "            y=self.scaler.scale(batch.y)\n",
    "            loss=self.criterion(logits, y)\n",
    "            y=self.scaler.unscale(y)\n",
    "            prediction=self.scaler.unscale(logits)\n",
    "\n",
    "            mse = mean_squared_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            mae = mean_absolute_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            self.log(\"train_mse\", mse, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mae\", mae, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        if(self.classification == True):\n",
    "            if(self.loss_name == 'BCEWithLogitsLoss'):\n",
    "                loss=self.criterion(logits, batch.y,self.weight)\n",
    "                prediction = torch.sigmoid(logits)\n",
    "                y_pred = prediction.detach().cpu().numpy() > 0.5\n",
    "            elif(self.loss_name == 'CrossEntropyLoss'):\n",
    "                loss=self.criterion(logits, batch.y.long(),self.weight)\n",
    "                prediction = torch.nn.functional.softmax(logits,dim=1)\n",
    "                y_pred = torch.argmax(prediction,dim=1).detach().cpu().numpy()\n",
    "\n",
    "            acc=balanced_accuracy_score(batch.y.detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(batch.y.detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(batch.y.detach().cpu().numpy(),y_pred)\n",
    "\n",
    "            self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        elif(self.classification == False):\n",
    "            y=self.scaler.scale(batch.y)\n",
    "            loss=self.criterion(logits, y)\n",
    "            y=self.scaler.unscale(y)\n",
    "            prediction=self.scaler.unscale(logits)\n",
    "\n",
    "            mse = mean_squared_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            mae = mean_absolute_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            self.log(\"val_mse\", mse, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mae\", mae, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        if(self.classification == True):\n",
    "            if(self.loss_name == 'BCEWithLogitsLoss'):\n",
    "                loss=self.criterion(logits, batch.y,self.weight)\n",
    "                prediction = torch.sigmoid(logits)\n",
    "                y_pred = prediction.detach().cpu().numpy() > 0.5\n",
    "            elif(self.loss_name == 'CrossEntropyLoss'):\n",
    "                loss=self.criterion(logits, batch.y.long(),self.weight)\n",
    "                prediction = torch.nn.functional.softmax(logits,dim=1)\n",
    "                y_pred = torch.argmax(prediction,dim=1).detach().cpu().numpy()\n",
    "\n",
    "            acc=balanced_accuracy_score(batch.y.detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(batch.y.detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(batch.y.detach().cpu().numpy(),y_pred)\n",
    "\n",
    "            self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "\n",
    "        elif(self.classification == False):\n",
    "            y=self.scaler.scale(batch.y)\n",
    "            loss=self.criterion(logits, y)\n",
    "            y=self.scaler.unscale(y)\n",
    "            prediction=self.scaler.unscale(logits)\n",
    "\n",
    "            mse = mean_squared_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            mae = mean_absolute_error(y.detach().cpu().numpy(), prediction.detach().cpu().numpy())\n",
    "            self.log(\"test_mse\", mse, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mae\", mae, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        logits=self(batch)\n",
    "        if(self.classification == True):\n",
    "            if(self.loss_name == 'BCEWithLogitsLoss'):\n",
    "                prediction = torch.sigmoid(logits)\n",
    "                y_pred = prediction.detach().cpu().numpy() > 0.5\n",
    "            elif(self.loss_name == 'CrossEntropyLoss'):\n",
    "                prediction = torch.nn.functional.softmax(logits,dim=1)\n",
    "                y_pred = torch.argmax(prediction,dim=1).detach().cpu().numpy()\n",
    "            return batch.y.view(-1).detach().cpu().numpy(), prediction, y_pred\n",
    "        elif(self.classification == False):\n",
    "            prediction=self.scaler.unscale(logits)\n",
    "            return batch.y.view(-1).detach().cpu().numpy(), prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n",
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('roost/roost_config.json','r') as f:\n",
    "    config=json.load(f)\n",
    "\n",
    "L.seed_everything(config['seed'])\n",
    "\n",
    "disorder_data = RoostDataModule(config['data_params']['train_path'],\n",
    "                                   config['data_params']['val_path'],\n",
    "                                   config['data_params']['test_path'], features=config['data_params']['embed'])\n",
    "disorder_data.prepare_data()\n",
    "predictloader=disorder_data.predict_dataloader()\n",
    "for x in predictloader:\n",
    "    datalength=len(x.y)\n",
    "\n",
    "prediction_roost=np.zeros((10,datalength))\n",
    "\n",
    "for i in range(10):\n",
    "    name='roost-disorder-'+str(i)\n",
    "    model = RoostLightningClass.load_from_checkpoint('roost_models/roost_trained_models/'+name+'.ckpt')\n",
    "    model.eval()\n",
    "    for x in predictloader:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            pred = torch.sigmoid(logits)\n",
    "            prediction_roost[i,:]=pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_roost=np.mean(prediction,axis=0)\n",
    "y_pred_roost = y_pred_proba_roost > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import pytorch_lightning as L\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score, f1_score, precision_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, matthews_corrcoef, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "# from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from torchmetrics.functional import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from pymatgen.core.composition import Composition\n",
    "from crabnet.kingcrab import CrabNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR, StepLR\n",
    "\n",
    "from crabnet.utils.utils import (Lamb, Lookahead, RobustL1, BCEWithLogitsLoss,\n",
    "                         EDMDataset, get_edm, Scaler, DummyScaler, count_parameters)\n",
    "from crabnet.utils.get_compute_device import get_compute_device\n",
    "# from crabnet.utils.composition import _element_composition, get_sym_dict, parse_formula, CompositionError\n",
    "#from utils.optim import SWA\n",
    "\n",
    "data_type_np = np.float32\n",
    "data_type_torch = torch.float32\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "class CrabNetDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_file: str , \n",
    "                 val_file: str, \n",
    "                 test_file: str,\n",
    "                 n_elements ='infer', \n",
    "                 classification = False,\n",
    "                 elem_prop='mat2vec',\n",
    "                 batch_size = 2**10,\n",
    "                 scale = True,\n",
    "                 pin_memory = True,\n",
    "                 predictset='test'):\n",
    "        super().__init__()\n",
    "        self.train_path = train_file\n",
    "        self.val_path = val_file\n",
    "        self.test_path = test_file\n",
    "        self.batch_size = batch_size\n",
    "        self.n_elements=n_elements\n",
    "        self.pin_memory = pin_memory\n",
    "        self.scale = scale\n",
    "        self.classification = classification\n",
    "        self.elem_prop=elem_prop\n",
    "        self.predictset=predictset\n",
    "\n",
    "    def prepare_data(self):\n",
    "        ### loading and encoding trianing data\n",
    "        if(re.search('.json', self.train_path )):\n",
    "            self.data_train=pd.read_json(self.train_path)\n",
    "        elif(re.search('.csv', self.train_path)):\n",
    "            self.data_train=pd.read_csv(self.train_path)\n",
    "\n",
    "        self.train_main_data = list(get_edm(self.data_train, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=False,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.train_len_data = len(self.train_main_data[0])\n",
    "        self.train_n_elements = self.train_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.train_n_elements:0.0f} '\n",
    "              f'elements in the formula for training')\n",
    "        \n",
    "        ### loading and encoding validation data\n",
    "        if(re.search('.json', self.val_path )):\n",
    "            self.data_val=pd.read_json(self.val_path)\n",
    "        elif(re.search('.csv', self.val_path)):\n",
    "            self.data_val=pd.read_csv(self.val_path)\n",
    "        \n",
    "        self.val_main_data = list(get_edm(self.data_val, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.val_len_data = len(self.val_main_data[0])\n",
    "        self.val_n_elements = self.val_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.val_n_elements:0.0f} '\n",
    "              f'elements in the formula for validation')\n",
    "        \n",
    "        ### loading and encoding testing data\n",
    "        if(re.search('.json', self.test_path )):\n",
    "            self.data_test=pd.read_json(self.test_path)\n",
    "        elif(re.search('.csv', self.test_path)):\n",
    "            self.data_test=pd.read_csv(self.test_path)\n",
    "        \n",
    "        self.test_main_data = list(get_edm(self.data_test, elem_prop=self.elem_prop,\n",
    "                                      n_elements=self.n_elements,\n",
    "                                      inference=True,\n",
    "                                      verbose=True,\n",
    "                                      drop_unary=False,\n",
    "                                      scale=self.scale))\n",
    "        \n",
    "        self.test_len_data = len(self.test_main_data[0])\n",
    "        self.test_n_elements = self.test_main_data[0].shape[1]//2\n",
    "\n",
    "        print(f'loading data with up to {self.test_n_elements:0.0f} '\n",
    "              f'elements in the formula for testing')\n",
    "\n",
    "        self.train_dataset = EDMDataset(self.train_main_data, self.train_n_elements)\n",
    "        self.val_dataset = EDMDataset(self.val_main_data, self.val_n_elements)\n",
    "        self.test_dataset = EDMDataset(self.test_main_data, self.test_n_elements)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory, shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "    def predict_dataloader(self):\n",
    "        if(self.predictset=='test'):\n",
    "            return DataLoader(self.test_dataset, batch_size=self.test_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "        elif(self.predictset=='val'):\n",
    "            return DataLoader(self.val_dataset, batch_size=self.val_len_data,\n",
    "                        pin_memory=self.pin_memory, shuffle=False)\n",
    "\n",
    "\n",
    "class CrabNetLightning(L.LightningModule):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = CrabNet(out_dims=config['out_dims'],\n",
    "                             d_model=config['d_model'],\n",
    "                             N=config['N'],\n",
    "                             heads=config['heads'])\n",
    "        print('\\nModel architecture: out_dims, d_model, N, heads')\n",
    "        print(f'{self.model.out_dims}, {self.model.d_model}, '\n",
    "                  f'{self.model.N}, {self.model.heads}')\n",
    "        print(f'Model size: {count_parameters(self.model)} parameters\\n')\n",
    "\n",
    "        ### here we define some important parameters\n",
    "        self.fudge=config['fudge']\n",
    "        self.batch_size=config['batch_size']\n",
    "        self.classification = config['classification']\n",
    "        self.base_lr=config['base_lr']\n",
    "        self.max_lr=config['max_lr']\n",
    "        ### here we also need to initialise scaler based on training data\n",
    "        if(re.search('.json', config['train_path'] )):\n",
    "            train_data=pd.read_json(config['train_path'])\n",
    "        elif(re.search('.csv', config['train_path'])):\n",
    "            train_data=pd.read_csv(config['train_path'])\n",
    "        \n",
    "        y=train_data['target'].values\n",
    "        self.step_size = len(y)\n",
    "        if self.classification:\n",
    "            self.scaler = DummyScaler(y)\n",
    "        else:\n",
    "            self.scaler = Scaler(y)\n",
    "        ### we also define loss function based on task\n",
    "        if self.classification:\n",
    "            if(np.sum(y)>0):\n",
    "                self.weight=torch.tensor(((len(y)-np.sum(y))/np.sum(y))).cuda()\n",
    "            print(\"Using BCE loss for classification task\")\n",
    "            self.criterion = BCEWithLogitsLoss\n",
    "        else:\n",
    "            print(\"Using RobustL1 loss for regression task\")\n",
    "            self.criterion = RobustL1\n",
    "\n",
    "    def forward(self, src, frac):\n",
    "        out=self.model(src, frac)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        base_optim = Lamb(params=self.model.parameters(),lr=0.001)\n",
    "        optimizer = Lookahead(base_optimizer=base_optim)\n",
    "        lr_scheduler = CyclicLR(optimizer,\n",
    "                                base_lr=self.base_lr,\n",
    "                                max_lr=self.max_lr,\n",
    "                                cycle_momentum=False,\n",
    "                                step_size_up=self.step_size)\n",
    "        # lr_scheduler=StepLR(optimizer,\n",
    "        #                     step_size=3,\n",
    "        #                     gamma=0.5)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"train_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"train_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        val_loss = self.criterion(prediction.view(-1),\n",
    "                              uncertainty.view(-1),\n",
    "                              y.view(-1), self.weight)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"val_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"val_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return val_loss\n",
    "     \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "            y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "            acc=balanced_accuracy_score(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            f1=f1_score(y.view(-1).detach().cpu().numpy(),y_pred,average='weighted')\n",
    "            mc=matthews_corrcoef(y.view(-1).detach().cpu().numpy(),y_pred)\n",
    "            \n",
    "            self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            mse = mean_squared_error(prediction.view(-1),y.view(-1))\n",
    "            mae = mean_absolute_error(prediction.view(-1),y.view(-1))\n",
    "            self.log(\"test_mse\", mse, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "            self.log(\"test_mae\", mae, on_step=True, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        X, y, formula = batch\n",
    "        y = self.scaler.scale(y)\n",
    "        src, frac = X.squeeze(-1).chunk(2, dim=1)\n",
    "        frac = frac * (1 + (torch.randn_like(frac))*self.fudge)\n",
    "        frac = torch.clamp(frac, 0, 1)\n",
    "        frac[src == 0] = 0\n",
    "        frac = frac / frac.sum(dim=1).unsqueeze(1).repeat(1, frac.shape[-1])\n",
    "        \n",
    "        output = self(src, frac)\n",
    "        prediction, uncertainty = output.chunk(2, dim=-1)\n",
    "        uncertainty = torch.exp(uncertainty) * self.scaler.std\n",
    "        prediction = self.scaler.unscale(prediction)\n",
    "        if self.classification:\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "        return formula, prediction, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 212224.18formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203327.11formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 200383.38formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 206773.62formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203323.57formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 204312.32formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc66766b6fa44b76990c63adbc793cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 208678.35formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203324.75formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 202447.70formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d86305fdf1040f9a3b63797537c3c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 210636.95formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203452.41formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 201937.43formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffcffa30030448c98ebd4c1febaee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 208754.84formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203318.84formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 204312.32formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a09a0f9c394d0e8025371c6ca83b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 207226.53formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 202559.82formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 203694.40formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d6d6af6333462f966249540ec2131d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 209447.29formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203327.11formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 202325.97formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bf4e45b4f34ffcbd016f0f3a8afc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 209748.72formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203317.66formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 202319.89formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e85ce17ba243b4bcb7db71650b8f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 209550.83formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 198476.00formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 204305.16formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe4eb89c7d0409ca7073dc28982fab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 202207.84formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203321.21formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 165792.10formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29454de7b6914f00bfe63266e523d23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 201664.44formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 193861.71formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 202318.02formulae/s]\n",
      "c:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6b9acce24143bd873223b2a22d8e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('crabnet/crabnet_config.json','r') as f:\n",
    "        config=json.load(f)\n",
    "disorder_data = CrabNetDataModule(config['train_path'],\n",
    "                                   config['val_path'],\n",
    "                                   config['test_path'],\n",
    "                                   classification = config['classification'])\n",
    "disorder_data.prepare_data()\n",
    "predictloader=disorder_data.predict_dataloader()\n",
    "for x in predictloader:\n",
    "    _,y_true,_=x\n",
    "    datalength=len(y_true)\n",
    "\n",
    "prediction_crabnet=np.zeros((10,datalength))\n",
    "\n",
    "for i in range(10):\n",
    "    name='crabnet-disorder-'+str(i)\n",
    "    model = CrabNetLightning.load_from_checkpoint('crabnet_models/crabnet_trained_models/'+name+'.ckpt')\n",
    "    trainer = Trainer()\n",
    "    formula, prediction, uncertainty=trainer.predict(model=model,datamodule=disorder_data)[0]\n",
    "    prediction_crabnet[i,:]=prediction.detach().cpu().numpy()[:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_roost=np.mean(prediction_roost,axis=0)\n",
    "y_pred_roost = y_pred_proba_roost > 0.5\n",
    "y_pred_proba_crabnet=np.mean(prediction_crabnet,axis=0)\n",
    "y_pred_crabnet = y_pred_proba_crabnet > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9141226702028342, 0.8615996055104127)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true,y_pred_crabnet), balanced_accuracy_score(y_true,y_pred_roost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9106009640325206, 0.857484201453588)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true,y_pred_crabnet,average='weighted'),f1_score(y_true,y_pred_roost,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9536934950385888, 0.9185457087921692)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true,y_pred_crabnet),precision_score(y_true,y_pred_roost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8941634860050891, 0.8357188295165394)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true,y_pred_crabnet),recall_score(y_true,y_pred_roost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8175099004702066, 0.7110756087614373)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_true,y_pred_crabnet),matthews_corrcoef(y_true,y_pred_roost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9662498129926128, 0.9327792442689724)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true,y_pred_proba_crabnet),roc_auc_score(y_true,y_pred_proba_roost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matminer.featurizers.composition import ElementProperty, Stoichiometry \n",
    "from matminer.featurizers.composition import ValenceOrbital, IonProperty, AtomicOrbitals\n",
    "from matplotlib import pyplot as plt\n",
    "from matminer.datasets import load_dataset\n",
    "from matminer.featurizers.base import MultipleFeaturizer\n",
    "\n",
    "from matminer.featurizers.conversions import DictToObject, StrToComposition\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from pymatgen.core.composition import Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('data/roost_data/train.csv',usecols=['formula', 'disorder'])\n",
    "df_val=pd.read_csv('data/roost_data/val.csv',usecols=['formula', 'disorder'])\n",
    "df_test=pd.read_csv('data/roost_data/test.csv',usecols=['formula', 'disorder'])\n",
    "df_train['composition']=[Composition(df_train.iloc[i]['formula']).fractional_composition for i in range(len(df_train))]\n",
    "df_val['composition']=[Composition(df_val.iloc[i]['formula']).fractional_composition for i in range(len(df_val))]\n",
    "df_test['composition']=[Composition(df_test.iloc[i]['formula']).fractional_composition for i in range(len(df_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pymatgen\\core\\periodic_table.py:212: UserWarning: No electronegativity for Ar. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "featurizer = MultipleFeaturizer([\n",
    "    ElementProperty.from_preset('magpie'),\n",
    "    Stoichiometry(),\n",
    "    ValenceOrbital()\n",
    "])\n",
    "flen=len(featurizer.featurize(df_train['composition'][0]))\n",
    "features_train=np.zeros((len(df_train),flen))\n",
    "features_val=np.zeros((len(df_val),flen))\n",
    "features_test=np.zeros((len(df_test),flen))\n",
    "for i,comp in enumerate(df_train['composition']):\n",
    "    features_train[i,:]=featurizer.featurize(comp)\n",
    "features_train=np.nan_to_num(features_train, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "for i,comp in enumerate(df_val['composition']):\n",
    "    features_val[i,:]=featurizer.featurize(comp)\n",
    "features_val=np.nan_to_num(features_val, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "for i,comp in enumerate(df_test['composition']):\n",
    "    features_test[i,:]=featurizer.featurize(comp)\n",
    "features_test=np.nan_to_num(features_test, copy=True, nan=0.0, posinf=None, neginf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=df_train['disorder'].values\n",
    "yval=df_val['disorder'].values\n",
    "ytest=df_test['disorder'].values\n",
    "Xtrain=features_train\n",
    "Xval=features_val\n",
    "Xtest=features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(Xtrain,ytrain)\n",
    "yproba_rf_val=RF.predict_proba(Xval)[:,1]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "Xtrain_normalized = preprocessing.normalize(Xtrain, norm='l2')\n",
    "Xval_normalized = preprocessing.normalize(Xval, norm='l2')\n",
    "Xtest_normalized = preprocessing.normalize(Xtest, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "NN=KNeighborsClassifier(n_neighbors=3)\n",
    "NN.fit(Xtrain_scaled,ytrain)\n",
    "yproba_nn_val=NN.predict_proba(Xval_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_nn_test=NN.predict(Xtest_scaled)\n",
    "yproba_nn_test=NN.predict_proba(Xtest_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882624314216647"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(ytest,ypred_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834764631043257"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,ypred_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307351428345335"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,ypred_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327450124935549"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,ypred_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5772612523236575"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(ytest,ypred_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576735495753127"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest,yproba_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 29\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 216219.40formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 210027.32formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 212653.34formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 217469.30formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 203327.11formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 214842.41formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811ece7f300c450bb4fcaf223108e56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('crabnet/crabnet_config.json','r') as f:\n",
    "    config_crabnet=json.load(f)\n",
    "\n",
    "L.seed_everything(config_crabnet['random_seed'])\n",
    "\n",
    "disorder_data_crabnet = CrabNetDataModule(config_crabnet['train_path'],\n",
    "                                   config_crabnet['val_path'],\n",
    "                                   config_crabnet['test_path'],\n",
    "                                   classification = config_crabnet['classification'],predictset='val')\n",
    "disorder_data_crabnet.prepare_data()\n",
    "valloader=disorder_data_crabnet.predict_dataloader()\n",
    "for x in valloader:\n",
    "    _,y_true,_=x\n",
    "    datalength=len(y_true)\n",
    "\n",
    "for i in range(1):\n",
    "    name='crabnet-disorder-'+str(i)\n",
    "    model_crabnet = CrabNetLightning.load_from_checkpoint('crabnet_models/crabnet_trained_models/'+name+'.ckpt')\n",
    "    trainer = Trainer()\n",
    "    formula, prediction, uncertainty=trainer.predict(model=model_crabnet,datamodule=disorder_data_crabnet)[0]\n",
    "    yproba_crabnet_val=prediction.detach().cpu().numpy()[:,0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('roost/roost_config.json','r') as f:\n",
    "    config_roost=json.load(f)\n",
    "\n",
    "disorder_data_roost = RoostDataModule(config_roost['data_params']['train_path'],\n",
    "                                   config_roost['data_params']['val_path'],\n",
    "                                   config_roost['data_params']['test_path'], features=config_roost['data_params']['embed'],predictset='val')\n",
    "disorder_data_roost.prepare_data()\n",
    "valloader=disorder_data_roost.predict_dataloader()\n",
    "\n",
    "for i in range(1):\n",
    "    name='roost-disorder-'+str(i)\n",
    "    model_roost = RoostLightningClass.load_from_checkpoint('roost_models/roost_trained_models/'+name+'.ckpt')\n",
    "    model_roost.eval()\n",
    "    for x in valloader:\n",
    "        with torch.no_grad():\n",
    "            logits = model_roost(x)\n",
    "            yproba_roost_val = torch.sigmoid(logits).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((yproba_rf_val,yproba_nn_val, yproba_roost_val,yproba_crabnet_val), axis=1)\n",
    "yval=y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_model=LogisticRegression()\n",
    "meta_model.fit(X,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083173537871524"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model.score(X,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba_rf_test=RF.predict_proba(Xtest)[:,1] \n",
    "yproba_nn_test=NN.predict_proba(Xtest_scaled)[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 213636.51formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 213757.74formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 213737.05formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture: out_dims, d_model, N, heads\n",
      "3, 512, 3, 4\n",
      "Model size: 11987206 parameters\n",
      "\n",
      "Using BCE loss for classification task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Generating EDM: 100%|██████████| 75091/75091 [00:00<00:00, 216064.25formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 8344/8344 [00:00<00:00, 208408.90formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 20859/20859 [00:00<00:00, 209440.08formulae/s]\n",
      "C:\\Users\\patykova\\.conda\\envs\\roost\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data with up to 16 elements in the formula for testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762ed168e09e4e95a75281508092cde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('crabnet/crabnet_config.json','r') as f:\n",
    "    config_crabnet=json.load(f)\n",
    "\n",
    "disorder_data_crabnet = CrabNetDataModule(config_crabnet['train_path'],\n",
    "                                   config_crabnet['val_path'],\n",
    "                                   config_crabnet['test_path'],\n",
    "                                   classification = config_crabnet['classification'],predictset='test')\n",
    "disorder_data_crabnet.prepare_data()\n",
    "testloader=disorder_data_crabnet.predict_dataloader()\n",
    "for x in testloader:\n",
    "    _,y_true_test,_=x\n",
    "\n",
    "for i in range(1):\n",
    "    name='crabnet-disorder-'+str(i)\n",
    "    model_crabnet = CrabNetLightning.load_from_checkpoint('crabnet_models/crabnet_trained_models/'+name+'.ckpt')\n",
    "    trainer = Trainer()\n",
    "    formula, prediction, uncertainty=trainer.predict(model=model_crabnet,datamodule=disorder_data_crabnet)[0]\n",
    "    yproba_crabnet_test=prediction.detach().cpu().numpy()[:,0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2426169 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('roost/roost_config.json','r') as f:\n",
    "    config_roost=json.load(f)\n",
    "\n",
    "disorder_data_roost = RoostDataModule(config_roost['data_params']['train_path'],\n",
    "                                   config_roost['data_params']['val_path'],\n",
    "                                   config_roost['data_params']['test_path'], features=config_roost['data_params']['embed'],predictset='test')\n",
    "disorder_data_roost.prepare_data()\n",
    "testloader=disorder_data_roost.predict_dataloader()\n",
    "\n",
    "for i in range(1):\n",
    "    name='roost-disorder-'+str(i)\n",
    "    model_roost = RoostLightningClass.load_from_checkpoint('roost_models/roost_trained_models/'+name+'.ckpt')\n",
    "    model_roost.eval()\n",
    "    for x in testloader:\n",
    "        with torch.no_grad():\n",
    "            logits = model_roost(x)\n",
    "            yproba_roost_test = torch.sigmoid(logits).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056522364447002"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.stack((yproba_rf_test, yproba_nn_test, yproba_roost_test,yproba_crabnet_test), axis=1)\n",
    "meta_model.score(XX,y_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba=meta_model.predict_proba(XX)[:,1]\n",
    "y_pred=yproba>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9041167045903824"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115776081424937"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305194805194805"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042536356772831"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_true_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609318816184103"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true_test,yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_proba_crabnet,bins=50,range=(0,1), alpha=0.5)\n",
    "plt.hist(y_pred_proba_roost,bins=50,range=(0,1), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.abs(y_pred_proba_roost-y_pred_proba_crabnet),bins=50,range=(0,1), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.880675008389664"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_roost,y_pred_crabnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['formula']=formula\n",
    "df['label']=y_true\n",
    "df['crabnet']=y_pred_proba_crabnet\n",
    "df['roost']=y_pred_proba_roost\n",
    "df['crabnet_label']=y_pred_crabnet.astype(int)\n",
    "df['roost_label']=y_pred_roost.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>label</th>\n",
       "      <th>crabnet</th>\n",
       "      <th>roost</th>\n",
       "      <th>crabnet_label</th>\n",
       "      <th>roost_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Al6 Au2.25 Eu2 Si2.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996719</td>\n",
       "      <td>0.323088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>In11.76 Na7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752937</td>\n",
       "      <td>0.482390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ni2 Pr0.945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997669</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ni1 Pd1 Si2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.359713</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Mn1 Nb2 O8 Zn2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141470</td>\n",
       "      <td>0.625605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20819</th>\n",
       "      <td>Ba3 O15 Ta5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109092</td>\n",
       "      <td>0.584031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20822</th>\n",
       "      <td>Dy4 Ni12 Sn25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.972229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20823</th>\n",
       "      <td>Nb4 O0.6 Rb6 S24.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621940</td>\n",
       "      <td>0.116999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20843</th>\n",
       "      <td>H5 Eu2 Rh1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634416</td>\n",
       "      <td>0.385636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20855</th>\n",
       "      <td>Al0.54 Ca1 N3 Si1.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998758</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     formula  label   crabnet     roost  crabnet_label  \\\n",
       "45     Al6 Au2.25 Eu2 Si2.75    1.0  0.996719  0.323088              1   \n",
       "46               In11.76 Na7    1.0  0.752937  0.482390              1   \n",
       "54               Ni2 Pr0.945    1.0  0.997669  0.059760              1   \n",
       "56               Ni1 Pd1 Si2    1.0  0.865808  0.359713              1   \n",
       "59            Mn1 Nb2 O8 Zn2    0.0  0.141470  0.625605              0   \n",
       "...                      ...    ...       ...       ...            ...   \n",
       "20819            Ba3 O15 Ta5    0.0  0.109092  0.584031              0   \n",
       "20822          Dy4 Ni12 Sn25    0.0  0.322993  0.972229              0   \n",
       "20823     Nb4 O0.6 Rb6 S24.4    1.0  0.621940  0.116999              1   \n",
       "20843             H5 Eu2 Rh1    1.0  0.634416  0.385636              1   \n",
       "20855   Al0.54 Ca1 N3 Si1.38    1.0  0.998758  0.421218              1   \n",
       "\n",
       "       roost_label  \n",
       "45               0  \n",
       "46               0  \n",
       "54               0  \n",
       "56               0  \n",
       "59               1  \n",
       "...            ...  \n",
       "20819            1  \n",
       "20822            1  \n",
       "20823            0  \n",
       "20843            0  \n",
       "20855            0  \n",
       "\n",
       "[1805 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da=df.loc[df['label']==df['crabnet_label']]\n",
    "db=da.loc[da['label']!=da['roost_label']]\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>label</th>\n",
       "      <th>crabnet</th>\n",
       "      <th>roost</th>\n",
       "      <th>crabnet_label</th>\n",
       "      <th>roost_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Te2 V1.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899129</td>\n",
       "      <td>0.156443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lu5 Mo2 O12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215111</td>\n",
       "      <td>0.528088</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mo4 O22 P4 Rb3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>0.121034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>H54 Cl4 Co3 N33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320666</td>\n",
       "      <td>0.534450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Cu1 O7 V2 Zn1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.208742</td>\n",
       "      <td>0.640481</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>Cu0.5 Nb1 Se2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>0.862991</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20715</th>\n",
       "      <td>C6 H20 Cl4 Hg1 N2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612588</td>\n",
       "      <td>0.094749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20717</th>\n",
       "      <td>Ba1 Nb0.5 O3 Tb0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341908</td>\n",
       "      <td>0.519833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20730</th>\n",
       "      <td>Pb4 S13 Sb6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.337095</td>\n",
       "      <td>0.720140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20737</th>\n",
       "      <td>Ga3 Ni3 Zr1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266283</td>\n",
       "      <td>0.732672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  formula  label   crabnet     roost  crabnet_label  \\\n",
       "3               Te2 V1.04    0.0  0.899129  0.156443              1   \n",
       "16            Lu5 Mo2 O12    1.0  0.215111  0.528088              0   \n",
       "33         Mo4 O22 P4 Rb3    0.0  0.832558  0.121034              1   \n",
       "44        H54 Cl4 Co3 N33    1.0  0.320666  0.534450              0   \n",
       "75          Cu1 O7 V2 Zn1    1.0  0.208742  0.640481              0   \n",
       "...                   ...    ...       ...       ...            ...   \n",
       "20709       Cu0.5 Nb1 Se2    1.0  0.080588  0.862991              0   \n",
       "20715   C6 H20 Cl4 Hg1 N2    0.0  0.612588  0.094749              1   \n",
       "20717  Ba1 Nb0.5 O3 Tb0.5    1.0  0.341908  0.519833              0   \n",
       "20730         Pb4 S13 Sb6    1.0  0.337095  0.720140              0   \n",
       "20737         Ga3 Ni3 Zr1    1.0  0.266283  0.732672              0   \n",
       "\n",
       "       roost_label  \n",
       "3                0  \n",
       "16               1  \n",
       "33               0  \n",
       "44               1  \n",
       "75               1  \n",
       "...            ...  \n",
       "20709            1  \n",
       "20715            0  \n",
       "20717            1  \n",
       "20730            1  \n",
       "20737            1  \n",
       "\n",
       "[684 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da=df.loc[df['label']==df['roost_label']]\n",
    "dc=da.loc[da['label']!=da['crabnet_label']]\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08653339086245745, 0.03279160074787861)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db)/len(df),len(dc)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11932499161033606"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(db)+len(dc))/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
