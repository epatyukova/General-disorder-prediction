{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e650a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatgen.core.composition import Composition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytorch_lightning as L\n",
    "import wandb\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR, CosineAnnealingLR, StepLR\n",
    "from torch.nn import CrossEntropyLoss, L1Loss, MSELoss, ReLU, NLLLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from roost.Data import data_from_composition_general\n",
    "from roost.Model import Roost\n",
    "from roost.utils import count_parameters, Scaler, DummyScaler, BCEWithLogitsLoss, Lamb, Lookahead, get_compute_device\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_type_np = np.float32\n",
    "data_type_torch = torch.float32\n",
    "device=get_compute_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2074d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b22c575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoostDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_file: str , \n",
    "                 val_file: str, \n",
    "                 test_file: str, \n",
    "                 batch_size = 256,\n",
    "                 features='onehot'):\n",
    "        super().__init__()\n",
    "        self.train_path = train_file\n",
    "        self.val_path = val_file\n",
    "        self.test_path = test_file\n",
    "        self.batch_size = batch_size\n",
    "        self.features=features\n",
    "\n",
    "    def prepare_data(self):\n",
    "        path='data/el-embeddings/'\n",
    "        if(self.features == 'onehot'):\n",
    "            with open(path+'onehot-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'matscholar'):\n",
    "            with open(path+'matscholar-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'mat2vec'):\n",
    "            with open(path+'mat2vec.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        elif(self.features == 'cgcnn'):\n",
    "            with open(path+'cgcnn-embedding.json',\"r\") as f:\n",
    "                elem_features=json.load(f)\n",
    "        \n",
    "        ### loading and encoding trianing data\n",
    "        if(re.search('.json', self.train_path )):\n",
    "            self.data_train=pd.read_json(self.train_path)\n",
    "        elif(re.search('.csv', self.train_path)):\n",
    "            self.data_train=pd.read_csv(self.train_path)\n",
    "\n",
    "        self.train_dataset = data_from_composition_general(self.data_train,elem_features)\n",
    "        self.train_len = len(self.train_dataset)\n",
    "        \n",
    "        ### loading and encoding validation data\n",
    "        if(re.search('.json', self.val_path )):\n",
    "            self.data_val=pd.read_json(self.val_path)\n",
    "        elif(re.search('.csv', self.val_path)):\n",
    "            self.data_val=pd.read_csv(self.val_path)\n",
    "        \n",
    "        self.val_dataset = data_from_composition_general(self.data_val,elem_features)\n",
    "        self.val_len = len(self.val_dataset)\n",
    "\n",
    "        ### loading and encoding testing data\n",
    "        if(re.search('.json', self.test_path )):\n",
    "            self.data_test=pd.read_json(self.test_path)\n",
    "        elif(re.search('.csv', self.test_path)):\n",
    "            self.data_test=pd.read_csv(self.test_path)\n",
    "        \n",
    "        self.test_dataset = data_from_composition_general(self.data_test,elem_features)\n",
    "        self.test_len = len(self.test_dataset)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len, shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.test_len, shuffle=False)\n",
    "    \n",
    "\n",
    "class RoostLightningClass(L.LightningModule):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size=config['data_params']['batch_size']\n",
    "        self.out_dims=config['model_params']['output_dim']\n",
    "        self.n_graphs=config['model_params']['n_graphs']\n",
    "        self.comp_heads=config['model_params']['comp_heads']\n",
    "        self.internal_elem_dim=config['model_params']['internal_elem_dim']\n",
    "        self.setup=config['setup_params']\n",
    "        self.model = Roost(**config['model_params'])\n",
    "        # maybe need to do it, to unify Roost and CrabNet\n",
    "        print('\\n Model architecture: out_dims, n_graphs, heads, internal_elem_dim')\n",
    "        print(f'{self.out_dims}, {self.n_graphs}, '\n",
    "                  f'{self.comp_heads}, {self.internal_elem_dim}')\n",
    "        print(f'Model size: {count_parameters(self.model)} parameters\\n')\n",
    "        \n",
    "        if(config['setup_params']['loss'] == 'BCEWithLogitsLoss'):\n",
    "            self.criterion = BCEWithLogitsLoss\n",
    "\n",
    "        if(re.search('.json', config['data_params']['train_path'] )):\n",
    "            train_data=pd.read_json(config['data_params']['train_path'])\n",
    "        elif(re.search('.csv', config['data_params']['train_path'])):\n",
    "            train_data=pd.read_csv(config['data_params']['train_path'])\n",
    "        y=train_data['disorder'].values\n",
    "        self.step_size = len(y)\n",
    "        if(np.sum(y)>0):\n",
    "            self.weight=torch.tensor(((len(y)-np.sum(y))/np.sum(y)),dtype=data_type_torch).to(device)   \n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = self.model(batch.x, batch.edge_index, batch.pos, batch.batch)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if(self.setup['optim'] == 'AdamW'):\n",
    "        # We use AdamW optimizer with MultistepLR scheduler as in the original Roost model\n",
    "            optimizer = torch.optim.AdamW(self.parameters(),lr=self.setup['learning_rate'], \n",
    "                                        weight_decay=self.setup['weight_decay']) \n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=self.setup['gamma'])\n",
    "\n",
    "        elif(self.setup['optim'] == 'Lamb'):\n",
    "            base_optim = Lamb(params=self.model.parameters(),lr=0.001)\n",
    "            optimizer = Lookahead(base_optimizer=base_optim)\n",
    "            scheduler = CyclicLR(optimizer,\n",
    "                                base_lr=self.setup['base_lr'],\n",
    "                                max_lr=self.setup['max_lr'],\n",
    "                                cycle_momentum=False,\n",
    "                                step_size_up=self.step_size)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        loss=self.criterion(logits, batch.y,self.weight)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        y_pred = prediction.detach().cpu().numpy() > 0.5\n",
    "        acc=balanced_accuracy_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        f1=f1_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        mc=matthews_corrcoef(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"train_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        loss=self.criterion(logits, batch.y,self.weight)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "        acc=balanced_accuracy_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        f1=f1_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        mc=matthews_corrcoef(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits=self(batch)\n",
    "        loss=self.criterion(logits, batch.y,self.weight)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "        acc=balanced_accuracy_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        f1=f1_score(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "        mc=matthews_corrcoef(batch.y.detach().cpu().numpy().astype(bool),y_pred)\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"test_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        self.log(\"test_mc\", mc, on_step=False, on_epoch=True, prog_bar=False, logger=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        logits=self(batch)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        y_pred = prediction.view(-1).detach().cpu().numpy() > 0.5\n",
    "        \n",
    "        return batch.y.view(-1).detach().cpu().numpy(), prediction, y_pred\n",
    "    \n",
    "def main(**config):\n",
    "    L.seed_everything(config['seed'])\n",
    "\n",
    "    data_file = 'data/general_disorder.csv'\n",
    "    df=pd.read_csv(data_file,usecols=['formula', 'disorder'])\n",
    "    index=np.linspace(0,len(df)-1,len(df),dtype=int)\n",
    "    train_idx,test_idx= train_test_split(index, test_size=0.2, random_state=config['seed'])\n",
    "    train_idx,val_idx= train_test_split(train_idx, test_size=0.1, random_state=config['seed'])\n",
    "    val_set = df.iloc[val_idx]\n",
    "    val_set.to_csv('data/roost_data/val.csv',index=False)\n",
    "    test_set = df.iloc[test_idx]\n",
    "    test_set.to_csv('data/roost_data/test.csv',index=False)\n",
    "    train_set = df.iloc[train_idx]\n",
    "    train_set.to_csv('data/roost_data/train.csv',index=False)\n",
    "    \n",
    "    wandb_logger = WandbLogger(project=\"Roost-global-disorder\", config=config, log_model=\"all\")\n",
    "    model = RoostLightningClass(**config)\n",
    "    trainer = Trainer(devices=1, accelerator='gpu',max_epochs=config['epochs'], logger=wandb_logger, \n",
    "                  callbacks=[StochasticWeightAveraging(swa_epoch_start=config['setup_params']['swa_epoch_start'],swa_lrs=config['setup_params']['swa_lrs']),\n",
    "                             ModelCheckpoint(monitor='val_acc', mode='max',dirpath='roost_models/trained_models/', filename='disorder-{epoch:02d}-{val_acc:.2f}'),\n",
    "                             EarlyStopping(monitor='val_loss', mode='max', patience=config['patience']),\n",
    "                             LearningRateMonitor(logging_interval='step')])\n",
    "    disorder_data = RoostDataModule(config['data_params']['train_path'],\n",
    "                                   config['data_params']['val_path'],\n",
    "                                   config['data_params']['test_path'], features=config['data_params']['embed'])\n",
    "    trainer.fit(model, datamodule=disorder_data)\n",
    "    y_true, prediction, y_pred=trainer.predict(ckpt_path='best', datamodule=disorder_data)[0]\n",
    "    metrics={}\n",
    "    metrics['acc']=balanced_accuracy_score(y_true,y_pred)\n",
    "    metrics['f1']=f1_score(y_true,y_pred)\n",
    "    metrics['precision']=precision_score(y_true,y_pred)\n",
    "    metrics['recall']=recall_score(y_true,y_pred)\n",
    "    metrics['mc']=matthews_corrcoef(y_true,y_pred)\n",
    "    metrics['roc_auc']=roc_auc_score(y_true,prediction)\n",
    "    pred_matrix={}\n",
    "    pred_matrix['y_true']=y_true\n",
    "    pred_matrix['y_score']=prediction.detach().numpy()\n",
    "    pred_matrix['y_true']=y_pred\n",
    "   \n",
    "    wandb.log(metrics)\n",
    "    wandb.log(pred_matrix)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abb39391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('roost/roost_config.json','r') as f:\n",
    "    config=json.load(f)\n",
    "path='data/el-embeddings/'\n",
    "if(config['data_params']['embed']=='onehot'):\n",
    "    with open(path+'onehot-embedding.json',\"r\") as f:\n",
    "        elem_features=json.load(f)\n",
    "elif(config['data_params']['embed']=='matscholar'):\n",
    "    with open(path+'matscholar-embedding.json',\"r\") as f:\n",
    "        elem_features=json.load(f)\n",
    "elif(config['data_params']['embed']=='mat2vec'):\n",
    "    with open(path+'mat2vec.json',\"r\") as f:\n",
    "        elem_features=json.load(f)\n",
    "elif(config['data_params']['embed']=='cgcnn'):\n",
    "    with open(path+'cgcnn-embedding.json',\"r\") as f:\n",
    "        elem_features=json.load(f)\n",
    "\n",
    "elem_emb_len=len(elem_features['H'])\n",
    "config['model_params']['input_dim']=elem_emb_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7812e971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optim': 'AdamW',\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 1e-06,\n",
       " 'momentum': 0.9,\n",
       " 'loss': 'BCEWithLogitsLoss',\n",
       " 'base_lr': 0.001,\n",
       " 'max_lr': 0.006,\n",
       " 'swa_epoch_start': 0.2,\n",
       " 'swa_lrs': 0.0001,\n",
       " 'gamma': 0.2}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['setup_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73b47d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model architecture: out_dims, n_graphs, heads, internal_elem_dim\n",
      "1, 3, 3, 64\n",
      "Model size: 2352057 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RoostLightningClass.load_from_checkpoint('roost_energy_models/trained_models/energy-epoch=93-val_acc=0.00.ckpt',\n",
    "                                                classification=True,criterion=BCEWithLogitsLoss,setup=config['setup_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71afb9ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RoostLightningClass' object has no attribute 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msetup, model\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mclassification, model\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39msetup, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\roost\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RoostLightningClass' object has no attribute 'criterion'"
     ]
    }
   ],
   "source": [
    "model.setup, model.hparams.classification, model.hparams.setup, model.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e802c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_data.prepare_data()\n",
    "dataloader=disorder_data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21747823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 DataBatch(x=[961, 200], edge_index=[2, 4159], y=[256], pos=[961], batch=[961], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "for ind,batch in enumerate(dataloader):\n",
    "    print(ind,batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b666ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams.classification=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34c7d2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function roost.utils.BCEWithLogitsLoss(output, target, weight=None)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38f3557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"classification\": True\n",
       "\"data_params\":    {'embed': 'matscholar', 'batch_size': 128, 'train_path': 'data/energy_data/train_fe.csv', 'val_path': 'data/energy_data/val_fe.csv', 'test_path': 'data/energy_data/test_fe.csv'}\n",
       "\"epochs\":         100\n",
       "\"model_name\":     roost\n",
       "\"model_params\":   {'input_dim': 200, 'output_dim': 1, 'hidden_layer_dims': [1024, 512, 256, 128, 64], 'n_graphs': 3, 'elem_heads': 3, 'internal_elem_dim': 64, 'g_elem_dim': 256, 'f_elem_dim': 256, 'comp_heads': 3, 'g_comp_dim': 128, 'f_comp_dim': 128, 'batchnorm': False, 'negative_slope': 0.2}\n",
       "\"patience\":       100\n",
       "\"seed\":           42\n",
       "\"setup_params\":   {'optim': 'AdamW', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'momentum': 0.9, 'loss': 'L1Loss', 'base_lr': 0.001, 'max_lr': 0.006, 'swa_epoch_start': 0.2, 'swa_lrs': 0.0003, 'gamma': 0.2}\n",
       "\"test_size\":      0.2\n",
       "\"val_size\":       0.1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37c2f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_data = RoostDataModule(config['data_params']['train_path'],\n",
    "                                   config['data_params']['val_path'],\n",
    "                                   config['data_params']['test_path'], features=config['data_params']['embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8764129f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('roost_energy_models/trained_models/energy-epoch=93-val_acc=0.00.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4fa8eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6143fd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StochasticWeightAveraging': {'n_averaged': 75,\n",
       "  'latest_update_epoch': 93,\n",
       "  'scheduler_state': {'anneal_func': <function torch.optim.swa_utils.SWALR._cosine_anneal(t)>,\n",
       "   'anneal_epochs': 10,\n",
       "   'base_lrs': [0.0003],\n",
       "   'last_epoch': 176,\n",
       "   '_step_count': 76,\n",
       "   'verbose': False,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0003]},\n",
       "  'average_model_state': OrderedDict([('model.material_nn.project_fea.weight',\n",
       "                tensor([[ 0.1814,  0.0198,  0.0808,  ..., -0.0408,  0.1799, -0.1739],\n",
       "                        [ 0.1793,  0.0948, -0.1398,  ..., -0.2047,  0.0222,  0.1107],\n",
       "                        [-0.1685, -0.0192,  0.0807,  ...,  0.1732, -0.0293,  0.1981],\n",
       "                        ...,\n",
       "                        [ 0.1598,  0.1110,  0.2008,  ..., -0.0157,  0.0770, -0.0737],\n",
       "                        [ 0.1671,  0.0894,  0.0350,  ...,  0.2250,  0.2377, -0.1426],\n",
       "                        [ 0.1947,  0.0192,  0.1408,  ..., -0.0987,  0.1253,  0.0840]])),\n",
       "               ('model.material_nn.graphs.0.pooling.0.gate_nn.lin1.weight',\n",
       "                tensor([[-0.2387,  0.0699,  0.0959,  ..., -0.0342,  0.0208,  0.1239],\n",
       "                        [-0.1235,  0.1264,  0.0771,  ..., -0.0775, -0.0792, -0.1905],\n",
       "                        [ 0.1028, -0.0745,  0.0881,  ..., -0.1031,  0.0786, -0.0675],\n",
       "                        ...,\n",
       "                        [ 0.1292,  0.0586, -0.2356,  ...,  0.1593,  0.1434,  0.0332],\n",
       "                        [ 0.1590,  0.0228, -0.1699,  ...,  0.0721,  0.0806, -0.0882],\n",
       "                        [ 0.0878, -0.0508,  0.1547,  ...,  0.0792, -0.1351,  0.0241]])),\n",
       "               ('model.material_nn.graphs.0.pooling.0.gate_nn.lin2.weight',\n",
       "                tensor([[ 9.0868e-02,  2.0026e-01,  5.4234e-02, -9.0970e-02, -8.6484e-02,\n",
       "                          2.4335e-01,  4.1276e-02,  1.4383e-01, -1.0173e-01, -8.7119e-03,\n",
       "                         -1.7263e-01, -2.3010e-01, -1.0200e-01,  9.0928e-02,  1.5471e-01,\n",
       "                         -5.3091e-02,  3.0259e-01, -9.2882e-02,  1.1935e-01, -1.9484e-01,\n",
       "                         -1.5625e-01,  9.3704e-02, -1.1484e-01, -1.4524e-01,  8.7840e-02,\n",
       "                         -1.9908e-01,  1.2394e-01, -7.7191e-02, -2.0512e-01,  2.3299e-01,\n",
       "                         -1.1895e-01,  1.4189e-01, -1.9170e-01, -1.7841e-01,  1.5804e-01,\n",
       "                         -2.0374e-01,  1.8111e-01,  1.7318e-01, -1.7426e-01, -1.6356e-01,\n",
       "                          7.6152e-02, -1.7184e-01, -8.5307e-02, -1.5135e-01, -1.1268e-01,\n",
       "                          7.7660e-02, -2.1227e-01,  8.3182e-02,  1.6103e-01,  3.3878e-02,\n",
       "                          1.7479e-01,  7.8165e-02, -7.2746e-02, -1.6245e-01, -1.9504e-01,\n",
       "                          1.2880e-01, -1.8545e-01, -6.4561e-02, -2.3061e-01,  8.3974e-02,\n",
       "                          7.3216e-02, -1.6911e-01, -1.4684e-01, -1.3264e-01,  2.3799e-01,\n",
       "                         -1.1318e-01,  1.8509e-01, -8.7940e-03, -7.5744e-02,  1.7337e-01,\n",
       "                          3.3447e-02, -1.7468e-01,  2.7833e-01, -1.6468e-01,  1.9628e-01,\n",
       "                          1.2259e-01, -1.5676e-01, -1.2931e-01,  3.3567e-02, -5.5083e-02,\n",
       "                         -2.3788e-01,  1.9396e-01, -3.1073e-02, -2.2647e-01, -1.4716e-01,\n",
       "                          5.0821e-02,  1.9432e-01,  1.6145e-01,  9.3049e-02,  1.9820e-01,\n",
       "                          1.7902e-01,  1.2400e-01,  2.4854e-01, -3.5426e-02,  1.2914e-01,\n",
       "                         -1.4810e-01,  1.3020e-01, -2.2644e-01,  2.1472e-01,  7.5103e-02,\n",
       "                          4.7697e-02, -6.5847e-02,  1.0314e-01, -1.0115e-01,  3.9546e-03,\n",
       "                          8.2067e-02, -5.0969e-02, -1.8738e-01, -9.2300e-02,  1.8116e-01,\n",
       "                          1.5766e-01,  2.4803e-01, -2.4927e-01,  8.0757e-02, -7.3378e-02,\n",
       "                         -1.2387e-01,  2.0127e-01,  3.2468e-02,  2.5104e-01,  1.5964e-01,\n",
       "                          2.7496e-01, -1.5660e-01, -9.5079e-02,  1.5393e-01, -1.1842e-01,\n",
       "                         -7.7447e-02,  1.1382e-01,  1.2530e-01, -1.0147e-01,  3.5157e-02,\n",
       "                          2.4241e-01, -1.8999e-01,  1.8648e-01, -8.3573e-02, -6.2221e-02,\n",
       "                         -1.6629e-01,  1.4951e-01, -2.2215e-01, -1.9846e-01, -1.1408e-01,\n",
       "                         -1.5866e-01, -6.7718e-02,  4.3096e-02, -2.3532e-01,  2.0106e-01,\n",
       "                          1.2228e-01, -1.8339e-01, -1.0196e-01,  1.4455e-01,  1.1991e-01,\n",
       "                          1.5852e-01,  2.3078e-01, -3.7467e-02,  1.1380e-01,  2.8658e-01,\n",
       "                         -9.2783e-02,  1.4668e-01,  4.2267e-02,  1.5776e-01,  1.2699e-01,\n",
       "                          2.0653e-01, -8.2605e-02,  1.6505e-01, -1.5162e-01, -1.4532e-03,\n",
       "                         -8.2922e-02,  3.0954e-02,  2.4142e-01,  1.0884e-01, -4.9244e-02,\n",
       "                         -2.2836e-01,  5.8843e-02, -2.2534e-01, -2.1508e-01,  2.2704e-01,\n",
       "                         -1.8134e-01, -2.3350e-01,  1.9347e-01,  2.8591e-01,  1.1563e-01,\n",
       "                         -6.2675e-02,  1.0041e-01,  2.1874e-01, -2.1570e-01, -1.0977e-01,\n",
       "                         -1.2377e-01,  1.8949e-01,  2.1033e-01,  7.9216e-02,  1.3459e-01,\n",
       "                         -9.8565e-02, -1.2811e-01,  9.7822e-02,  1.4949e-01,  1.4857e-01,\n",
       "                         -9.7794e-02,  9.1025e-02, -1.6170e-01, -1.6814e-01, -2.0452e-01,\n",
       "                         -2.4818e-01, -1.1002e-01,  1.3065e-01,  1.8475e-01,  4.3047e-02,\n",
       "                         -5.3939e-02,  1.7090e-01,  1.0342e-01, -6.4105e-02, -4.7886e-02,\n",
       "                         -2.0879e-01,  1.7322e-01, -2.0683e-04,  6.1525e-02,  6.5211e-02,\n",
       "                          7.3213e-02,  1.5266e-01,  1.7786e-01,  1.7669e-01,  7.3898e-02,\n",
       "                          1.9648e-01, -8.9493e-02,  1.8976e-01, -6.8990e-03,  3.5155e-01,\n",
       "                         -1.3489e-01,  1.8877e-01,  1.9488e-01, -1.8089e-01,  6.9830e-02,\n",
       "                          1.7280e-01,  1.6349e-01,  2.1697e-01, -4.6857e-02,  1.6703e-01,\n",
       "                          1.7477e-01,  2.1102e-02, -1.6138e-01,  1.9915e-01, -1.4538e-01,\n",
       "                          2.1024e-01, -1.3372e-01,  4.8552e-02,  2.0009e-01,  1.5728e-01,\n",
       "                          1.2462e-01, -2.4333e-03,  1.2700e-01, -1.1907e-01, -2.2293e-01,\n",
       "                          2.3665e-01,  2.3254e-01, -7.6987e-02, -1.6277e-01, -1.6267e-01,\n",
       "                          2.6519e-02]])),\n",
       "               ('model.material_nn.graphs.0.pooling.0.message_nn.lin1.weight',\n",
       "                tensor([[-0.2113,  0.0945, -0.1561,  ..., -0.1780, -0.1267, -0.0916],\n",
       "                        [-0.0539, -0.1497,  0.0516,  ..., -0.1606, -0.0373,  0.1231],\n",
       "                        [ 0.1257, -0.1722, -0.1072,  ..., -0.1064, -0.1116, -0.0671],\n",
       "                        ...,\n",
       "                        [-0.0926,  0.1284,  0.1639,  ..., -0.0771, -0.0439,  0.1709],\n",
       "                        [ 0.0482,  0.1368, -0.0460,  ..., -0.1142,  0.1253, -0.0569],\n",
       "                        [ 0.1296, -0.0885,  0.1357,  ...,  0.1014, -0.0550,  0.0712]])),\n",
       "               ('model.material_nn.graphs.0.pooling.0.message_nn.lin2.weight',\n",
       "                tensor([[-0.0843, -0.1985,  0.0078,  ..., -0.1270, -0.0953, -0.0340],\n",
       "                        [ 0.1346, -0.1861, -0.1618,  ...,  0.1234, -0.1799,  0.0324],\n",
       "                        [-0.0421, -0.0189,  0.0180,  ...,  0.1464,  0.0475,  0.0965],\n",
       "                        ...,\n",
       "                        [ 0.0764, -0.1196,  0.1892,  ...,  0.0719,  0.1367, -0.0059],\n",
       "                        [-0.0233,  0.1061, -0.0911,  ...,  0.0911,  0.0636,  0.0453],\n",
       "                        [-0.0366,  0.1285, -0.0553,  ...,  0.0861,  0.0296,  0.0587]])),\n",
       "               ('model.material_nn.graphs.0.pooling.1.gate_nn.lin1.weight',\n",
       "                tensor([[-0.0218, -0.1372,  0.1054,  ...,  0.0095, -0.0501,  0.0295],\n",
       "                        [ 0.1416, -0.2440, -0.0564,  ...,  0.0409, -0.1052,  0.1124],\n",
       "                        [-0.0295, -0.0404, -0.0697,  ...,  0.1337,  0.1100,  0.1483],\n",
       "                        ...,\n",
       "                        [-0.1047, -0.1443,  0.1070,  ..., -0.1786, -0.1165,  0.1518],\n",
       "                        [ 0.1013,  0.1466,  0.1077,  ..., -0.1167,  0.1106,  0.1013],\n",
       "                        [ 0.1321,  0.0983, -0.0678,  ..., -0.1083,  0.0035, -0.0200]])),\n",
       "               ('model.material_nn.graphs.0.pooling.1.gate_nn.lin2.weight',\n",
       "                tensor([[-1.4459e-01, -1.2489e-01, -1.4446e-01, -1.3382e-01,  1.3402e-01,\n",
       "                         -5.9935e-02, -1.3705e-01, -7.3462e-02,  9.6311e-02,  1.1071e-01,\n",
       "                         -2.0429e-01,  4.1819e-02,  7.8867e-02,  1.1481e-01,  1.4745e-01,\n",
       "                         -1.2939e-01, -8.8875e-02,  1.0744e-01, -6.6751e-02,  5.3593e-02,\n",
       "                         -1.0651e-01,  2.5660e-01,  1.1840e-01,  1.6429e-01, -1.2569e-01,\n",
       "                         -2.5354e-01,  1.0480e-01, -5.3945e-02, -2.2254e-01, -6.0964e-02,\n",
       "                         -1.6070e-01, -1.1967e-01,  1.2363e-01,  8.1204e-02, -1.3919e-01,\n",
       "                          4.3309e-02, -9.7894e-02, -5.0438e-02, -1.1008e-02, -1.2779e-01,\n",
       "                          1.8616e-01,  2.4944e-01,  2.4369e-01, -2.3299e-01, -2.8452e-01,\n",
       "                          1.9314e-01,  1.0097e-01,  2.1615e-01, -2.3170e-01, -9.6970e-02,\n",
       "                         -1.1658e-01,  1.7063e-01,  1.5511e-01, -3.8531e-02, -1.9277e-01,\n",
       "                          2.7270e-01,  1.5812e-01,  6.6515e-02,  2.9133e-02,  1.9557e-01,\n",
       "                          1.0758e-01,  9.1728e-02, -1.0663e-01,  1.9640e-01, -2.3476e-01,\n",
       "                          1.8069e-01, -1.5637e-01, -1.8345e-01,  2.3062e-01,  2.2781e-01,\n",
       "                          1.4326e-01,  9.7794e-02,  1.3129e-01, -2.4687e-01,  1.1959e-02,\n",
       "                          1.8668e-01, -2.7880e-02,  2.8945e-01,  1.2690e-01,  1.8468e-01,\n",
       "                         -4.7849e-05, -4.7786e-02,  1.6634e-01, -4.8825e-02,  2.6387e-01,\n",
       "                         -5.5974e-02,  5.2440e-02, -5.1199e-02, -4.3091e-02, -2.1914e-01,\n",
       "                         -1.9041e-01,  4.4741e-02, -1.5538e-01,  2.1850e-01,  2.6616e-01,\n",
       "                          1.5366e-01,  1.8912e-01,  6.5991e-02,  1.8190e-01, -5.0859e-02,\n",
       "                         -8.1384e-02,  5.3057e-02,  1.6592e-01,  2.6677e-01, -1.1133e-01,\n",
       "                          2.0687e-01,  1.1128e-01, -1.9428e-01, -4.6754e-02, -1.2655e-02,\n",
       "                          1.3908e-01, -2.2835e-01,  1.0247e-01, -1.9138e-01,  1.1924e-01,\n",
       "                          2.5725e-01,  2.0874e-01,  4.5841e-02, -2.6606e-01, -1.5010e-01,\n",
       "                         -1.6344e-01,  6.1139e-02, -8.2566e-02, -1.7977e-02, -4.2446e-02,\n",
       "                         -1.3922e-01, -1.2224e-01,  2.9130e-01,  1.9624e-02, -2.1012e-01,\n",
       "                         -3.5593e-02,  1.0153e-01,  2.8561e-01,  2.8783e-02,  2.8213e-01,\n",
       "                          1.5771e-01, -1.5263e-01, -1.3714e-01, -7.6626e-02, -2.3313e-01,\n",
       "                         -2.2333e-01, -1.2321e-01, -1.1504e-01, -5.8716e-02,  1.0999e-01,\n",
       "                         -2.2356e-01, -3.9313e-02, -1.6599e-01,  4.5759e-02,  4.7695e-02,\n",
       "                          7.0380e-02,  1.6491e-01,  1.1286e-01, -2.2197e-01,  6.0278e-02,\n",
       "                          7.4519e-02,  2.1039e-01, -5.0384e-02, -1.8994e-01, -1.3378e-01,\n",
       "                         -1.2529e-01, -1.5130e-01,  7.7428e-02, -1.8423e-01,  2.8246e-02,\n",
       "                         -1.7792e-02, -1.6890e-01,  5.1272e-02,  8.5500e-02,  1.5333e-01,\n",
       "                          9.0542e-02, -9.9281e-02, -5.7735e-02, -1.3267e-01,  1.4240e-01,\n",
       "                         -2.5896e-01, -2.1088e-01,  8.0084e-02,  2.0593e-01,  1.8938e-01,\n",
       "                         -1.9053e-01,  1.3199e-01,  1.9255e-01,  1.1645e-01,  1.9001e-01,\n",
       "                         -1.9187e-01,  4.7818e-02, -3.0710e-02,  2.5525e-01, -1.5448e-01,\n",
       "                          1.0446e-01,  1.6119e-01, -7.8583e-02, -1.8152e-01, -1.4260e-04,\n",
       "                          9.4832e-02,  1.6583e-01,  2.2083e-01, -1.7052e-01, -1.3327e-01,\n",
       "                         -1.1748e-01, -1.4902e-01,  1.1743e-01,  1.3377e-01,  2.3001e-01,\n",
       "                          2.1483e-01, -1.0707e-01, -1.5539e-01,  9.9880e-02,  2.8475e-01,\n",
       "                         -1.4689e-01,  9.7881e-02,  7.8606e-02, -3.1669e-01, -1.3624e-01,\n",
       "                          1.4526e-01,  1.4438e-01,  8.9283e-02, -2.2595e-01,  1.2750e-01,\n",
       "                         -1.5985e-01,  1.1123e-01,  7.6870e-02, -1.5805e-01,  3.3953e-01,\n",
       "                          1.4043e-01,  1.2348e-01, -1.3797e-01,  2.6168e-01,  1.3087e-01,\n",
       "                          2.2950e-01,  3.7081e-02, -1.8663e-01, -1.2626e-01,  6.5968e-02,\n",
       "                          1.1354e-01,  1.6299e-01,  1.1029e-01, -1.6807e-01, -5.9049e-02,\n",
       "                         -1.4665e-01,  5.5412e-02,  1.4919e-01,  1.1647e-01, -7.0837e-02,\n",
       "                         -2.2228e-01,  8.5242e-02,  2.0134e-01,  1.6449e-01,  8.1923e-02,\n",
       "                          3.1986e-02, -6.7689e-02, -1.0968e-01, -6.7156e-02, -2.7806e-01,\n",
       "                         -1.0384e-01]])),\n",
       "               ('model.material_nn.graphs.0.pooling.1.message_nn.lin1.weight',\n",
       "                tensor([[-0.0704,  0.0108, -0.0968,  ..., -0.0597, -0.0045,  0.0476],\n",
       "                        [ 0.0466,  0.0634,  0.0472,  ..., -0.0618, -0.1437,  0.0057],\n",
       "                        [ 0.0041, -0.1097, -0.0002,  ..., -0.1505,  0.1188, -0.0767],\n",
       "                        ...,\n",
       "                        [ 0.1318,  0.1084,  0.1189,  ...,  0.0719, -0.0205, -0.0737],\n",
       "                        [ 0.0867,  0.0252, -0.1215,  ..., -0.1042, -0.1030, -0.0484],\n",
       "                        [-0.0318,  0.0237,  0.0828,  ...,  0.1138, -0.0722,  0.0104]])),\n",
       "               ('model.material_nn.graphs.0.pooling.1.message_nn.lin2.weight',\n",
       "                tensor([[-0.1012, -0.1613, -0.1129,  ...,  0.1021,  0.1937, -0.0445],\n",
       "                        [-0.1535, -0.0248,  0.0460,  ..., -0.1369, -0.1503, -0.0527],\n",
       "                        [-0.1264,  0.0671,  0.1916,  ...,  0.0097, -0.0195,  0.0786],\n",
       "                        ...,\n",
       "                        [ 0.1269, -0.1509, -0.1608,  ..., -0.0993,  0.1386,  0.0709],\n",
       "                        [-0.0521, -0.1064, -0.0182,  ...,  0.0123,  0.1832,  0.0325],\n",
       "                        [ 0.0147,  0.0810, -0.0334,  ..., -0.1131,  0.0917, -0.0095]])),\n",
       "               ('model.material_nn.graphs.0.pooling.2.gate_nn.lin1.weight',\n",
       "                tensor([[ 0.1268, -0.0770, -0.1443,  ..., -0.1024,  0.0510,  0.0915],\n",
       "                        [ 0.0762, -0.1122, -0.0477,  ...,  0.0903,  0.1783,  0.1797],\n",
       "                        [ 0.0878, -0.2196,  0.1018,  ...,  0.0556, -0.1144, -0.0143],\n",
       "                        ...,\n",
       "                        [-0.0926, -0.0065,  0.0807,  ...,  0.0833,  0.1670, -0.0724],\n",
       "                        [-0.0634, -0.0867, -0.1497,  ..., -0.1541,  0.1552,  0.0143],\n",
       "                        [-0.0719, -0.0807,  0.1246,  ...,  0.1001,  0.0746, -0.0533]])),\n",
       "               ('model.material_nn.graphs.0.pooling.2.gate_nn.lin2.weight',\n",
       "                tensor([[-0.0738, -0.2293,  0.0998, -0.1454,  0.1587,  0.0817, -0.1841,  0.1804,\n",
       "                          0.1092,  0.2048,  0.1464,  0.1037, -0.1263, -0.1509, -0.0483, -0.1637,\n",
       "                         -0.2692,  0.2021,  0.1980, -0.1264, -0.0837, -0.0239, -0.1551,  0.0795,\n",
       "                          0.1034, -0.0895, -0.1335, -0.1623, -0.0600, -0.2827,  0.0705,  0.1690,\n",
       "                         -0.1856, -0.1367, -0.2222, -0.2016,  0.1881,  0.1207, -0.1962, -0.1457,\n",
       "                         -0.0438,  0.1603, -0.1251,  0.1001,  0.2081,  0.1740,  0.0724,  0.1173,\n",
       "                         -0.1963,  0.2626,  0.1896,  0.1809, -0.1672,  0.2747,  0.1406,  0.1507,\n",
       "                          0.0351,  0.0916, -0.1708,  0.1463, -0.2716,  0.1221,  0.1063,  0.1449,\n",
       "                          0.2012, -0.0989, -0.2232, -0.1982, -0.0775, -0.1235, -0.2851, -0.1123,\n",
       "                          0.0708, -0.1759, -0.0845, -0.1124, -0.1050, -0.2925,  0.2231,  0.0978,\n",
       "                         -0.1320,  0.1427,  0.2576,  0.2145, -0.2385, -0.1490, -0.1788,  0.1169,\n",
       "                          0.2244,  0.1453, -0.1770, -0.2419,  0.1621, -0.0592, -0.1319, -0.2478,\n",
       "                         -0.1661, -0.2493, -0.0376,  0.2123,  0.0505,  0.1943,  0.1504,  0.2840,\n",
       "                         -0.1848, -0.1770, -0.1100, -0.0823, -0.2804,  0.1750,  0.1604,  0.0197,\n",
       "                         -0.1966, -0.2752,  0.0815, -0.1653,  0.0634, -0.1663,  0.1545,  0.2560,\n",
       "                         -0.1852,  0.1982, -0.1548,  0.0273, -0.0681, -0.2963, -0.0828, -0.2465,\n",
       "                         -0.2451,  0.2947, -0.0540, -0.2285,  0.2320,  0.0934, -0.1643,  0.0674,\n",
       "                         -0.1274,  0.1936, -0.2705, -0.2431,  0.1183,  0.1336,  0.0896, -0.1582,\n",
       "                         -0.3157, -0.2138,  0.1084, -0.1460,  0.1108, -0.1547,  0.0379, -0.2326,\n",
       "                          0.0774,  0.0564,  0.0481, -0.0287, -0.1807, -0.1959, -0.0594,  0.1345,\n",
       "                          0.1519, -0.2084,  0.1896,  0.2782, -0.1148, -0.2029,  0.0871,  0.0633,\n",
       "                         -0.1884,  0.2425, -0.0683, -0.0333,  0.1153,  0.1649,  0.0921, -0.0532,\n",
       "                          0.1027, -0.0520,  0.2663, -0.0605,  0.0126,  0.0723, -0.2362,  0.2712,\n",
       "                          0.2152, -0.1058, -0.1178,  0.1399,  0.2240,  0.0681,  0.0217,  0.1261,\n",
       "                          0.0753, -0.0668,  0.0869, -0.2671, -0.1872, -0.1144,  0.2023, -0.2962,\n",
       "                          0.2561,  0.1662, -0.1890, -0.0707, -0.1047,  0.0160,  0.2246,  0.1235,\n",
       "                         -0.1556, -0.1791, -0.1476,  0.1300,  0.0576, -0.2025, -0.2733,  0.1990,\n",
       "                         -0.1308,  0.0608,  0.0640,  0.1374, -0.1125,  0.2406, -0.0387,  0.1423,\n",
       "                          0.0603,  0.1710,  0.0713,  0.0612, -0.1286,  0.1379,  0.1326, -0.2154,\n",
       "                         -0.2366, -0.1363,  0.2070,  0.1688, -0.2459,  0.2195, -0.0714,  0.3014,\n",
       "                          0.2302,  0.0413, -0.2614, -0.1805,  0.2438,  0.0984,  0.1877, -0.1798,\n",
       "                          0.1794,  0.1552,  0.1342, -0.1084, -0.2012, -0.2035, -0.1074, -0.0900]])),\n",
       "               ('model.material_nn.graphs.0.pooling.2.message_nn.lin1.weight',\n",
       "                tensor([[ 0.0317,  0.0091, -0.1229,  ...,  0.1551, -0.0211,  0.1808],\n",
       "                        [-0.2088, -0.0047, -0.0459,  ...,  0.0448,  0.2321, -0.1228],\n",
       "                        [ 0.0900,  0.1689,  0.0264,  ...,  0.2019,  0.1498, -0.0392],\n",
       "                        ...,\n",
       "                        [-0.1763, -0.0807, -0.1001,  ...,  0.1491,  0.2118,  0.1045],\n",
       "                        [-0.0311,  0.0198,  0.1098,  ...,  0.0671,  0.0388, -0.0659],\n",
       "                        [ 0.1315,  0.1682, -0.0315,  ..., -0.1550,  0.0524, -0.0399]])),\n",
       "               ('model.material_nn.graphs.0.pooling.2.message_nn.lin2.weight',\n",
       "                tensor([[-0.1799,  0.2426,  0.0833,  ...,  0.0458, -0.1033, -0.1815],\n",
       "                        [ 0.1834,  0.2275, -0.1159,  ..., -0.0087, -0.1277,  0.1369],\n",
       "                        [ 0.1406, -0.1279, -0.0211,  ..., -0.0497,  0.1058,  0.0992],\n",
       "                        ...,\n",
       "                        [-0.1833,  0.0223,  0.1824,  ..., -0.1924, -0.1267,  0.1792],\n",
       "                        [ 0.2113, -0.2265, -0.1774,  ..., -0.0773,  0.0053, -0.2173],\n",
       "                        [-0.0818, -0.1269,  0.1149,  ..., -0.1805, -0.0926,  0.0259]])),\n",
       "               ('model.material_nn.graphs.1.pooling.0.gate_nn.lin1.weight',\n",
       "                tensor([[-0.0377,  0.0982, -0.0657,  ...,  0.0793,  0.2494,  0.0898],\n",
       "                        [-0.1612, -0.0545, -0.0878,  ...,  0.1598, -0.0477, -0.1697],\n",
       "                        [ 0.0189, -0.0556, -0.0946,  ...,  0.0757,  0.1407,  0.0967],\n",
       "                        ...,\n",
       "                        [ 0.2358,  0.1428, -0.0535,  ..., -0.0083, -0.1452,  0.1053],\n",
       "                        [ 0.2316,  0.1465,  0.0740,  ..., -0.0924, -0.1358,  0.1010],\n",
       "                        [ 0.3458,  0.1969, -0.0485,  ..., -0.1834, -0.2389, -0.0823]])),\n",
       "               ('model.material_nn.graphs.1.pooling.0.gate_nn.lin2.weight',\n",
       "                tensor([[-2.3283e-01, -5.4856e-02, -9.8697e-02, -2.7035e-01,  2.8239e-01,\n",
       "                          2.1954e-01,  2.7984e-01, -3.2961e-01,  2.2252e-01, -2.2807e-01,\n",
       "                          2.9058e-01, -2.4968e-01, -2.1437e-01,  2.4946e-01, -4.0563e-01,\n",
       "                          2.3970e-01, -1.6169e-01, -1.1201e-01, -2.5342e-01,  2.5391e-01,\n",
       "                          2.3648e-01, -4.2648e-01, -2.3354e-01,  2.0440e-01, -1.7848e-01,\n",
       "                          2.9214e-01,  2.4956e-01,  1.8452e-01,  1.5785e-01,  2.6808e-01,\n",
       "                          2.6294e-01, -2.0608e-01,  1.4688e-01,  7.1483e-02,  2.6404e-01,\n",
       "                          2.0833e-01, -1.8052e-01,  2.6454e-01,  1.3336e-01, -2.1659e-01,\n",
       "                         -2.8033e-01, -2.3221e-01, -1.3410e-01,  2.4098e-01,  3.5004e-01,\n",
       "                         -1.8444e-01, -4.2707e-01, -2.1646e-01,  3.2118e-01, -1.8947e-01,\n",
       "                         -2.6770e-01, -2.0023e-01, -2.0969e-01, -7.6359e-02,  1.7865e-01,\n",
       "                         -1.2963e-01, -3.1419e-01,  1.4934e-01, -2.1358e-01,  2.2525e-01,\n",
       "                          1.0290e-01, -3.3417e-01, -8.4599e-02,  1.2212e-01,  4.5912e-01,\n",
       "                          1.5666e-01, -2.1436e-01,  1.9501e-01,  2.6169e-01, -1.0237e-01,\n",
       "                          2.4281e-01,  4.7386e-02,  2.3454e-01,  2.0455e-01, -2.0955e-01,\n",
       "                         -4.2515e-01, -2.5023e-01, -2.6601e-01,  2.0609e-01,  1.6390e-01,\n",
       "                          3.0391e-01,  2.7351e-01,  2.4495e-01,  1.4124e-01,  2.4335e-01,\n",
       "                         -1.4934e-01, -2.6475e-01, -3.5629e-01,  1.0851e-01,  1.2300e-01,\n",
       "                          1.4984e-01, -3.0618e-01,  2.8927e-01,  2.8547e-01, -2.3085e-01,\n",
       "                          2.6122e-01,  1.8786e-01, -2.8943e-01,  3.2582e-01, -2.1333e-01,\n",
       "                          9.1907e-02, -9.6500e-02, -3.8266e-01,  2.0601e-01, -2.6662e-01,\n",
       "                         -3.1927e-01,  1.9868e-01, -2.5984e-01, -2.4182e-01,  2.3009e-01,\n",
       "                          2.1369e-01,  3.2124e-01,  1.7707e-01, -1.9179e-01,  1.9602e-01,\n",
       "                          3.0217e-01, -3.1140e-01,  2.4915e-01, -2.5422e-01, -1.9692e-01,\n",
       "                          1.7005e-01, -2.0652e-01,  1.3371e-01,  3.1817e-01, -6.0804e-03,\n",
       "                          1.0985e-01, -1.7176e-01, -1.4563e-01,  1.4979e-01,  1.2105e-01,\n",
       "                         -2.0808e-01, -1.9970e-01,  1.8315e-01,  2.4152e-01,  3.1039e-01,\n",
       "                          1.3213e-01,  1.4856e-01,  5.9864e-02,  2.1529e-01,  1.9123e-01,\n",
       "                          1.9629e-01, -2.3018e-01,  2.2444e-01,  2.5349e-01,  1.9606e-01,\n",
       "                         -1.7124e-01,  1.5670e-01,  1.3250e-01, -1.7175e-01, -2.2802e-01,\n",
       "                          2.7801e-01,  2.5688e-01,  9.6139e-02,  1.8049e-01, -7.6095e-02,\n",
       "                          1.4574e-01,  5.2290e-02, -2.2723e-01,  6.1753e-02,  1.2560e-01,\n",
       "                         -2.7154e-01, -3.0666e-01, -2.2041e-01, -2.7891e-01, -6.4057e-02,\n",
       "                          2.3219e-01,  2.7381e-01,  2.2328e-01, -7.7487e-02,  1.8574e-01,\n",
       "                          1.4876e-01,  1.0116e-01,  3.6336e-04, -4.1543e-01,  2.1500e-01,\n",
       "                         -3.4180e-01, -1.4576e-01, -7.8241e-02, -3.3922e-01,  2.8572e-01,\n",
       "                         -1.1040e-01, -2.6529e-01,  3.0828e-01, -2.0668e-01, -3.1649e-01,\n",
       "                          2.4581e-01, -1.6168e-01, -3.2513e-01, -2.5602e-01, -2.8540e-01,\n",
       "                          3.5380e-01,  2.9327e-01,  2.8708e-01,  1.9943e-01, -3.9504e-01,\n",
       "                         -2.2650e-01,  2.1550e-01, -2.3197e-01, -1.9634e-01, -3.3100e-01,\n",
       "                         -1.5040e-01,  2.7733e-01,  2.9123e-01, -1.2679e-01, -2.5980e-01,\n",
       "                          2.0851e-01,  6.7257e-02, -2.7194e-01,  2.1817e-01,  2.5307e-01,\n",
       "                          9.3914e-02, -1.9238e-01,  2.7518e-01, -1.4707e-01, -2.2956e-01,\n",
       "                          2.5903e-01, -1.2197e-01, -3.2501e-01, -2.1769e-01, -1.9787e-01,\n",
       "                          2.9430e-01, -2.5880e-01, -3.2874e-01,  3.0912e-01,  3.1442e-01,\n",
       "                         -3.2107e-01, -1.3552e-01, -1.5782e-01, -1.7319e-01,  2.1441e-01,\n",
       "                          1.9279e-01,  6.3792e-02,  2.0550e-01, -1.6089e-01, -2.0910e-01,\n",
       "                          3.1921e-01, -2.5677e-01,  2.5752e-01, -2.5652e-01, -2.7261e-01,\n",
       "                          2.7259e-01, -2.7345e-01,  6.5138e-02,  2.7259e-01,  1.7025e-01,\n",
       "                          3.3946e-01, -3.0490e-01, -2.6910e-01,  9.7788e-02,  3.0748e-01,\n",
       "                          6.6441e-02,  3.4366e-01,  2.9358e-01,  8.9425e-02,  1.9729e-01,\n",
       "                          1.9976e-01]])),\n",
       "               ('model.material_nn.graphs.1.pooling.0.message_nn.lin1.weight',\n",
       "                tensor([[-0.1452,  0.0339,  0.0608,  ..., -0.0534, -0.1489, -0.0258],\n",
       "                        [ 0.1648,  0.0419,  0.1336,  ..., -0.0004,  0.0636,  0.1033],\n",
       "                        [-0.1494, -0.1217, -0.1007,  ...,  0.0631,  0.1695, -0.0570],\n",
       "                        ...,\n",
       "                        [ 0.1181,  0.0439,  0.0431,  ...,  0.0269,  0.0370,  0.0403],\n",
       "                        [-0.0855,  0.1672,  0.2081,  ...,  0.0010,  0.1392, -0.0421],\n",
       "                        [ 0.1193, -0.1618, -0.0596,  ..., -0.0847,  0.0124, -0.0947]])),\n",
       "               ('model.material_nn.graphs.1.pooling.0.message_nn.lin2.weight',\n",
       "                tensor([[ 5.1583e-02, -1.9190e-01,  1.6739e-01,  ...,  1.0875e-02,\n",
       "                         -3.3928e-02,  4.9247e-02],\n",
       "                        [ 7.1388e-02,  1.3520e-01, -1.7903e-02,  ..., -1.5579e-01,\n",
       "                          6.6371e-02,  3.7427e-02],\n",
       "                        [-5.9718e-02, -1.8347e-01, -1.0441e-01,  ..., -8.2291e-02,\n",
       "                         -1.0173e-01, -1.3881e-01],\n",
       "                        ...,\n",
       "                        [ 5.0717e-02,  3.6517e-02, -5.7839e-02,  ...,  5.7848e-02,\n",
       "                          8.1362e-02,  7.1323e-02],\n",
       "                        [-1.3043e-02, -1.3232e-01,  1.2051e-01,  ...,  5.3701e-02,\n",
       "                         -8.9865e-02, -6.7200e-02],\n",
       "                        [ 1.3879e-01, -1.6664e-01,  1.9720e-02,  ..., -4.9551e-05,\n",
       "                         -1.0397e-01, -9.4538e-02]])),\n",
       "               ('model.material_nn.graphs.1.pooling.1.gate_nn.lin1.weight',\n",
       "                tensor([[-0.1676, -0.2221,  0.1304,  ...,  0.1880,  0.0251,  0.1127],\n",
       "                        [ 0.1232,  0.1348, -0.0032,  ...,  0.1123,  0.0044,  0.0180],\n",
       "                        [ 0.0188, -0.1609, -0.0353,  ...,  0.0991, -0.0589,  0.1198],\n",
       "                        ...,\n",
       "                        [ 0.0997, -0.1135, -0.0258,  ...,  0.0605,  0.1410, -0.0603],\n",
       "                        [-0.0117,  0.3176, -0.0219,  ..., -0.0520, -0.1417,  0.0183],\n",
       "                        [-0.1474, -0.2032, -0.1965,  ..., -0.0405,  0.1338,  0.1787]])),\n",
       "               ('model.material_nn.graphs.1.pooling.1.gate_nn.lin2.weight',\n",
       "                tensor([[-0.1172, -0.1250, -0.2128,  0.1212,  0.1789,  0.1651, -0.0785,  0.1929,\n",
       "                          0.2581,  0.1629,  0.2290,  0.2624,  0.2883,  0.1389,  0.2988,  0.2884,\n",
       "                         -0.1434, -0.2533,  0.1344, -0.1010, -0.2590,  0.2285, -0.2091, -0.0987,\n",
       "                          0.2068,  0.2133,  0.2002, -0.3862,  0.1976,  0.1855, -0.0894, -0.1813,\n",
       "                         -0.2646,  0.2665,  0.0916, -0.0817,  0.2149,  0.0725,  0.1670, -0.0569,\n",
       "                          0.3011, -0.2380,  0.1066,  0.1649,  0.2135, -0.1084, -0.2307,  0.3296,\n",
       "                          0.2291, -0.1805, -0.2948,  0.2381, -0.1711, -0.1777, -0.2872,  0.2271,\n",
       "                         -0.1534, -0.0973,  0.1124,  0.2079,  0.1819, -0.1381,  0.2631,  0.2555,\n",
       "                         -0.1733,  0.2195,  0.1556,  0.2670, -0.1504, -0.1576,  0.1222, -0.3522,\n",
       "                         -0.1498,  0.1689,  0.2594, -0.1115, -0.3459, -0.1844, -0.2771,  0.1673,\n",
       "                          0.1275,  0.1750,  0.0647, -0.2963, -0.0417,  0.2266, -0.2794, -0.3189,\n",
       "                         -0.2504,  0.2602, -0.1984,  0.2451,  0.1154, -0.2965, -0.1431,  0.1698,\n",
       "                         -0.1447,  0.2109,  0.2226, -0.1726, -0.1307, -0.1695,  0.1944, -0.2187,\n",
       "                         -0.1472, -0.1903,  0.2414,  0.1847,  0.1686, -0.3019, -0.2378,  0.3712,\n",
       "                         -0.2266,  0.1517,  0.2121, -0.3126,  0.2047,  0.3495, -0.1183,  0.1736,\n",
       "                          0.2010, -0.1761, -0.1403, -0.1296,  0.2673,  0.2656,  0.2744,  0.1983,\n",
       "                          0.1517, -0.1375,  0.1637, -0.0833, -0.0783,  0.0355,  0.1857, -0.1002,\n",
       "                          0.2019, -0.1220, -0.1844, -0.2777,  0.2253,  0.0918, -0.1568, -0.0783,\n",
       "                          0.2344,  0.3663, -0.2242, -0.2389,  0.1700, -0.1258, -0.0787,  0.1990,\n",
       "                         -0.1524,  0.1123,  0.2673,  0.2566,  0.1647, -0.1799,  0.3148, -0.2133,\n",
       "                          0.2730, -0.1685,  0.1674, -0.1331,  0.1016, -0.1290, -0.2765, -0.1278,\n",
       "                          0.2132, -0.3162,  0.3794,  0.1715,  0.2676, -0.1632,  0.1397, -0.2180,\n",
       "                         -0.1074, -0.1415, -0.1895, -0.3794,  0.1817, -0.1571,  0.1260, -0.1411,\n",
       "                          0.2085, -0.1831,  0.1658, -0.1539,  0.1207,  0.0914, -0.2025, -0.1303,\n",
       "                          0.1185,  0.1538, -0.2985, -0.0476,  0.2613, -0.1368, -0.1836, -0.1844,\n",
       "                         -0.1703, -0.0735,  0.1733, -0.3029,  0.2610, -0.0702,  0.1219, -0.1388,\n",
       "                         -0.1103, -0.2284, -0.1208,  0.1801,  0.2308,  0.2461, -0.2776, -0.2004,\n",
       "                         -0.1534, -0.1610, -0.0513, -0.0618, -0.1415, -0.1568,  0.2928,  0.1619,\n",
       "                         -0.2132,  0.1663,  0.1941, -0.2460,  0.2557, -0.1085,  0.1430, -0.1639,\n",
       "                          0.2369,  0.1845, -0.1835,  0.2316, -0.1043,  0.1669, -0.1676,  0.0773,\n",
       "                          0.1502,  0.1230,  0.2277,  0.1137, -0.1855,  0.1796,  0.3476,  0.0687,\n",
       "                          0.1752,  0.4258,  0.2083,  0.0424, -0.1189,  0.3073,  0.0862, -0.0701]])),\n",
       "               ('model.material_nn.graphs.1.pooling.1.message_nn.lin1.weight',\n",
       "                tensor([[ 0.1834,  0.0291, -0.0190,  ...,  0.1888, -0.0656,  0.1558],\n",
       "                        [-0.0318, -0.0701, -0.1339,  ..., -0.0712,  0.0536, -0.0562],\n",
       "                        [ 0.1338, -0.0345, -0.0078,  ..., -0.1025,  0.1356, -0.1256],\n",
       "                        ...,\n",
       "                        [-0.1759, -0.0291, -0.0643,  ..., -0.1201,  0.0400,  0.0234],\n",
       "                        [ 0.0951,  0.0050, -0.1457,  ..., -0.1748, -0.0762, -0.1286],\n",
       "                        [ 0.0279,  0.0261,  0.1325,  ...,  0.1577,  0.0794,  0.0935]])),\n",
       "               ('model.material_nn.graphs.1.pooling.1.message_nn.lin2.weight',\n",
       "                tensor([[-0.2080, -0.0814,  0.1273,  ..., -0.1806, -0.0204,  0.0629],\n",
       "                        [-0.1475,  0.1116,  0.0033,  ...,  0.0610,  0.0876,  0.0784],\n",
       "                        [-0.0741, -0.0989,  0.0804,  ...,  0.1297,  0.0149, -0.1886],\n",
       "                        ...,\n",
       "                        [ 0.1677, -0.0391,  0.0999,  ..., -0.1590,  0.0457,  0.0919],\n",
       "                        [ 0.0053,  0.0280, -0.1908,  ..., -0.0205,  0.1225, -0.1632],\n",
       "                        [ 0.1027,  0.0799,  0.0365,  ...,  0.1062,  0.1722, -0.1420]])),\n",
       "               ('model.material_nn.graphs.1.pooling.2.gate_nn.lin1.weight',\n",
       "                tensor([[ 0.0401,  0.1433, -0.0386,  ..., -0.1411, -0.0829, -0.0496],\n",
       "                        [ 0.0779,  0.0847,  0.1315,  ...,  0.1470,  0.1167, -0.0749],\n",
       "                        [ 0.0875,  0.1460,  0.1912,  ...,  0.1777, -0.0341,  0.0311],\n",
       "                        ...,\n",
       "                        [-0.1919, -0.2375,  0.0887,  ..., -0.0557, -0.1585, -0.1708],\n",
       "                        [-0.0481,  0.0146, -0.0867,  ...,  0.0777, -0.2391,  0.0267],\n",
       "                        [ 0.0279, -0.0538, -0.0176,  ..., -0.1157, -0.0640, -0.0642]])),\n",
       "               ('model.material_nn.graphs.1.pooling.2.gate_nn.lin2.weight',\n",
       "                tensor([[ 0.2528, -0.1597,  0.2211, -0.3416, -0.1378, -0.1827,  0.1664, -0.0986,\n",
       "                          0.0315,  0.2087, -0.0424,  0.1978, -0.2633, -0.0762, -0.1721,  0.1082,\n",
       "                          0.1716,  0.2550, -0.2258, -0.1217,  0.2644, -0.0397,  0.2349,  0.0818,\n",
       "                         -0.1095, -0.0552,  0.1731, -0.1759,  0.1043,  0.1789, -0.0553, -0.1319,\n",
       "                          0.1426,  0.1136,  0.3104,  0.2566,  0.1953, -0.1506, -0.1940, -0.2463,\n",
       "                          0.1794,  0.1853, -0.0782, -0.2007, -0.0627, -0.1302,  0.1883, -0.0910,\n",
       "                          0.1848,  0.2864, -0.1171,  0.1984, -0.2462, -0.1450, -0.2366,  0.0843,\n",
       "                         -0.1054, -0.1152, -0.3107,  0.1671, -0.0926, -0.1832,  0.1853,  0.2026,\n",
       "                          0.1932,  0.1771,  0.1789, -0.1800,  0.2689,  0.2025,  0.0990,  0.2301,\n",
       "                         -0.3323,  0.0291,  0.1912,  0.0642,  0.3361, -0.1428, -0.2080, -0.2220,\n",
       "                         -0.1649,  0.2290,  0.2098,  0.1162,  0.1085,  0.1637,  0.0963,  0.2341,\n",
       "                          0.2856,  0.1294,  0.0434, -0.2445, -0.3157,  0.0263,  0.1521, -0.2611,\n",
       "                          0.1705, -0.1909, -0.1181,  0.1591, -0.1481, -0.3098,  0.1707,  0.1493,\n",
       "                          0.0342,  0.0426, -0.2027, -0.2088,  0.0325, -0.1019,  0.0782, -0.1061,\n",
       "                          0.1803, -0.0173,  0.0606,  0.2595,  0.2512,  0.1163, -0.1276, -0.2343,\n",
       "                         -0.1411, -0.1447, -0.0573,  0.1283, -0.2361,  0.0857, -0.1986,  0.2516,\n",
       "                         -0.2098, -0.2230,  0.0577, -0.0870,  0.2034,  0.1589, -0.3794,  0.3194,\n",
       "                          0.2918,  0.0570,  0.1809, -0.2443,  0.0411, -0.2756, -0.2535,  0.1724,\n",
       "                          0.1353,  0.1526, -0.2420,  0.2060,  0.1723,  0.0616, -0.1136,  0.2347,\n",
       "                          0.1709,  0.1513, -0.1588, -0.1252, -0.1160,  0.2176,  0.1962, -0.2468,\n",
       "                          0.3151, -0.2872, -0.1494,  0.0885, -0.2374,  0.0966, -0.0694, -0.2365,\n",
       "                         -0.1759,  0.2606, -0.1748, -0.0868,  0.1436,  0.2015,  0.1017,  0.1954,\n",
       "                          0.2192, -0.0320, -0.1118,  0.1374, -0.1960,  0.1161, -0.1093,  0.1871,\n",
       "                         -0.1333, -0.1688, -0.3407,  0.1498,  0.1785, -0.1558,  0.1954, -0.1796,\n",
       "                         -0.1393,  0.1680,  0.2909,  0.2320,  0.3153,  0.1230, -0.1760, -0.1563,\n",
       "                         -0.1209,  0.0473,  0.0914,  0.2065,  0.0393,  0.0424, -0.1084, -0.2625,\n",
       "                         -0.2285,  0.2363,  0.3393, -0.3040, -0.0741, -0.0516,  0.2671, -0.1973,\n",
       "                          0.3276,  0.1836,  0.2147,  0.1974,  0.1403,  0.1280,  0.1646, -0.2107,\n",
       "                          0.2095,  0.2389,  0.2328,  0.2371, -0.2339,  0.0761, -0.2331,  0.2470,\n",
       "                          0.2060, -0.2607, -0.1495,  0.1593,  0.2142,  0.0308, -0.0990, -0.2275,\n",
       "                         -0.2187,  0.1436,  0.1438, -0.0389, -0.1003, -0.2889, -0.1949, -0.1044,\n",
       "                         -0.2656,  0.1727, -0.0919, -0.0708,  0.2453, -0.0369,  0.2270, -0.1969]])),\n",
       "               ('model.material_nn.graphs.1.pooling.2.message_nn.lin1.weight',\n",
       "                tensor([[ 7.5830e-02,  7.9161e-02,  1.6208e-01,  ...,  6.8755e-02,\n",
       "                          9.3707e-03,  1.3603e-01],\n",
       "                        [ 1.1270e-01,  1.1961e-04, -8.9651e-02,  ...,  5.3872e-03,\n",
       "                          1.2194e-01,  2.1118e-02],\n",
       "                        [ 5.1989e-02,  1.5108e-01,  9.3012e-02,  ..., -7.4403e-02,\n",
       "                          6.7615e-02, -1.3903e-01],\n",
       "                        ...,\n",
       "                        [ 2.0338e-02,  4.3180e-02, -2.8008e-02,  ..., -3.2398e-02,\n",
       "                          4.5905e-02, -1.6888e-03],\n",
       "                        [-1.6255e-01, -1.1497e-01,  5.7911e-02,  ...,  2.1613e-02,\n",
       "                         -3.5729e-02, -1.5591e-01],\n",
       "                        [ 9.9557e-02,  4.5663e-02,  8.7297e-02,  ..., -4.3573e-02,\n",
       "                         -6.5694e-02, -4.5276e-02]])),\n",
       "               ('model.material_nn.graphs.1.pooling.2.message_nn.lin2.weight',\n",
       "                tensor([[ 1.0972e-01,  1.4895e-01, -1.2084e-01,  ...,  8.3597e-02,\n",
       "                         -5.7282e-02, -1.0532e-01],\n",
       "                        [-1.6317e-02,  7.6213e-03, -1.8801e-02,  ..., -7.0886e-02,\n",
       "                         -1.3040e-01, -1.3458e-01],\n",
       "                        [-3.1368e-02, -1.3858e-01,  1.1657e-01,  ...,  1.5167e-01,\n",
       "                          1.7910e-01, -2.2516e-02],\n",
       "                        ...,\n",
       "                        [-2.4357e-02, -5.7403e-02,  1.7229e-01,  ...,  6.5960e-02,\n",
       "                         -4.1225e-02,  9.4896e-02],\n",
       "                        [-2.1790e-01, -5.8650e-02,  1.0697e-02,  ..., -1.3387e-01,\n",
       "                         -1.1091e-01, -2.2678e-02],\n",
       "                        [-1.1041e-01,  1.4071e-02, -1.8611e-01,  ...,  5.0730e-05,\n",
       "                         -7.3969e-02,  5.5083e-02]])),\n",
       "               ('model.material_nn.graphs.2.pooling.0.gate_nn.lin1.weight',\n",
       "                tensor([[ 0.0656,  0.1691,  0.0150,  ...,  0.1561, -0.0686, -0.0728],\n",
       "                        [-0.2295,  0.0101,  0.1585,  ..., -0.0231,  0.0530, -0.0743],\n",
       "                        [-0.1848,  0.1856, -0.0007,  ..., -0.0125,  0.1377,  0.0902],\n",
       "                        ...,\n",
       "                        [ 0.1184, -0.1355, -0.0316,  ..., -0.1040, -0.1582,  0.0950],\n",
       "                        [-0.1490,  0.0801,  0.0493,  ...,  0.0250, -0.0139,  0.0674],\n",
       "                        [-0.2493, -0.2110,  0.1310,  ...,  0.1506,  0.1742, -0.1309]])),\n",
       "               ('model.material_nn.graphs.2.pooling.0.gate_nn.lin2.weight',\n",
       "                tensor([[-0.1151, -0.2215,  0.2169,  0.1325,  0.2417, -0.0664,  0.1058, -0.1198,\n",
       "                          0.2982,  0.0623,  0.1988,  0.0918, -0.2057, -0.2462,  0.1795,  0.1004,\n",
       "                          0.3967,  0.0723, -0.1249,  0.0452,  0.1568,  0.1561,  0.1646,  0.1583,\n",
       "                          0.1941,  0.1130, -0.0360,  0.2189,  0.1300, -0.1917, -0.0506, -0.2034,\n",
       "                         -0.0225, -0.1473, -0.2354,  0.0587, -0.1771, -0.0602, -0.0738, -0.0785,\n",
       "                          0.3489, -0.1962,  0.0963, -0.1161,  0.1430,  0.2280,  0.0744, -0.0410,\n",
       "                          0.2684,  0.2095,  0.1910,  0.1549,  0.1325,  0.1960, -0.1811,  0.1773,\n",
       "                         -0.2578,  0.3095, -0.2674,  0.2836, -0.1096, -0.1030, -0.1312,  0.2622,\n",
       "                          0.1731, -0.2119, -0.2461, -0.1230, -0.1157, -0.1849, -0.0909, -0.0812,\n",
       "                          0.2524, -0.1014, -0.2601, -0.2465, -0.1972,  0.2121, -0.2376, -0.0629,\n",
       "                          0.0993, -0.2185,  0.1622,  0.1889, -0.0762,  0.2007,  0.0511,  0.2264,\n",
       "                         -0.1996,  0.0512, -0.2196, -0.1320, -0.2455,  0.2261,  0.3424, -0.0677,\n",
       "                          0.1267,  0.2029, -0.1789, -0.1852,  0.2951, -0.1997, -0.0873,  0.0869,\n",
       "                         -0.1634, -0.1917,  0.2629, -0.2161, -0.1067, -0.1939, -0.0785,  0.2214,\n",
       "                          0.1381, -0.2129, -0.1526, -0.2460, -0.1012,  0.1820,  0.0667, -0.1788,\n",
       "                          0.1665, -0.1393,  0.1451,  0.2360,  0.1390,  0.1646, -0.1573,  0.2167,\n",
       "                         -0.0543, -0.0661,  0.1824, -0.1479,  0.0643,  0.1516, -0.0734,  0.2797,\n",
       "                         -0.1423, -0.2632, -0.2069, -0.0862,  0.1243, -0.1096,  0.2375, -0.0755,\n",
       "                          0.1509, -0.1743, -0.2212,  0.2391, -0.0714, -0.0506,  0.2096, -0.2420,\n",
       "                          0.2345,  0.1537, -0.1444, -0.2054, -0.0540, -0.1907, -0.1598, -0.0742,\n",
       "                         -0.1389, -0.1020,  0.2476, -0.0452,  0.1622,  0.0733,  0.0246,  0.1092,\n",
       "                         -0.2915, -0.0485,  0.3098,  0.1014,  0.1487,  0.0401,  0.1878, -0.1269,\n",
       "                          0.2140,  0.2514,  0.1821,  0.2186,  0.2464, -0.2648,  0.1141,  0.1644,\n",
       "                         -0.0795, -0.1605, -0.2459, -0.0450, -0.0988,  0.2116,  0.1814,  0.0260,\n",
       "                          0.2170,  0.2010,  0.2359,  0.0508,  0.0502, -0.0956,  0.1436, -0.0535,\n",
       "                          0.1658,  0.0956,  0.1813,  0.2341, -0.2721,  0.0360,  0.1250,  0.2024,\n",
       "                          0.0884,  0.0523,  0.1336,  0.1440,  0.2225, -0.1233,  0.0716,  0.1856,\n",
       "                          0.1169,  0.1840,  0.1976, -0.0672, -0.1891, -0.1703, -0.1301, -0.1224,\n",
       "                         -0.1148,  0.0912, -0.1439,  0.1098, -0.1021, -0.2291, -0.1252, -0.0503,\n",
       "                         -0.3193, -0.2049, -0.0554,  0.1284, -0.1411, -0.0660,  0.2088, -0.0432,\n",
       "                          0.1875,  0.3236,  0.1538, -0.0955,  0.2009, -0.0457, -0.1341,  0.1065,\n",
       "                          0.1836, -0.2338,  0.1344, -0.1730,  0.0668, -0.1579, -0.1570, -0.2054]])),\n",
       "               ('model.material_nn.graphs.2.pooling.0.message_nn.lin1.weight',\n",
       "                tensor([[ 0.0148,  0.1400,  0.0675,  ..., -0.0203,  0.0408,  0.0694],\n",
       "                        [ 0.1173, -0.0470,  0.0259,  ...,  0.0145,  0.1857, -0.1628],\n",
       "                        [ 0.0312, -0.0250,  0.0069,  ...,  0.0363, -0.1328,  0.1124],\n",
       "                        ...,\n",
       "                        [ 0.0385, -0.0924,  0.0587,  ...,  0.0048, -0.2059, -0.1882],\n",
       "                        [-0.0415,  0.0435, -0.0611,  ...,  0.1150,  0.1004,  0.1181],\n",
       "                        [ 0.0641,  0.0023, -0.1387,  ...,  0.1553,  0.0051,  0.0858]])),\n",
       "               ('model.material_nn.graphs.2.pooling.0.message_nn.lin2.weight',\n",
       "                tensor([[ 0.0793,  0.0664,  0.1429,  ..., -0.0552, -0.1511, -0.0340],\n",
       "                        [ 0.0663,  0.1426, -0.0313,  ..., -0.0561,  0.2010, -0.0025],\n",
       "                        [ 0.0497,  0.0499,  0.0349,  ..., -0.1871, -0.1334,  0.1837],\n",
       "                        ...,\n",
       "                        [ 0.2160,  0.1213,  0.0467,  ..., -0.1338,  0.1969, -0.1125],\n",
       "                        [-0.1801, -0.0927,  0.0927,  ...,  0.0674, -0.1312,  0.0886],\n",
       "                        [ 0.2050, -0.1777,  0.1767,  ...,  0.0315,  0.1692,  0.0773]])),\n",
       "               ('model.material_nn.graphs.2.pooling.1.gate_nn.lin1.weight',\n",
       "                tensor([[-0.0187, -0.1028, -0.1293,  ...,  0.0995, -0.0275,  0.0693],\n",
       "                        [-0.1076,  0.0355, -0.1019,  ...,  0.0003,  0.0478, -0.0141],\n",
       "                        [ 0.1168, -0.0951, -0.0735,  ...,  0.0705,  0.0201,  0.0128],\n",
       "                        ...,\n",
       "                        [-0.0857, -0.2822,  0.0155,  ..., -0.1907, -0.0621, -0.1186],\n",
       "                        [-0.1674,  0.0599,  0.0285,  ...,  0.1244, -0.1244, -0.0238],\n",
       "                        [-0.1998, -0.0814, -0.1350,  ..., -0.1792, -0.0666, -0.1002]])),\n",
       "               ('model.material_nn.graphs.2.pooling.1.gate_nn.lin2.weight',\n",
       "                tensor([[-0.2042,  0.1071,  0.1491, -0.1060,  0.0918, -0.2797,  0.0975, -0.1004,\n",
       "                         -0.0975, -0.1043,  0.2371, -0.1754, -0.2386,  0.1188,  0.1192,  0.2524,\n",
       "                          0.2278,  0.1389,  0.0527, -0.1266, -0.1752, -0.0377, -0.0967,  0.1644,\n",
       "                         -0.2195, -0.0744, -0.2243, -0.1661, -0.0160,  0.1551,  0.1890,  0.0882,\n",
       "                          0.1477,  0.0796, -0.1611, -0.1454,  0.0309,  0.1470,  0.0397, -0.2118,\n",
       "                          0.0950, -0.3241,  0.0742,  0.0710, -0.1243,  0.0563, -0.1736, -0.1478,\n",
       "                          0.1676,  0.2187,  0.0562,  0.0779,  0.0926,  0.1316, -0.2383, -0.1277,\n",
       "                          0.1127, -0.0708,  0.1752,  0.1255,  0.2790,  0.2128, -0.0546,  0.2797,\n",
       "                          0.1304, -0.1164, -0.0362,  0.1866, -0.2367, -0.2618,  0.1959,  0.1724,\n",
       "                         -0.0383,  0.0653,  0.1054,  0.1851,  0.1688, -0.2064, -0.1550, -0.1396,\n",
       "                         -0.1666, -0.0649, -0.2108, -0.0433,  0.1151, -0.0407, -0.1251,  0.1909,\n",
       "                         -0.0748, -0.0389, -0.2419,  0.1129,  0.1139, -0.0768,  0.0988, -0.3441,\n",
       "                         -0.1698,  0.0412,  0.0945, -0.1569,  0.0989,  0.0581,  0.3502,  0.0975,\n",
       "                         -0.1454, -0.2363, -0.0361, -0.0708, -0.0239, -0.2695, -0.1839, -0.0806,\n",
       "                          0.2268, -0.1519, -0.1031, -0.2950, -0.1685, -0.0421, -0.2141,  0.1034,\n",
       "                          0.2571,  0.0569,  0.0314,  0.2004, -0.1039, -0.2493,  0.1744,  0.2676,\n",
       "                          0.1278, -0.0445,  0.1238,  0.1694,  0.1937,  0.2830, -0.1169, -0.1502,\n",
       "                          0.1780,  0.2040,  0.1304, -0.1035, -0.2642, -0.2712,  0.2277,  0.1406,\n",
       "                          0.2014,  0.0811,  0.0894,  0.1921, -0.0326,  0.2429, -0.1465, -0.0851,\n",
       "                         -0.2033, -0.1274, -0.1265,  0.1455,  0.3266, -0.0224,  0.2819, -0.0245,\n",
       "                         -0.1928,  0.2551,  0.1343,  0.0978,  0.1300,  0.1277,  0.1387,  0.1461,\n",
       "                          0.2047, -0.1103, -0.2381, -0.1196,  0.1001,  0.0490, -0.0287, -0.0847,\n",
       "                          0.2054,  0.2371, -0.2416,  0.0891,  0.0371,  0.0777,  0.1086,  0.1707,\n",
       "                         -0.2979, -0.1823, -0.1865,  0.0693,  0.2421, -0.1340,  0.0518,  0.2094,\n",
       "                         -0.2786,  0.0846, -0.1445, -0.1070,  0.1324,  0.2216, -0.1939, -0.0981,\n",
       "                         -0.2043,  0.1224, -0.2307, -0.3118,  0.0974, -0.0333,  0.0629, -0.2370,\n",
       "                          0.2959, -0.1638, -0.0753,  0.0519,  0.2185, -0.0871, -0.1519, -0.1894,\n",
       "                          0.2088, -0.0565, -0.0960, -0.2013,  0.1119, -0.1101,  0.1905,  0.1369,\n",
       "                         -0.3065, -0.2759,  0.0323, -0.1117, -0.2022, -0.1073, -0.1732, -0.2070,\n",
       "                          0.0832,  0.2314, -0.1609,  0.1370, -0.0649,  0.2256,  0.4081, -0.0573,\n",
       "                          0.1710,  0.1874,  0.0890,  0.1920,  0.2338,  0.1248,  0.1611,  0.0375,\n",
       "                          0.1998, -0.2712,  0.1341,  0.1315,  0.1916,  0.0628,  0.1518,  0.1069]])),\n",
       "               ('model.material_nn.graphs.2.pooling.1.message_nn.lin1.weight',\n",
       "                tensor([[-0.1044,  0.0074,  0.0715,  ..., -0.1505,  0.0922, -0.1218],\n",
       "                        [ 0.1010,  0.1247, -0.0089,  ...,  0.0851,  0.0752, -0.0672],\n",
       "                        [ 0.1456,  0.0408,  0.0684,  ...,  0.1201,  0.0164,  0.0476],\n",
       "                        ...,\n",
       "                        [ 0.0806, -0.0294, -0.0827,  ...,  0.0596,  0.1433, -0.1081],\n",
       "                        [-0.0111, -0.1726, -0.1069,  ..., -0.1296, -0.0135,  0.1930],\n",
       "                        [ 0.0310,  0.0443,  0.1865,  ...,  0.0373,  0.1373, -0.1059]])),\n",
       "               ('model.material_nn.graphs.2.pooling.1.message_nn.lin2.weight',\n",
       "                tensor([[ 0.0620, -0.0182, -0.0954,  ..., -0.0955,  0.1102, -0.1336],\n",
       "                        [-0.1214, -0.0356,  0.0484,  ...,  0.0443, -0.0067, -0.0301],\n",
       "                        [-0.0144, -0.1843,  0.1310,  ...,  0.0537,  0.0802, -0.1775],\n",
       "                        ...,\n",
       "                        [ 0.0946,  0.0345,  0.1115,  ..., -0.1099, -0.0887, -0.1249],\n",
       "                        [-0.0103,  0.0747,  0.0136,  ..., -0.1250,  0.1606, -0.0461],\n",
       "                        [-0.0749,  0.0896, -0.0396,  ..., -0.0648,  0.0239, -0.0003]])),\n",
       "               ('model.material_nn.graphs.2.pooling.2.gate_nn.lin1.weight',\n",
       "                tensor([[-0.1027,  0.2415,  0.0711,  ...,  0.1153, -0.0448,  0.0585],\n",
       "                        [-0.0049,  0.0990, -0.0591,  ...,  0.1669,  0.2259, -0.0844],\n",
       "                        [ 0.1697, -0.0022, -0.0099,  ...,  0.0987,  0.0205, -0.2028],\n",
       "                        ...,\n",
       "                        [-0.0722, -0.0872,  0.0758,  ..., -0.1242, -0.0719, -0.0867],\n",
       "                        [-0.2206, -0.1966, -0.3796,  ..., -0.1136, -0.0682, -0.0279],\n",
       "                        [ 0.1692,  0.0153, -0.1745,  ...,  0.0297, -0.0104, -0.1613]])),\n",
       "               ('model.material_nn.graphs.2.pooling.2.gate_nn.lin2.weight',\n",
       "                tensor([[-0.1453, -0.3093, -0.2603, -0.0682, -0.0713,  0.2227, -0.1473, -0.1150,\n",
       "                          0.2385, -0.1991,  0.2350, -0.1124,  0.0663,  0.0564, -0.1614,  0.1689,\n",
       "                         -0.2190, -0.2014,  0.0774,  0.3329,  0.2816, -0.1690,  0.1304, -0.2396,\n",
       "                         -0.1405, -0.1532, -0.1710,  0.0560, -0.0630,  0.1228, -0.0781, -0.2463,\n",
       "                          0.1868, -0.2023,  0.2335, -0.1244,  0.0712, -0.1791,  0.2302, -0.1891,\n",
       "                         -0.1967, -0.1876, -0.0334, -0.1337, -0.0692,  0.1207, -0.1572,  0.2756,\n",
       "                         -0.2025, -0.2727,  0.2358,  0.0647,  0.2016,  0.1015, -0.2106,  0.1750,\n",
       "                          0.2337,  0.0254,  0.1585, -0.1412, -0.1325, -0.1642, -0.0997, -0.2158,\n",
       "                         -0.2031, -0.1423, -0.1937,  0.1073,  0.1587,  0.1522, -0.1245, -0.2232,\n",
       "                          0.5350,  0.1294,  0.3900,  0.0349, -0.0578, -0.2016,  0.2680, -0.1779,\n",
       "                          0.2329, -0.1593,  0.1509, -0.0256, -0.2571,  0.3167,  0.1431, -0.1864,\n",
       "                         -0.1028, -0.0653,  0.2287,  0.2043,  0.1204, -0.3139,  0.1896,  0.1138,\n",
       "                          0.1514,  0.3127,  0.1183, -0.1224, -0.0933, -0.1182, -0.2880, -0.2487,\n",
       "                          0.1041, -0.2345,  0.0899,  0.2294,  0.1998,  0.1068,  0.0614,  0.1385,\n",
       "                         -0.1963,  0.2369, -0.1481, -0.0530,  0.1656,  0.1072,  0.0361,  0.2369,\n",
       "                         -0.1652,  0.0227, -0.1511, -0.1843,  0.1009,  0.1953,  0.2203, -0.1743,\n",
       "                         -0.0234, -0.0609,  0.2067, -0.1626,  0.2434,  0.1711,  0.2401,  0.1720,\n",
       "                         -0.1765, -0.2960,  0.1649,  0.1239,  0.2008, -0.2901, -0.0957, -0.1183,\n",
       "                          0.1347, -0.2013, -0.2506,  0.1321,  0.2870, -0.2270, -0.1181, -0.2866,\n",
       "                          0.1984, -0.0889, -0.2299, -0.2145, -0.1597, -0.1762, -0.1902,  0.1190,\n",
       "                          0.1305, -0.0421, -0.2229, -0.0604, -0.1735,  0.2176,  0.2848,  0.1857,\n",
       "                          0.1771, -0.0425, -0.1306, -0.1579, -0.0318, -0.1085, -0.1547,  0.1489,\n",
       "                         -0.2926, -0.1242,  0.1393,  0.2543,  0.3539, -0.2596,  0.1333, -0.2332,\n",
       "                         -0.1034, -0.2620,  0.1451,  0.2210,  0.0711,  0.2800, -0.1189,  0.0974,\n",
       "                          0.1177, -0.2531, -0.2083, -0.1646, -0.0327, -0.2071,  0.1003,  0.2833,\n",
       "                          0.0874,  0.2407,  0.1286,  0.2002, -0.0613,  0.1201,  0.0684, -0.0552,\n",
       "                          0.0808,  0.3040,  0.1303, -0.0859, -0.0145, -0.0409,  0.2165,  0.0878,\n",
       "                          0.1687, -0.1657, -0.1364,  0.0463, -0.1007, -0.1661,  0.0060, -0.1502,\n",
       "                         -0.1188,  0.0331,  0.1819,  0.1435,  0.2893,  0.2545, -0.2570,  0.2973,\n",
       "                         -0.1088, -0.1843, -0.1710, -0.2328,  0.0264,  0.2451, -0.1922, -0.1787,\n",
       "                         -0.2153, -0.1866, -0.1092, -0.0432, -0.2702, -0.2606,  0.1410, -0.1268,\n",
       "                         -0.1832,  0.0800, -0.1181,  0.2131, -0.1949,  0.1903, -0.1021, -0.2128]])),\n",
       "               ('model.material_nn.graphs.2.pooling.2.message_nn.lin1.weight',\n",
       "                tensor([[-0.0366,  0.1574,  0.0367,  ...,  0.0817, -0.1255,  0.0779],\n",
       "                        [ 0.1701, -0.1590, -0.0454,  ..., -0.0201,  0.1129, -0.1935],\n",
       "                        [ 0.0116,  0.1663, -0.0588,  ..., -0.1351,  0.1246, -0.0692],\n",
       "                        ...,\n",
       "                        [ 0.0506, -0.0971,  0.1766,  ..., -0.0812,  0.0056, -0.2185],\n",
       "                        [ 0.0274,  0.1139, -0.0550,  ..., -0.1746,  0.1505, -0.0387],\n",
       "                        [ 0.1179,  0.1581, -0.0390,  ...,  0.1267, -0.0920, -0.1607]])),\n",
       "               ('model.material_nn.graphs.2.pooling.2.message_nn.lin2.weight',\n",
       "                tensor([[ 0.0961, -0.0014,  0.0746,  ...,  0.1770,  0.0728,  0.0503],\n",
       "                        [-0.0398,  0.0311,  0.0469,  ..., -0.0915,  0.1381,  0.1479],\n",
       "                        [-0.0862, -0.1797, -0.0725,  ..., -0.1164, -0.2111, -0.1637],\n",
       "                        ...,\n",
       "                        [-0.0827,  0.1391, -0.0145,  ...,  0.1206, -0.0997,  0.1751],\n",
       "                        [-0.0242,  0.0070,  0.0925,  ..., -0.1997, -0.1067, -0.1263],\n",
       "                        [ 0.0004, -0.0282, -0.0750,  ...,  0.1193,  0.1456,  0.1357]])),\n",
       "               ('model.material_nn.comp_pool.0.gate_nn.lin1.weight',\n",
       "                tensor([[ 1.6410e-01, -1.3155e-01, -2.5392e-02,  ..., -8.6081e-02,\n",
       "                         -1.7150e-02, -1.3273e-01],\n",
       "                        [ 2.2918e-02,  2.4907e-01,  1.2116e-01,  ..., -1.3027e-02,\n",
       "                          3.4780e-01, -1.9570e-01],\n",
       "                        [ 3.5377e-01,  2.3453e-01,  2.8127e-04,  ...,  2.1412e-01,\n",
       "                          2.2593e-01,  4.5497e-02],\n",
       "                        ...,\n",
       "                        [ 2.3127e-01,  3.0744e-02,  4.6185e-02,  ..., -3.3137e-01,\n",
       "                         -8.1348e-02, -2.4368e-01],\n",
       "                        [-3.2039e-01, -1.9789e-01,  5.4074e-02,  ..., -3.7240e-02,\n",
       "                         -2.7214e-01, -8.0677e-02],\n",
       "                        [ 1.1169e-01,  2.8798e-01, -8.9063e-02,  ...,  3.8323e-01,\n",
       "                          5.0340e-01, -1.1961e-02]])),\n",
       "               ('model.material_nn.comp_pool.0.gate_nn.lin2.weight',\n",
       "                tensor([[ 0.2094,  0.3856,  0.3109,  0.2043,  0.1064,  0.3787, -0.3046,  0.1396,\n",
       "                         -0.3305,  0.0687,  0.3265,  0.1223,  0.2479,  0.3654, -0.2157, -0.3651,\n",
       "                          0.3146,  0.2867,  0.1926,  0.3956, -0.3878, -0.2450,  0.2387,  0.1519,\n",
       "                         -0.3441, -0.0946, -0.3123, -0.4017,  0.5044,  0.5514,  0.4027,  0.2489,\n",
       "                          0.4182, -0.0704, -0.0446,  0.3243,  0.2036, -0.2020, -0.2579,  0.0905,\n",
       "                          0.0972,  0.2507,  0.2854,  0.3476, -0.2515, -0.2002,  0.1601, -0.0816,\n",
       "                         -0.1976, -0.1705,  0.1127,  0.3121,  0.3986, -0.3122, -0.2642, -0.4671,\n",
       "                          0.1595,  0.2098,  0.3608, -0.2847,  0.3433,  0.3341, -0.3759, -0.1057,\n",
       "                         -0.3183,  0.1631, -0.0405, -0.3369,  0.2245, -0.2421,  0.2919, -0.3016,\n",
       "                         -0.2142,  0.2873, -0.1328,  0.3261,  0.2642, -0.2006, -0.0656,  0.1273,\n",
       "                         -0.3182, -0.3077, -0.3524, -0.1256,  0.1965,  0.1473,  0.2036, -0.2674,\n",
       "                         -0.1980,  0.1900, -0.1634, -0.1424, -0.2516,  0.1968,  0.1343,  0.4628,\n",
       "                          0.2267,  0.3613, -0.2468,  0.3828, -0.2952, -0.4020,  0.2501, -0.2207,\n",
       "                         -0.1704,  0.3665,  0.1494, -0.3053, -0.2269,  0.2788,  0.1481, -0.3206,\n",
       "                          0.2937,  0.4180, -0.0611, -0.3680,  0.3168, -0.1561,  0.0533, -0.3699,\n",
       "                         -0.3410, -0.2665,  0.1412, -0.5794,  0.3860, -0.3490, -0.2027,  0.2266]])),\n",
       "               ('model.material_nn.comp_pool.0.message_nn.lin1.weight',\n",
       "                tensor([[ 0.2232,  0.1698, -0.0772,  ...,  0.0742,  0.1618, -0.2090],\n",
       "                        [ 0.2176, -0.2258, -0.2081,  ..., -0.0847,  0.1350, -0.1530],\n",
       "                        [ 0.0751,  0.2289,  0.1986,  ..., -0.2090,  0.0265, -0.0394],\n",
       "                        ...,\n",
       "                        [-0.1133, -0.2602,  0.0609,  ..., -0.0910,  0.1562, -0.1570],\n",
       "                        [-0.1637, -0.1081, -0.1249,  ...,  0.0589,  0.1204, -0.0010],\n",
       "                        [ 0.1437, -0.1726, -0.2285,  ..., -0.1128, -0.1406, -0.0836]])),\n",
       "               ('model.material_nn.comp_pool.0.message_nn.lin2.weight',\n",
       "                tensor([[-0.0597, -0.0112,  0.1854,  ..., -0.0567,  0.1007,  0.2137],\n",
       "                        [-0.0604,  0.2064,  0.2137,  ...,  0.2360, -0.1706,  0.1586],\n",
       "                        [-0.2158,  0.2151, -0.2438,  ..., -0.2185, -0.0810, -0.2345],\n",
       "                        ...,\n",
       "                        [ 0.1538,  0.1606,  0.2497,  ..., -0.1907, -0.0315,  0.1530],\n",
       "                        [-0.2104,  0.1934,  0.1855,  ...,  0.1425, -0.1138,  0.1444],\n",
       "                        [-0.2386, -0.0792,  0.1426,  ...,  0.2807,  0.2512, -0.0084]])),\n",
       "               ('model.material_nn.comp_pool.1.gate_nn.lin1.weight',\n",
       "                tensor([[-0.1834, -0.0493, -0.0895,  ...,  0.2081,  0.2702,  0.0431],\n",
       "                        [ 0.0015,  0.0952,  0.0160,  ...,  0.0277,  0.0712,  0.1461],\n",
       "                        [ 0.1913, -0.1953,  0.2181,  ...,  0.1049, -0.0642,  0.1624],\n",
       "                        ...,\n",
       "                        [ 0.1889, -0.1703,  0.1040,  ...,  0.1536,  0.0065,  0.2087],\n",
       "                        [ 0.1608,  0.0976,  0.0338,  ...,  0.0319,  0.1856, -0.0793],\n",
       "                        [-0.0506, -0.1428,  0.0027,  ..., -0.2430,  0.2872, -0.0044]])),\n",
       "               ('model.material_nn.comp_pool.1.gate_nn.lin2.weight',\n",
       "                tensor([[-0.3183, -0.3627, -0.3620,  0.2308,  0.2325,  0.4014, -0.3188, -0.3005,\n",
       "                         -0.1435, -0.4967,  0.3428,  0.1409,  0.0752, -0.2447,  0.4151, -0.0556,\n",
       "                          0.3524,  0.2488,  0.2835, -0.4096,  0.1339, -0.2220,  0.1808,  0.4794,\n",
       "                          0.2755,  0.1579,  0.1423, -0.3386, -0.3184, -0.2128,  0.2016, -0.0999,\n",
       "                         -0.2565,  0.3293,  0.5851, -0.0378, -0.1675, -0.0917,  0.2495, -0.1541,\n",
       "                          0.5326,  0.2810, -0.1994,  0.2314, -0.3296,  0.3926, -0.3823, -0.3105,\n",
       "                          0.1128,  0.1808,  0.2224, -0.2932, -0.2827,  0.3538,  0.1937, -0.1394,\n",
       "                          0.4244, -0.3411, -0.1415, -0.1154, -0.3300, -0.2675, -0.1897,  0.1395,\n",
       "                         -0.0434, -0.2145, -0.1926, -0.4117,  0.3437,  0.3059,  0.1858, -0.0602,\n",
       "                         -0.4476, -0.3022,  0.3505, -0.4423,  0.4459,  0.3000,  0.1934, -0.0683,\n",
       "                         -0.3545, -0.4153, -0.1088,  0.3145, -0.1055,  0.2800,  0.2431,  0.1392,\n",
       "                          0.1703,  0.0391, -0.2148, -0.4032,  0.2230, -0.2051, -0.2799,  0.1842,\n",
       "                          0.3462,  0.1319, -0.1399,  0.0736,  0.1939,  0.0398, -0.1749,  0.4110,\n",
       "                         -0.3237,  0.5445,  0.1903, -0.4366,  0.4277, -0.3552, -0.0934, -0.2814,\n",
       "                          0.2828,  0.2806,  0.3655, -0.5089,  0.2466, -0.1984, -0.0746, -0.2248,\n",
       "                         -0.1494, -0.3005, -0.3256, -0.1784,  0.0949,  0.2820, -0.1558,  0.2304]])),\n",
       "               ('model.material_nn.comp_pool.1.message_nn.lin1.weight',\n",
       "                tensor([[ 0.0360,  0.1212, -0.1731,  ...,  0.2013, -0.0718, -0.1003],\n",
       "                        [-0.0628,  0.2149,  0.0501,  ..., -0.1019, -0.1860,  0.0230],\n",
       "                        [ 0.0832, -0.2525,  0.1244,  ...,  0.1604,  0.0411, -0.1091],\n",
       "                        ...,\n",
       "                        [-0.0145, -0.2308,  0.1632,  ..., -0.2107,  0.2408, -0.0827],\n",
       "                        [ 0.0740,  0.2577, -0.2170,  ...,  0.0066, -0.1323, -0.1106],\n",
       "                        [ 0.2155, -0.2448,  0.1410,  ..., -0.1958, -0.0663,  0.0584]])),\n",
       "               ('model.material_nn.comp_pool.1.message_nn.lin2.weight',\n",
       "                tensor([[-0.2498,  0.2351, -0.0089,  ..., -0.1482, -0.1757, -0.1473],\n",
       "                        [ 0.1058, -0.1514, -0.0671,  ...,  0.1730,  0.0550, -0.1774],\n",
       "                        [-0.1297,  0.1670, -0.2217,  ...,  0.1174, -0.0796,  0.0438],\n",
       "                        ...,\n",
       "                        [ 0.2352,  0.1025,  0.1996,  ...,  0.1427,  0.0419, -0.0766],\n",
       "                        [ 0.2004,  0.2422,  0.0196,  ..., -0.1594,  0.1205, -0.0240],\n",
       "                        [ 0.1316, -0.1953,  0.0282,  ..., -0.2071, -0.1343,  0.1649]])),\n",
       "               ('model.material_nn.comp_pool.2.gate_nn.lin1.weight',\n",
       "                tensor([[ 0.0676, -0.0471,  0.1638,  ...,  0.1773, -0.0088, -0.2354],\n",
       "                        [-0.0854,  0.1942, -0.1472,  ...,  0.2366, -0.1289, -0.1119],\n",
       "                        [-0.0470, -0.1271, -0.2202,  ...,  0.2212, -0.2462,  0.0360],\n",
       "                        ...,\n",
       "                        [-0.1190,  0.0341,  0.2515,  ...,  0.0355,  0.0846, -0.1621],\n",
       "                        [ 0.0515, -0.0230,  0.0234,  ..., -0.3218,  0.1059,  0.1564],\n",
       "                        [ 0.1773,  0.2208, -0.0150,  ..., -0.1315, -0.1656,  0.1195]])),\n",
       "               ('model.material_nn.comp_pool.2.gate_nn.lin2.weight',\n",
       "                tensor([[ 0.3641,  0.4611,  0.0170,  0.4996, -0.3564,  0.4025,  0.3403,  0.3831,\n",
       "                          0.3095,  0.3825, -0.4681, -0.2034,  0.4224, -0.1378, -0.1736,  0.3734,\n",
       "                          0.2332,  0.4714,  0.3585, -0.3117,  0.4580,  0.2587, -0.2299, -0.2894,\n",
       "                         -0.4104, -0.5444,  0.2904, -0.4684,  0.1381, -0.3153,  0.3813,  0.2005,\n",
       "                         -0.2946, -0.2492, -0.4297, -0.4399,  0.3792, -0.2901,  0.4386,  0.2820,\n",
       "                          0.3267, -0.1834,  0.2593,  0.3559,  0.3222, -0.2299, -0.2189, -0.1820,\n",
       "                          0.1550, -0.2465, -0.4582, -0.1532, -0.5116, -0.3970, -0.4535,  0.3127,\n",
       "                          0.1446,  0.2425, -0.1702, -0.3425,  0.2640,  0.4229, -0.3929,  0.1917,\n",
       "                          0.1778, -0.3576,  0.4548,  0.4867, -0.1885,  0.3123, -0.6043,  0.2533,\n",
       "                         -0.1593, -0.2726, -0.4644, -0.3761, -0.4815, -0.4648, -0.3354,  0.4706,\n",
       "                          0.2592,  0.1517, -0.3178,  0.3663, -0.4935,  0.3615,  0.3436, -0.3558,\n",
       "                         -0.1793,  0.3141, -0.2354,  0.2405, -0.4316,  0.4925,  0.3549,  0.4105,\n",
       "                          0.3262, -0.3734,  0.4969,  0.3730,  0.3219, -0.2356, -0.3905, -0.1108,\n",
       "                          0.4084,  0.3904,  0.3212, -0.3982,  0.2462, -0.3004,  0.3451, -0.3807,\n",
       "                          0.3975,  0.1853, -0.2807,  0.4530,  0.4633, -0.2471,  0.2091, -0.2246,\n",
       "                          0.2021, -0.2511,  0.2850, -0.3534,  0.3862,  0.5568, -0.4388, -0.4693]])),\n",
       "               ('model.material_nn.comp_pool.2.message_nn.lin1.weight',\n",
       "                tensor([[-0.1234,  0.0075,  0.0690,  ...,  0.1261,  0.2197,  0.0553],\n",
       "                        [ 0.2305, -0.1464, -0.1691,  ..., -0.0722,  0.0127,  0.1439],\n",
       "                        [ 0.1392, -0.1590, -0.1172,  ...,  0.2571,  0.0115, -0.0008],\n",
       "                        ...,\n",
       "                        [ 0.1251, -0.1453,  0.0734,  ..., -0.2361,  0.1989,  0.1309],\n",
       "                        [ 0.0131,  0.0035, -0.1247,  ...,  0.1835, -0.1420,  0.0787],\n",
       "                        [-0.0590, -0.0117, -0.1611,  ...,  0.1501, -0.2169,  0.1731]])),\n",
       "               ('model.material_nn.comp_pool.2.message_nn.lin2.weight',\n",
       "                tensor([[ 0.1517,  0.1513, -0.2191,  ..., -0.0646,  0.0089,  0.0021],\n",
       "                        [ 0.1001,  0.0598,  0.2116,  ..., -0.1654, -0.1942,  0.0252],\n",
       "                        [ 0.2282, -0.2517, -0.0266,  ...,  0.1764,  0.2025,  0.0724],\n",
       "                        ...,\n",
       "                        [ 0.1338, -0.1668,  0.2182,  ...,  0.1784, -0.1473, -0.1195],\n",
       "                        [-0.1871, -0.2400,  0.0911,  ...,  0.1903,  0.1840, -0.0394],\n",
       "                        [-0.0796,  0.1153, -0.0240,  ...,  0.0809, -0.2099, -0.0109]])),\n",
       "               ('model.resnet.fcs.0.weight',\n",
       "                tensor([[-0.0076,  0.0219, -0.1088,  ..., -0.1080,  0.0441,  0.0661],\n",
       "                        [ 0.0098, -0.0799,  0.0093,  ..., -0.0054, -0.0493, -0.0869],\n",
       "                        [-0.0472,  0.0323, -0.0134,  ..., -0.0195, -0.0066,  0.0437],\n",
       "                        ...,\n",
       "                        [ 0.1267, -0.1044,  0.1008,  ...,  0.0212,  0.0667,  0.0835],\n",
       "                        [ 0.0082,  0.0244,  0.0554,  ..., -0.0030,  0.0391,  0.0120],\n",
       "                        [-0.0342,  0.0696,  0.0211,  ...,  0.0250, -0.0658, -0.0499]])),\n",
       "               ('model.resnet.fcs.0.bias',\n",
       "                tensor([ 0.0045, -0.0885, -0.0779,  ..., -0.0522,  0.0090, -0.0545])),\n",
       "               ('model.resnet.fcs.1.weight',\n",
       "                tensor([[ 0.0025, -0.0615,  0.0374,  ..., -0.0753, -0.0814, -0.0012],\n",
       "                        [ 0.0248, -0.0567, -0.0504,  ...,  0.0131,  0.0082, -0.0329],\n",
       "                        [-0.0605, -0.0288,  0.0100,  ...,  0.0169, -0.0715,  0.0053],\n",
       "                        ...,\n",
       "                        [ 0.0313,  0.0579,  0.0629,  ...,  0.0678, -0.0230, -0.0817],\n",
       "                        [ 0.0832, -0.0236,  0.0540,  ..., -0.1165,  0.0702, -0.0670],\n",
       "                        [-0.0799,  0.0823, -0.0015,  ..., -0.0733, -0.0143,  0.0359]])),\n",
       "               ('model.resnet.fcs.1.bias',\n",
       "                tensor([ 2.1436e-02,  5.3199e-03, -2.4558e-02, -3.4339e-02, -1.1344e-02,\n",
       "                         1.1502e-02,  2.4287e-03, -7.2445e-03,  1.2984e-02, -1.1553e-02,\n",
       "                         2.3764e-02, -7.3950e-03,  2.3252e-02, -2.6499e-02, -1.8634e-02,\n",
       "                         2.0920e-02, -3.0736e-02,  9.7326e-03, -1.5756e-02,  4.4228e-03,\n",
       "                        -6.7644e-03, -3.1387e-02, -3.0727e-02,  1.2833e-02,  9.0463e-03,\n",
       "                        -3.5937e-03,  4.5350e-03,  1.2376e-02, -2.3304e-02,  2.5071e-02,\n",
       "                        -1.7440e-02, -5.4670e-03, -2.8824e-02, -2.5641e-02,  1.9819e-03,\n",
       "                         2.1563e-02, -2.6059e-02, -2.7384e-02,  2.5449e-02, -6.7506e-03,\n",
       "                        -3.2411e-02, -1.7095e-02, -3.5154e-02, -1.7354e-02, -3.4780e-02,\n",
       "                         1.1225e-02, -2.3149e-02, -1.9618e-02,  2.6395e-02,  1.9413e-02,\n",
       "                        -1.8067e-02,  1.1309e-02, -1.6675e-02, -2.6352e-02, -1.2666e-02,\n",
       "                         8.0108e-03, -2.4654e-02,  1.0700e-03, -1.3718e-02,  1.2468e-02,\n",
       "                        -3.5515e-02, -1.4551e-03, -2.6699e-02,  8.7250e-03,  6.9799e-03,\n",
       "                         1.1373e-02,  9.5107e-03,  2.0360e-02, -1.2601e-02, -1.0456e-02,\n",
       "                         1.7921e-02, -1.7053e-02,  7.0097e-03, -2.6396e-02, -7.2561e-03,\n",
       "                        -4.5725e-03,  1.2194e-02,  1.3273e-03, -1.7217e-02,  1.0944e-04,\n",
       "                         6.6889e-03,  9.1350e-04, -1.7655e-02,  1.2025e-02,  1.5919e-02,\n",
       "                         3.0770e-03,  2.9694e-04,  1.6535e-02,  7.9427e-04, -1.6844e-02,\n",
       "                         1.3321e-02, -3.1557e-02,  2.4864e-03,  1.6111e-02, -1.8813e-02,\n",
       "                         7.8488e-03,  1.5642e-02, -7.3629e-04, -2.0846e-02, -2.5199e-03,\n",
       "                        -2.5122e-02, -9.5830e-04, -2.9986e-02, -3.3279e-02, -4.5634e-03,\n",
       "                        -1.3825e-02,  1.8550e-03, -4.1299e-03, -8.7583e-03, -2.0499e-02,\n",
       "                        -4.0072e-03,  1.8430e-02, -3.0049e-02,  2.0418e-02, -1.5886e-02,\n",
       "                        -7.7297e-03,  2.4185e-02, -2.1809e-02, -3.8369e-02,  1.1194e-02,\n",
       "                        -8.1569e-03,  1.6189e-02,  9.4101e-03,  6.1178e-03, -1.8049e-02,\n",
       "                        -3.8501e-02,  5.5197e-03, -2.8962e-02, -1.5112e-02, -2.7227e-02,\n",
       "                        -3.8372e-02,  2.1195e-02, -4.3673e-03, -2.3421e-02, -3.0272e-02,\n",
       "                        -1.7326e-02,  7.9416e-03, -1.3411e-03,  1.0189e-02, -1.3741e-02,\n",
       "                        -3.4454e-02, -3.7439e-03, -1.9169e-02, -2.6128e-02,  1.6387e-03,\n",
       "                        -2.1593e-02, -2.2174e-02, -1.4425e-02,  1.7349e-02, -1.6697e-02,\n",
       "                        -9.0117e-03, -1.7070e-02, -2.0784e-03,  1.0802e-02, -3.3807e-03,\n",
       "                        -1.2387e-02, -7.4531e-03, -5.2629e-03,  3.4743e-03, -1.2805e-02,\n",
       "                        -2.3744e-02,  1.7556e-02,  6.3835e-03, -5.5152e-03, -3.6537e-02,\n",
       "                         4.7169e-03, -2.5608e-02,  1.2705e-03,  5.2465e-03, -2.0860e-02,\n",
       "                         2.8386e-03, -1.7624e-02, -1.8631e-02,  1.7872e-02,  1.3488e-02,\n",
       "                        -2.4570e-02,  3.1658e-03, -2.2132e-02, -2.0122e-02,  2.7954e-02,\n",
       "                        -2.2934e-02, -3.8631e-03, -2.8087e-02, -1.0615e-02,  1.5058e-02,\n",
       "                        -2.5455e-03,  1.0027e-02, -1.5501e-02, -2.6658e-02,  6.8212e-03,\n",
       "                         1.0835e-02,  1.5440e-02, -2.1759e-02, -2.2503e-02,  2.3384e-03,\n",
       "                        -6.3703e-03, -2.6331e-02,  1.2660e-02,  5.8977e-04,  2.9184e-03,\n",
       "                        -2.3906e-04, -3.3842e-02, -5.0758e-03, -9.1817e-03,  2.0934e-02,\n",
       "                        -2.8800e-02, -6.5796e-04, -2.2575e-02, -2.5305e-02, -1.9243e-02,\n",
       "                         1.7854e-02, -6.2468e-03, -2.9733e-02,  7.5520e-03,  1.4157e-02,\n",
       "                        -1.1247e-02,  2.8642e-03, -3.0142e-02, -4.1458e-02,  3.1317e-02,\n",
       "                        -2.7134e-02, -2.4322e-03, -1.2628e-02, -1.7618e-02,  6.4885e-03,\n",
       "                        -1.0292e-02, -1.3150e-02, -1.0586e-02, -1.6876e-02, -2.6451e-02,\n",
       "                        -2.1818e-03, -1.6234e-02, -1.4071e-02, -3.4850e-03, -9.8658e-03,\n",
       "                        -1.7254e-02, -1.4758e-02, -2.8409e-02, -2.9427e-02, -3.0936e-02,\n",
       "                         2.3028e-02, -1.3330e-02, -1.3469e-02,  7.8641e-03,  3.9910e-03,\n",
       "                        -1.6367e-02,  4.1963e-05, -2.5663e-02, -4.5403e-03, -1.2905e-02,\n",
       "                        -1.2973e-02, -2.6744e-02,  1.2518e-02,  9.5507e-03,  9.4673e-04,\n",
       "                         5.3036e-03,  2.5083e-02, -2.7486e-02,  1.5136e-02, -1.6729e-02,\n",
       "                         1.3823e-03, -2.7697e-02, -2.9912e-02,  8.0681e-03, -1.0939e-02,\n",
       "                        -1.8460e-02,  1.8984e-02, -2.7298e-02,  2.6517e-02, -2.7568e-02,\n",
       "                         1.8136e-02, -1.3202e-02, -1.8227e-02,  9.0138e-03, -3.0919e-02,\n",
       "                         7.1658e-04,  2.1536e-03,  1.8632e-02, -2.6104e-02, -1.5950e-02,\n",
       "                        -3.7566e-02,  2.0240e-02, -4.2134e-04,  1.4693e-02,  1.5407e-02,\n",
       "                        -2.1466e-02,  1.4111e-02, -1.0821e-03,  2.2938e-02,  1.5061e-02,\n",
       "                         1.7029e-02, -3.8043e-03, -1.5707e-02, -1.0640e-02,  1.0153e-02,\n",
       "                        -8.4134e-03, -4.4157e-03, -1.5816e-02, -6.9934e-04, -6.6810e-03,\n",
       "                         1.9639e-02, -6.0205e-03,  6.3419e-03, -2.5651e-02,  2.2868e-02,\n",
       "                        -1.1704e-02,  1.4450e-03, -1.7714e-02,  1.7270e-02,  1.9080e-02,\n",
       "                        -2.5716e-02,  1.4517e-02, -2.8679e-03, -1.5793e-02,  6.3505e-03,\n",
       "                        -1.7020e-02, -2.0320e-02,  1.3139e-02,  1.6555e-02,  3.4213e-02,\n",
       "                        -2.0848e-02, -3.2218e-02,  1.0891e-02,  5.4844e-04,  1.1311e-02,\n",
       "                        -6.2063e-03, -1.7253e-02, -1.5704e-02,  6.0693e-03, -4.0431e-03,\n",
       "                        -2.8513e-02,  1.4324e-02, -2.0579e-02, -1.1913e-02, -2.1543e-02,\n",
       "                         8.4001e-03,  7.9202e-03, -1.7016e-02, -2.9392e-02,  1.4623e-02,\n",
       "                         8.2159e-03, -3.3749e-02, -5.3196e-03,  7.1422e-04, -1.4844e-02,\n",
       "                        -2.4245e-02, -1.1826e-02, -2.7909e-02, -1.3822e-02, -3.4247e-02,\n",
       "                        -7.2206e-03,  8.4550e-03, -3.8806e-03,  1.4011e-02, -3.3962e-03,\n",
       "                         1.1801e-02,  6.5653e-03, -2.3422e-02,  1.5195e-02,  1.3289e-02,\n",
       "                         1.2047e-02,  5.7884e-04,  1.0816e-02,  1.5547e-02,  6.9058e-03,\n",
       "                         1.1478e-02,  8.0482e-03, -1.9008e-03, -1.6160e-02,  1.1172e-02,\n",
       "                        -1.4013e-02,  1.6989e-02,  1.4479e-02, -1.7472e-02, -1.3023e-02,\n",
       "                        -5.5568e-03, -9.3352e-03, -1.7745e-02, -2.5409e-02,  1.6023e-02,\n",
       "                        -3.5045e-02, -1.1920e-02,  1.0556e-02,  1.1645e-02, -3.8331e-03,\n",
       "                         5.0093e-03, -3.0842e-02,  7.6060e-04, -1.8990e-02,  1.7035e-02,\n",
       "                         2.4063e-02,  7.7057e-03, -3.6502e-03, -1.0843e-02, -1.1052e-02,\n",
       "                         2.3663e-02,  1.3190e-03, -2.5720e-02,  4.6759e-03,  1.6501e-02,\n",
       "                        -2.1552e-02,  3.4601e-03, -4.5292e-03,  1.0827e-02, -1.1121e-02,\n",
       "                        -3.0779e-02, -9.4503e-03, -2.5723e-02, -3.6062e-02, -1.9282e-02,\n",
       "                        -1.1021e-02, -6.2333e-03, -1.6800e-02, -9.3464e-03, -9.9504e-03,\n",
       "                         2.2646e-03,  7.7269e-03, -3.7522e-02, -1.4579e-02, -1.2343e-02,\n",
       "                        -2.8143e-02, -1.3495e-02,  5.2110e-03,  1.5428e-02,  1.6595e-02,\n",
       "                        -3.9286e-02, -3.7315e-02,  1.3475e-02, -8.0851e-03,  1.2212e-02,\n",
       "                        -3.5418e-02,  1.3737e-02, -1.6937e-02, -6.7806e-03,  7.9436e-04,\n",
       "                        -1.7066e-02, -1.4382e-03, -3.7074e-02, -1.6994e-03, -3.1421e-03,\n",
       "                         7.6706e-03, -3.7174e-02, -1.5260e-02, -1.2391e-02,  1.2203e-02,\n",
       "                         1.4436e-02,  1.0961e-02, -2.1409e-02, -9.5664e-03,  9.9006e-03,\n",
       "                        -2.3509e-02,  1.6970e-02,  9.0460e-03,  1.8268e-02,  1.2232e-02,\n",
       "                        -2.7151e-02, -3.0217e-02,  7.1281e-03,  1.1345e-03, -2.9355e-02,\n",
       "                        -1.9772e-03, -2.5451e-02,  2.7588e-03, -2.6241e-02, -9.6301e-03,\n",
       "                        -9.7444e-04,  1.0853e-02,  7.0010e-04, -1.0892e-02,  2.1829e-02,\n",
       "                        -8.6101e-03,  2.6428e-03,  8.1663e-03, -1.5293e-03, -1.8064e-02,\n",
       "                         1.6958e-02, -1.5768e-02, -6.4330e-03,  2.1590e-02,  1.5416e-02,\n",
       "                        -4.7243e-03, -3.9021e-02, -3.3915e-02, -2.9664e-02,  1.2731e-02,\n",
       "                         4.6299e-03,  7.1155e-03, -1.3149e-02,  4.8219e-06,  5.4808e-03,\n",
       "                        -1.4994e-02, -1.2112e-02, -2.7908e-02, -1.7604e-02,  1.5584e-02,\n",
       "                         1.7881e-02, -2.2773e-02, -2.0914e-02, -8.4288e-03, -4.1042e-03,\n",
       "                        -5.9635e-04, -1.2727e-02, -2.9978e-02, -8.8180e-03,  1.5731e-02,\n",
       "                        -1.5729e-02, -3.1208e-02,  1.4637e-02, -1.3106e-03,  2.5131e-03,\n",
       "                         6.3095e-03,  1.0084e-02])),\n",
       "               ('model.resnet.fcs.2.weight',\n",
       "                tensor([[ 0.0993, -0.1264, -0.0458,  ..., -0.0374, -0.0913, -0.1162],\n",
       "                        [ 0.0347,  0.0995,  0.0750,  ..., -0.0842,  0.0146,  0.0298],\n",
       "                        [-0.1065,  0.0983,  0.1038,  ...,  0.0737, -0.0325,  0.0552],\n",
       "                        ...,\n",
       "                        [ 0.0138, -0.0447,  0.0334,  ...,  0.0231, -0.0286,  0.0915],\n",
       "                        [-0.0043, -0.0575,  0.0906,  ...,  0.0853, -0.0028,  0.0471],\n",
       "                        [-0.0470,  0.0199, -0.0579,  ...,  0.0254, -0.0856, -0.0346]])),\n",
       "               ('model.resnet.fcs.2.bias',\n",
       "                tensor([-0.0610,  0.0072, -0.0321, -0.0340, -0.0070, -0.0118, -0.0363, -0.0193,\n",
       "                        -0.0091,  0.0014, -0.0072, -0.0296, -0.0281,  0.0373, -0.0424, -0.0321,\n",
       "                        -0.0303, -0.0578,  0.0066,  0.0136,  0.0187, -0.0352, -0.0659, -0.0371,\n",
       "                        -0.0172,  0.0197, -0.0633, -0.0271, -0.0279, -0.0172, -0.0040, -0.0292,\n",
       "                         0.0012, -0.0071, -0.0406, -0.0270, -0.0501,  0.0096, -0.0169, -0.0053,\n",
       "                        -0.0618,  0.0042, -0.0445,  0.0167, -0.0473, -0.0316, -0.0046, -0.0329,\n",
       "                        -0.0429, -0.0225,  0.0081, -0.0416,  0.0386,  0.0020,  0.0273,  0.0006,\n",
       "                         0.0006, -0.0439, -0.0246,  0.0039,  0.0044,  0.0128, -0.0461, -0.0193,\n",
       "                        -0.0380, -0.0059, -0.0314, -0.0067, -0.0005, -0.0070, -0.0343, -0.0272,\n",
       "                         0.0106,  0.0143, -0.0178,  0.0255, -0.0382, -0.0024, -0.0045,  0.0253,\n",
       "                         0.0014, -0.0058,  0.0049, -0.0225, -0.0337, -0.0434, -0.0353,  0.0029,\n",
       "                        -0.0167, -0.0172, -0.0426,  0.0142, -0.0169, -0.0148, -0.0135, -0.0439,\n",
       "                        -0.0399,  0.0127,  0.0331,  0.0086, -0.0199, -0.0226,  0.0343, -0.0010,\n",
       "                        -0.0121, -0.0039, -0.0122,  0.0004,  0.0164, -0.0078,  0.0154,  0.0016,\n",
       "                         0.0095, -0.0082, -0.0647, -0.0184,  0.0016,  0.0092, -0.0326, -0.0003,\n",
       "                         0.0131, -0.0118,  0.0367,  0.0067, -0.0207, -0.0470, -0.0443, -0.0299,\n",
       "                         0.0127,  0.0015, -0.0360,  0.0074,  0.0082, -0.0345,  0.0356, -0.0191,\n",
       "                        -0.0196,  0.0055, -0.0394, -0.0511,  0.0056, -0.0412, -0.0253, -0.0333,\n",
       "                        -0.0286,  0.0321, -0.0211, -0.0035, -0.0038, -0.0151, -0.0386, -0.0337,\n",
       "                        -0.0129,  0.0024, -0.0052,  0.0018,  0.0282, -0.0034,  0.0065, -0.0210,\n",
       "                        -0.0298,  0.0157, -0.0149,  0.0159, -0.0244, -0.0350, -0.0016, -0.0277,\n",
       "                        -0.0415, -0.0021,  0.0067,  0.0173,  0.0113, -0.0409, -0.0018, -0.0010,\n",
       "                        -0.0441, -0.0557,  0.0121, -0.0287, -0.0424, -0.0295, -0.0441, -0.0199,\n",
       "                        -0.0382, -0.0256, -0.0206, -0.0240,  0.0121, -0.0586, -0.0043, -0.0352,\n",
       "                        -0.0163,  0.0025, -0.0258, -0.0247,  0.0031, -0.0468,  0.0025, -0.0248,\n",
       "                        -0.0464, -0.0158, -0.0009, -0.0467,  0.0250, -0.0329, -0.0597, -0.0109,\n",
       "                        -0.0490,  0.0398,  0.0047,  0.0225, -0.0125, -0.0111,  0.0062, -0.0251,\n",
       "                         0.0138,  0.0120,  0.0196, -0.0402, -0.0279, -0.0218, -0.0373, -0.0514,\n",
       "                        -0.0042,  0.0127,  0.0080, -0.0565, -0.0127, -0.0207, -0.0302,  0.0154,\n",
       "                        -0.0452, -0.0234, -0.0180,  0.0176, -0.0251, -0.0168, -0.0354,  0.0226,\n",
       "                        -0.0339,  0.0196,  0.0132,  0.0172, -0.0129, -0.0466,  0.0155,  0.0091,\n",
       "                        -0.0419,  0.0065,  0.0062,  0.0093,  0.0134, -0.0076, -0.0062, -0.0365])),\n",
       "               ('model.resnet.fcs.3.weight',\n",
       "                tensor([[ 0.0494, -0.1541,  0.0655,  ...,  0.0448, -0.0272,  0.1624],\n",
       "                        [-0.0327, -0.0964,  0.1437,  ..., -0.0329,  0.1141,  0.1235],\n",
       "                        [-0.0111, -0.1280,  0.0370,  ...,  0.0106,  0.1424,  0.0049],\n",
       "                        ...,\n",
       "                        [ 0.1035, -0.0893, -0.1533,  ..., -0.0057, -0.1063,  0.0553],\n",
       "                        [-0.0850,  0.1792, -0.0749,  ..., -0.0321, -0.0230, -0.1207],\n",
       "                        [-0.0696,  0.0041, -0.0625,  ...,  0.0362,  0.1451, -0.1343]])),\n",
       "               ('model.resnet.fcs.3.bias',\n",
       "                tensor([-0.0169,  0.0298, -0.0523,  0.0516,  0.0134, -0.0126,  0.0365,  0.0069,\n",
       "                         0.0100, -0.0392, -0.0160,  0.0186, -0.0101, -0.0276, -0.0515, -0.0443,\n",
       "                        -0.0408, -0.0018, -0.0396, -0.0128, -0.0540,  0.0151, -0.0454, -0.0193,\n",
       "                        -0.0133,  0.0481, -0.0264, -0.0744,  0.0410, -0.0176, -0.0593, -0.0600,\n",
       "                         0.0317,  0.0599, -0.0270,  0.0004, -0.0208,  0.0242, -0.0173, -0.0547,\n",
       "                        -0.0627, -0.0380, -0.0326, -0.0246, -0.0546,  0.0152, -0.0614, -0.0289,\n",
       "                        -0.0356,  0.0046, -0.0404,  0.0014, -0.0401,  0.0223, -0.0332, -0.0513,\n",
       "                         0.0201,  0.0448,  0.0313, -0.0464,  0.0195,  0.0638,  0.0138, -0.0247,\n",
       "                        -0.0558, -0.0049, -0.0595, -0.0514, -0.0560, -0.0187,  0.0039,  0.0280,\n",
       "                        -0.0604, -0.0776,  0.0284, -0.0353, -0.0663,  0.0099,  0.0332, -0.0528,\n",
       "                        -0.0050, -0.0507, -0.0100, -0.0067, -0.0515,  0.0150, -0.0526,  0.0306,\n",
       "                         0.0187, -0.0333,  0.0319,  0.0309, -0.0172, -0.0608,  0.0017,  0.0618,\n",
       "                        -0.0196, -0.0691, -0.0170, -0.0555, -0.0167, -0.0737, -0.0390,  0.0422,\n",
       "                         0.0656, -0.0367,  0.0358,  0.0009,  0.0553,  0.0569, -0.0267, -0.0535,\n",
       "                         0.0060,  0.0026, -0.0464, -0.0232,  0.0151, -0.0583, -0.0219, -0.0256,\n",
       "                         0.0208, -0.0105,  0.0516,  0.0125, -0.0250, -0.0457, -0.0262,  0.0022])),\n",
       "               ('model.resnet.fcs.4.weight',\n",
       "                tensor([[ 0.1431,  0.0161,  0.0882,  ..., -0.1662, -0.2034, -0.1915],\n",
       "                        [-0.0026,  0.2033, -0.0087,  ...,  0.2290,  0.1943, -0.2466],\n",
       "                        [-0.0825,  0.1359,  0.0103,  ...,  0.2142, -0.2259, -0.1561],\n",
       "                        ...,\n",
       "                        [ 0.1216, -0.2135, -0.0348,  ..., -0.0598,  0.0349, -0.1780],\n",
       "                        [ 0.0531,  0.0127,  0.0289,  ...,  0.0727, -0.1140,  0.2146],\n",
       "                        [-0.1947,  0.0251,  0.0977,  ..., -0.2497, -0.0823,  0.2117]])),\n",
       "               ('model.resnet.fcs.4.bias',\n",
       "                tensor([-0.0063,  0.0453,  0.0199, -0.0685,  0.0087, -0.0352,  0.0484, -0.0658,\n",
       "                        -0.0330,  0.0599,  0.0619,  0.0597, -0.0676, -0.0870,  0.0182,  0.0679,\n",
       "                         0.0281,  0.0053,  0.0587,  0.0687,  0.0803, -0.0710, -0.0333, -0.0508,\n",
       "                         0.0829, -0.0788,  0.0560,  0.0092,  0.0316, -0.0737, -0.0171, -0.0334,\n",
       "                        -0.0517,  0.0764, -0.0246, -0.0484,  0.0740, -0.0166,  0.0251,  0.0558,\n",
       "                        -0.0200,  0.0569,  0.0439, -0.0871, -0.0493, -0.0978,  0.0726, -0.0183,\n",
       "                        -0.0152, -0.0032, -0.0780,  0.0754,  0.0555,  0.0437, -0.0654,  0.0092,\n",
       "                         0.0353, -0.0218, -0.0720,  0.0029,  0.0530,  0.0456,  0.0907, -0.0317])),\n",
       "               ('model.resnet.res_fcs.0.weight',\n",
       "                tensor([[ 0.0634,  0.0022, -0.0715,  ...,  0.0351,  0.0718, -0.0026],\n",
       "                        [ 0.0764,  0.0497,  0.0121,  ...,  0.0833,  0.1125,  0.0180],\n",
       "                        [ 0.0267,  0.0509,  0.0978,  ...,  0.0988,  0.0398, -0.0392],\n",
       "                        ...,\n",
       "                        [ 0.0369, -0.0842, -0.0204,  ...,  0.0175,  0.0064,  0.0395],\n",
       "                        [ 0.0571,  0.0226, -0.0770,  ..., -0.0265,  0.0447,  0.0791],\n",
       "                        [ 0.0168,  0.0510, -0.0852,  ...,  0.0472,  0.0074,  0.0401]])),\n",
       "               ('model.resnet.res_fcs.1.weight',\n",
       "                tensor([[ 0.0587,  0.0696,  0.0517,  ..., -0.0191, -0.0180,  0.0804],\n",
       "                        [ 0.0345, -0.0177, -0.0269,  ...,  0.0804,  0.0123, -0.0421],\n",
       "                        [-0.0484, -0.0021, -0.0221,  ..., -0.0495, -0.0416, -0.0681],\n",
       "                        ...,\n",
       "                        [-0.0241,  0.0071, -0.0186,  ..., -0.0974, -0.0793,  0.0571],\n",
       "                        [ 0.0447, -0.0566,  0.0677,  ...,  0.0344, -0.0515,  0.0267],\n",
       "                        [ 0.0744, -0.0169, -0.0600,  ..., -0.0799, -0.0002, -0.0525]])),\n",
       "               ('model.resnet.res_fcs.2.weight',\n",
       "                tensor([[ 0.0124, -0.0869,  0.0915,  ...,  0.0638, -0.1014, -0.0651],\n",
       "                        [-0.1121,  0.1163, -0.0899,  ..., -0.0689, -0.0981,  0.0126],\n",
       "                        [-0.0030, -0.0615,  0.0896,  ..., -0.0232,  0.0908, -0.0315],\n",
       "                        ...,\n",
       "                        [ 0.0566,  0.0872,  0.1240,  ..., -0.0119, -0.0800, -0.0502],\n",
       "                        [-0.0438, -0.0190,  0.0336,  ..., -0.0444,  0.0165,  0.0278],\n",
       "                        [-0.0315, -0.0991,  0.0382,  ..., -0.0653,  0.0716, -0.0110]])),\n",
       "               ('model.resnet.res_fcs.3.weight',\n",
       "                tensor([[-0.1656,  0.0743, -0.0379,  ..., -0.0943, -0.0432, -0.0033],\n",
       "                        [-0.1527, -0.0046, -0.0612,  ...,  0.0328, -0.0469, -0.0476],\n",
       "                        [ 0.1246, -0.0353,  0.0910,  ...,  0.0767,  0.0976,  0.0477],\n",
       "                        ...,\n",
       "                        [ 0.0490, -0.1484, -0.0744,  ..., -0.0865, -0.1532,  0.0443],\n",
       "                        [ 0.1114, -0.0155, -0.0331,  ..., -0.1428, -0.0048, -0.0734],\n",
       "                        [-0.0689, -0.1237, -0.1429,  ..., -0.0099,  0.0767, -0.0614]])),\n",
       "               ('model.resnet.res_fcs.4.weight',\n",
       "                tensor([[-0.2309,  0.1136, -0.2385,  ...,  0.0494, -0.0918,  0.1971],\n",
       "                        [ 0.2387, -0.0590,  0.0685,  ..., -0.0208, -0.2485,  0.1798],\n",
       "                        [-0.2351,  0.1730,  0.2375,  ..., -0.0601,  0.1355, -0.2238],\n",
       "                        ...,\n",
       "                        [-0.0321,  0.0586, -0.1061,  ...,  0.0642,  0.0376,  0.0018],\n",
       "                        [-0.0156, -0.0064,  0.2032,  ...,  0.0941,  0.1427, -0.1918],\n",
       "                        [-0.1883, -0.0056, -0.0209,  ..., -0.2455,  0.1239, -0.0426]])),\n",
       "               ('model.resnet.fc_out.weight',\n",
       "                tensor([[-0.1363, -0.0572, -0.2011,  0.2192,  0.0688,  0.0049, -0.3124, -0.0160,\n",
       "                         -0.1197,  0.1719, -0.2359, -0.3637, -0.0913, -0.2927,  0.0192,  0.0430,\n",
       "                          0.0404, -0.2008, -0.2693,  0.1125, -0.1401,  0.2580,  0.1683, -0.0931,\n",
       "                         -0.2984,  0.3430, -0.0410,  0.3577, -0.2516, -0.2790,  0.1715, -0.2786,\n",
       "                         -0.2515, -0.3020,  0.0220,  0.3486,  0.1587, -0.0800, -0.3312,  0.3050,\n",
       "                          0.0792,  0.1031,  0.3836,  0.0428, -0.1585, -0.2685, -0.1757, -0.0641,\n",
       "                         -0.1771, -0.0886,  0.2305,  0.3171,  0.0497,  0.3529,  0.1044, -0.3627,\n",
       "                         -0.1563,  0.2654, -0.2532, -0.1172, -0.1601,  0.2983,  0.0865, -0.3844]])),\n",
       "               ('model.resnet.fc_out.bias', tensor([0.0808]))])},\n",
       " \"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0,\n",
       "  'stopped_epoch': 0,\n",
       "  'best_score': tensor(0.0915, device='cuda:0'),\n",
       "  'patience': 100},\n",
       " \"ModelCheckpoint{'monitor': 'val_mae', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'val_mae',\n",
       "  'best_model_score': tensor(0.1087, device='cuda:0'),\n",
       "  'best_model_path': 'roost_energy_models/trained_models/energy-epoch=93-val_acc=0.00.ckpt',\n",
       "  'current_score': tensor(0.1087, device='cuda:0'),\n",
       "  'dirpath': 'roost_energy_models/trained_models/',\n",
       "  'best_k_models': {'roost_energy_models/trained_models/energy-epoch=93-val_acc=0.00.ckpt': tensor(0.1087, device='cuda:0')},\n",
       "  'kth_best_model_path': 'roost_energy_models/trained_models/energy-epoch=93-val_acc=0.00.ckpt',\n",
       "  'kth_value': tensor(0.1087, device='cuda:0'),\n",
       "  'last_model_path': ''}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['callbacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e430c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'material_nn.project_fea.weight'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='model.material_nn.project_fea.weight'\n",
    "s[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9995e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "checkpoint1=OrderedDict()\n",
    "for key,value in checkpoint['state_dict'].items():\n",
    "    checkpoint1[key[6:]]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9122e3a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Roost:\n\tUnexpected key(s) in state_dict: \"al_nn.project_fea.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\roost\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Roost:\n\tUnexpected key(s) in state_dict: \"al_nn.project_fea.weight\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5795d6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd3fc18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.criterion(torch.tensor([0.0,1.0]),torch.tensor([0.0,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2fbbc1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RoostLightningClass' object has no attribute 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\roost\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RoostLightningClass' object has no attribute 'criterion'"
     ]
    }
   ],
   "source": [
    "model.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f32030b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Negation, the `-` operator, on a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Disorder-prediction-new 1\\Disorder-prediction-new\\roost\\utils.py:94\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss\u001b[1;34m(output, target, weight)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBCEWithLogitsLoss\u001b[39m(output, target,weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 94\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\.conda\\envs\\roost\\lib\\site-packages\\torch\\nn\\functional.py:3150\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m   3148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m-> 3150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Negation, the `-` operator, on a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
     ]
    }
   ],
   "source": [
    "model.hparams.criterion(torch.tensor([True,False]),torch.tensor([True,False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "923d7495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function roost.utils.BCEWithLogitsLoss(output, target, weight=None)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94777d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=BCEWithLogitsLoss\n",
    "loss(torch.tensor([0.0,1.0]),torch.tensor([0.0,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7baa4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
